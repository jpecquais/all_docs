[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SPAT Revolution",
    "section": "",
    "text": "FLUX:: Immersive SPAT Revolution 22.09"
  },
  {
    "objectID": "index.html#a-user-guide",
    "href": "index.html#a-user-guide",
    "title": "SPAT Revolution",
    "section": "A User Guide",
    "text": "A User Guide\nWritten by Cristian Vogel, Jean-Loup Pecquais, Hugo Larin and Nicolas Erard\nwith contributions from: Gäel Martinet, Vincent Carlier, Florie-Anne Lafaye, Thibaut Carpentier, Anders Tveit and the IRCAM team.\nLegal Information\nThird edition of FLUX:: SPAT Revolution User Guide published in September 2022\nAll writing is protected under copyright © 2023 Cristian Vogel / FLUX SOFTWARE ENGINEERING\nFLUX:: is a trademark of FLUX SOFTWARE ENGINEERING All trademarks and the logos are copyright protected.\nFLUX:: SPAT Revolution is published by\nFLUX SOFTWARE ENGINEERING\n31, rue des Marais\n45130 Meung-sur-Loire\nR.C.S 431 616 770 ORLEANS\nIRCAMTOOLS SPAT Copyright 2023 FLUX SOFTWARE ENGINEERING and IRCAM. All rights reserved.\nSPAT Revolution Copyright 2023 FLUX SOFTWARE ENGINEERING and IRCAM. All rights reserved."
  },
  {
    "objectID": "Credits.html#version-22.09",
    "href": "Credits.html#version-22.09",
    "title": "SPAT Revolution - Credits",
    "section": "Version 22.09",
    "text": "Version 22.09"
  },
  {
    "objectID": "Credits.html#user-guide-and-documentation",
    "href": "Credits.html#user-guide-and-documentation",
    "title": "SPAT Revolution - Credits",
    "section": "User Guide and Documentation",
    "text": "User Guide and Documentation\nCristian Vogel, Hugo Larin, Jean-Loup Pecquais and Nicolas Erard\nAdditional contributions: Gaël Martinet, Vincent Carlier, Florie-Anne Lafaye, Thibaut Carpentier, Anders Tveit and the IRCAM team.\n\nProject Manager and Designer:\nGaël Martinet, Hugo Larin\n\n\nApplication Development:\nGaël Martinet, Florie-Anne Lafaye, Alexis Gentil, Nicolas Erard, Siegfried Hand and Antoine Lorence.\n\n\nFLUX:: DSP Design and Development:\nGaël Martinet, Maxence Grandidier and Lorcan Mc Donagh\n\n\n“Spat~” Design of digital signal processing algorithms and implementation in Max:\nJean-Marc Jot (Espaces Nouveaux / Ircam).\n\n\n“Spat~” Objective and perceptual characterization of room acoustical quality:\nJean-Pascal Jullien, Olivier Warusfel and Eckhard Kahle\nAdditional contributions:\nGerard Assayag, Georges Bloch, Martine Marin, Véronique Larcher, Guillaume Vandernoot, Khoa-Van Nguyen and Markus Noisternig\n\n\n“Spat~” C++ dsp code:\nThibaut Carpentier and Remy Muller\n\n\nGraphic design:\nNicolas Philippot\n\n\nFLUX:: Framework development:\nGaël Martinet, Florie-Anne Lafaye, Alexis Gentil, Bastien Prevosto, Siegfried Hand and Antoine Lorence\nAdditional contributions: Hugo Larin, Vincent Carlier, Jean-Loup Pecquais, Nicolas Erard, Jean Cruypenynck, Pablo Arias, Samuel Tracol, HAL\n\n\nFLUX:: Framework graphic engine:\nEmmanuel Julien (GS lib) and Gaël Martinet\n\n\nTranslation\n\nFrench: Jean-Loup Pecquais, Nicolas Erard\nGerman: Nils Hahmann\nKorean: Gong Eunju, Kim Joohna\nItalian: Gianni Tamanini\nSpanish: Ralph Killhertz\n\n\n\nAdditional libs:\n\nNuXPixels (Magnus Lidström)\nspline lib (Joachim Klahr)\nLibJpeg\nFreetype 2\nZlib\nBoost\nRTTrPM (Blacktraxx)\n\n\n\nAdditional Python modules:\n\nargh (Andrey Mikhaylenko)\nCrypto (Dwayne C. Litzenberger)\nDocopt (Vladimir Keleshev)\necdsa (Peter Pearson)\nenum (Ben Finney)\nipgetter (Fernando Giannasi)\nparamiko (Jeff Forcier)\npathtools (Yesudeep Mangalapilly)\npsutil (Giampaolo Rodola)\nwatchdog (Yesudeep Mangalapilly, Google, Inc)\nyaml (Kirill Simonov)\nwinshell (Tim Golden)\nsix (Benjamin Peterson)\nRequest (Kenneth Reitz)\npylightxl (pydpiper)\nsentry_sdk (Copyright (c) 2018 Sentry)\nurllib3 (Andrey Petrov)\ncertifi (Kenneth Reitz)\nanytree (c0fec0de)\nboltons (Copyright (c) 2013, Mahmoud Hashemi)\npendulum (Sébastien Eustace)\npytzdata (Sébastien Eustace)\nmsgpack (Inada Naoki)\ndateutil (Gustavo Niemeyer, Paul Ganssle)\ntgcrypto (Copyright (C) 2017-2020 Dan https://github.com/delivrance)\nsourcedefender (Copyright (c) 2018-2020 SOURCEdefender. All rights reserved.)\n\n\n\nAnd\nthanks to all fantastic testers…\n\n\nFLUX:: Special Thanks to:\nAlain, Yves, Bruno and Claude for helping to shape our minds over the years.\nHAL for its support\n\n\nIrcam Special Thanks to\nXavier Chabot, Eric Daubresse, Gerhard Eckel, Serge Lemouton, Gilbert Nouno, Laurent Pottier, Manuel Poletti, Leslie Stuck, and Zack Settel for instructive discussions and advice.\n\n\nIrcam R&D Director :\nHugues Vinet\n\n\nIRCAMTOOLS Collection Manager for IRCAM:\nFrédérick Rousseau\n\n\nCollection Manager for FLUX:: SE\nGaël Martinet\n\n\nPublished by FLUX:: SE\nFLUX SOFTWARE ENGINEERING\nOrléans, France,\nhttp://www.flux.audio\nCopyright 2020 FLUX SOFTWARE ENGINEERING,\nAll Rights Reserved.\nIRCAMTOOLS SPAT and \"SPAT Revolution\" Copyright 2020 FLUX SOFTWARE ENGINEERING and IRCAM. All rights reserved.\nSpatialisateur and Spat~ are trademarks of Ircam and Espaces Nouveaux:\nThe Ambisonic Logo, a trademark formerly owned by Wyastone Estade Ltd, which expired\nin 2010 is featured on page 30 of this guide"
  },
  {
    "objectID": "Welcome_to_Spat_Revolution.html",
    "href": "Welcome_to_Spat_Revolution.html",
    "title": "1  Welcome to SPAT Revolution",
    "section": "",
    "text": "Product Page | Shop Page\nFirst of all, thank you for acquiring SPAT Revolution. We hope it will provide you with new levels of productivity, creativity and experience in sound design. Our goal was to deliver the most comprehensive real-time spatial audio renderer ever designed, and to make the whole process of spatialized audio production powerful and intuitive for beginners and professionals alike. Our real-time audio environment provides easy access to some of the most advanced spatialization algorithms currently available, at the very best sound quality currently possible.\n‘SPAT’ is short for Spatialisateur in French. It is a real-time audio library that allows composers, sound artists, performers and sound engineers to control the localisation of sound sources in virtual and real 3D auditory spaces.\n\n\nSPAT Revolution wraps the ‘Spat’ processing library in a luxurious and characteristic graphic environment to help visualise many aspects of a spatial audio composition in realtime. This graphic interface allows sound mixes to be composed as interactive spatial models existing in Virtual Room. SPAT contains a powerful multichannel reverberation engine which can be applied to design and add a sense of auditory space in studio mixes and realtime on location.\n\n\n\n\n\n\nNote\n\n\n\nArtificial Reverberation Editor\n\n\n\n\nSPAT Revolution maintains the highest audio quality throughout the entire signal flow\n\n2 SPAT Revolution’s Heritage\nSPAT Revolution is underpinned by 30 years of technical research and development in acoustics and sound.\nBehind SPAT Revolution is the partnership of FLUX:: SE and Ircam in Paris, France. Founded in 1977, Ircam is one of the world’s leading public research institutes in the fields of musical expression, science of music, sound and acoustics. The first result of this partnership was the plugin suite IRCAM Tools. In that release was the first incarnation of SPAT as a DAW plugin based on over 30 years of research with Ircam’s Acoustic and Cognitive Spaces Team. After decades of development the next step was the full production environment for spatial audio - SPAT Revolution through the elegant simplicity of the graphic interface, SPAT Revolution represents a formidable achievement. It brings together the technical expertise from decades of academic research and development at IRCAM into an easy-to-use package that is flexible and powerful enough to meet all the demands of spatial audio production, from day to day surround sound post-production to the most challenging realtime installations. As you will discover, SPAT Revolution can handle a virtually unlimited number of input and output audio streams and is prepared for all formats and 3D-audio workflows currently available or imaginable in the audio industry.\nAlthough this user guide cannot cover every technical aspect of the algorithms and expert knowledge contained within SPAT Revolution we hope you will feel assured that the science behind the sound is absolutely correct.\n\n\n3 About this Guide\nThis guide has been written for practitioners already working in immersive sound production yet new to the SPAT Revolution software environment. Is also intended to be read as a practical introduction to surround and immersive audio production for those who are new to the medium and coming to it through SPAT Revolution. Of course, there is plenty more knowledge to be had in the field of immersive audio and the technology behind it, which will strengthen your understanding and decision-making.\nWe strongly suggest spending the time to read through this guide before starting on your first major production and keep it on hand during the process. Expert support and advice can also be sought from the FLUX Immersive FB user group and the Web-based Knowledge base.\nLet us start now with a practical guide on getting the software installed and running."
  },
  {
    "objectID": "Users_and_Applications.html",
    "href": "Users_and_Applications.html",
    "title": "2  Users and Applications",
    "section": "",
    "text": "SPAT Revolution is aimed at all practitioners working in the medium of spatial audio and 3D sound production - old and new. It is an expert system intended for professional use but its intuitive graphical interface invites a more diverse range of creators to engage in spatial sound production - if it is your first experience working with spatial sound technology, SPAT Revolution is a great way to start out directly at a professional quality level.\nSPAT Revolution spatialises and renders audio in real-time. It is used in:\n\npost-production for film\nstudio composition\nconcert diffusion\nvirtual reality\naudio for video games\n360 video soundtracks\n3D Audio for broadcast\ninteractive sound art\nlive production mixing\nscientific research and development\nsound design for film, music and theatre\nenvironmental sound\n\nIn the contexts of live production or sound installation, the composer or sound mixer can associate sound events with a room effect or a specific position in space. Virtual objects can be controlled on screen, or by a sequencer, a score-following system, or any other algorithmic approach. Spat can easily be linked to any remote control device (show controllers, trajectory applications, tracking systems, tablet, smartphone, joystick, gestural sensors, etc.) through OSC and RTTrPM interfacing protocols. RTTrPM is supported by the SPAT Revolution Ultimate license only.\nIn the contexts of studio mixing and post-production, a virtual source/object can receive its audio from individual channels on a mixing desk or DAW with additional controllers easily set up to allow hands on control of the positions and characteristics of virtual sources and associated room effect. SPAT Revolution can re-mix a multichannel mix from one format in a virtual room that could be rendered in a different output format, allowing a novel approach to up- and down-mixing.\nIn the context of Augmented and Virtual Reality, a spatialized auditory component is essential in creating the sensations of presence and immersion in interactive virtual reality applications. In such scenarios, the B-Format and binaural 3D capabilities of Spat are particularly well suited.\nAn important thing to keep in mind is the long heritage and technical expertise behind SPAT Revolution. There are many critical factors to consider when multichannel audio is actually applied in the real world. But rest assured that the algorithms behind your spatial sound project are being implemented correctly at the stage of the authoring and rendering environment. It is good to know that SPAT Revolution is built with such a high level of technical expertise in such an intuitive package.\n\n\n\n\n\n\nNote\n\n\n\nWhatever the scale of your spatialized audio production, SPAT Revolution makes it simple to craft an impressive and reliable end result."
  },
  {
    "objectID": "Getting_Started.html",
    "href": "Getting_Started.html",
    "title": "Getting started",
    "section": "",
    "text": "In the following section, we will discuss how to install SPAT Revolution, using the FLUX:: Center, and how to redeem and activate your licenses.\nWe will also explain all the differences between the Ultimate and Essential licenses.\nFurthermore, if you are searching for a quick start guide, check this document : quick start guide."
  },
  {
    "objectID": "Installation_and_Activation.html#how-to-install-spat-revolution",
    "href": "Installation_and_Activation.html#how-to-install-spat-revolution",
    "title": "3  Installation and Activation",
    "section": "3.1 How to Install SPAT Revolution?",
    "text": "3.1 How to Install SPAT Revolution?\nFOUR (4) STEPS:\n\nCreate an account on FLUX website\nLicense code redeem\nSoftware license activation\nDownload and installation"
  },
  {
    "objectID": "Installation_and_Activation.html#create-and-account",
    "href": "Installation_and_Activation.html#create-and-account",
    "title": "3  Installation and Activation",
    "section": "3.2 Create and account",
    "text": "3.2 Create and account\n\nCreate an account on the FLUX website, clicking on the previous link."
  },
  {
    "objectID": "Installation_and_Activation.html#redeem-a-license-code-from-activation-code",
    "href": "Installation_and_Activation.html#redeem-a-license-code-from-activation-code",
    "title": "3  Installation and Activation",
    "section": "3.3 Redeem a License Code from activation code",
    "text": "3.3 Redeem a License Code from activation code\nFLUX:: uses the iLok license management system to deliver software licenses to users. If you have received an activation code (such as from a dealer purchase or 30-day trial), you can use the Redeem License Code window to activate your license.\n\nVisit our License Code Activation page for more information."
  },
  {
    "objectID": "Installation_and_Activation.html#ilok-user-account",
    "href": "Installation_and_Activation.html#ilok-user-account",
    "title": "3  Installation and Activation",
    "section": "3.4 iLok User Account",
    "text": "3.4 iLok User Account\nTo activate licenses:\n\n\nAn iLok user account is required.\nAn iLok USB key is optional.\n\nFLUX:: uses the iLok license management system to deliver software licenses to users. If you don’t have an iLok account yet, please create a free iLok account at http://www.ilok.com and download the iLok license manager. SPAT Revolution Essential license comes with one (1) activation where the SPAT Revolution Ultimate Bundle includes two (2) activation linked to your user account. Having two activations gives you the possibility of a fixed license on one particular machine and a portable license on an iLok USB key if you own one. Other examples are for main and backup SPAT Engine running on a live production or In-studio and on-the-road scenarios.\n\n\n\n\n\n\nNote\n\n\n\nCloud license is currently not supported."
  },
  {
    "objectID": "Installation_and_Activation.html#ilok-license-manager",
    "href": "Installation_and_Activation.html#ilok-license-manager",
    "title": "3  Installation and Activation",
    "section": "3.5 iLok License Manager",
    "text": "3.5 iLok License Manager\nIf you have redeemed your software license or completed your purchase process, your license will automatically be delivered into your iLok account\n\nFor new iLok users, the first step is to download and install the iLok license manager available on the home page of the iLok website. When your user account is successfully activated and the iLok license manager is correctly installed, you can start the license manager software and log in to your iLok user account."
  },
  {
    "objectID": "Installation_and_Activation.html#transferring-license",
    "href": "Installation_and_Activation.html#transferring-license",
    "title": "3  Installation and Activation",
    "section": "3.6 Transferring license",
    "text": "3.6 Transferring license\n\nPressing on the sign-in button will allow you to connect to your account. After Logging in, you are now ready to transfer any licenses to a computer or to any iLok USB key if you happen to have one. The process of transferring a license is as simple as dragging the license from the Available tab to your Local Computer (or iLok key) on the left side. SPAT Revolution Essential license is a single license where SPAT Revolution Ultimate is a bundle containing three (3) licenses, Essential, Ultimate and Legacy.\nSimply drag your license to your Local Computer or on an iLok USB key. You are now set!\n\n\n\n\n\n\nNote\n\n\n\nIf you require further information about iLok and managing licenses please refer to iLok.com website."
  },
  {
    "objectID": "Installation_and_Activation.html#flux-center",
    "href": "Installation_and_Activation.html#flux-center",
    "title": "3  Installation and Activation",
    "section": "3.7 FLUX:: Center",
    "text": "3.7 FLUX:: Center\n\nNext step is to get the installers for the FLUX:: products you are licensed for. All the software and plugins from FLUX:: are available via our FLUX:: Center software. This is a Mac or Windows application we have created to help keep your FLUX:: products up to date and to give you a clear overview of what you have installed. Firstly, please visit the download section of the FLUX:: Website to get the installer for the FLUX:: Center application.\nOn this page you will find a macOS, a Windows 64 bits. As well are provided legacy version for older operating systems. After downloading and installing, you can open the FLUX:: Center applications to begin the process of installing the SPAT Revolution software.\n\n\n\n\n\n\nWarning\n\n\n\nAn authentication is required at the launch of FLUX:: Center. This is the login details of your FLUX shop account which allows you to see only your products licensed for (temporary or permanent)."
  },
  {
    "objectID": "Installation_and_Activation.html#center-preferences",
    "href": "Installation_and_Activation.html#center-preferences",
    "title": "3  Installation and Activation",
    "section": "3.8 Center Preferences",
    "text": "3.8 Center Preferences\n\nWhen you open FLUX:: Center you will see a page that lists all FLUX:: products available for you to install. You will also find information about which version you have currently installed on your system and which new versions might be available for you to update to. You can select versions to install - or uninstall if necessary - using the pull down menus. If you would like to access more installer options such as your preferred plug-in format, please click on the gear icon to the top right of the header area."
  },
  {
    "objectID": "Installation_and_Activation.html#center-preferences-and-options",
    "href": "Installation_and_Activation.html#center-preferences-and-options",
    "title": "3  Installation and Activation",
    "section": "3.9 Center Preferences and Options",
    "text": "3.9 Center Preferences and Options\n\n\n\n\n\n\n\nNote\n\n\n\nSPAT Revolution Send/Room/Return plugins are available in VST-64bit, AU-64bit and AAX-64bit only.\n\n\nThis preference page will allow you to choose various installation options such as preferred plug-in formats for your system. Choosing your format and returning to the main page by pressing the OK button will show all your install options for software and plugins based on the desired formats chosen.\nIf you would like to be closer to the most current development cycles of the software, you can enable the Beta Versions option. This will give you access to a special set of software installers from the pull down menus on the main FLUX:: Center page. Beta versions are the new builds that are still under development but may contain useful bug fixes and new features. If you find that a beta version is not stable enough for you, then you can always roll back to a stable release version at any time through the FLUX:: Center installers. Note that these versions starts with a B where official releases start with a V."
  },
  {
    "objectID": "Ultimate_And_Essential_Licences.html#ultimate-and-essential-whats-common",
    "href": "Ultimate_And_Essential_Licences.html#ultimate-and-essential-whats-common",
    "title": "4  Ultimate and Essential licenses",
    "section": "4.1 Ultimate and Essential : what’s common?",
    "text": "4.1 Ultimate and Essential : what’s common?\nThe SPAT Revolution software supports with the same installer (binary) both license options and has the common features listed below:\n\nAn easy-to-understand setup page, showing a clear representation of the signal path.\nA powerful mixing environment, using a 3D view and perceptive factor parameters.\nAn oriented-object audio engine allowing the user to render either channel-based, Higher Order Ambisonic (HOA) or binaural audio streams.\nSupport for mono, stereo and multichannel inputs streams.\nA flexible speaker array editor allowing going beyond the usual standards.\nA snapshot system to easily recall scenes on the fly.\nAn audio pipe technologies allowing receiving and sending audio from all the major DAW to and from SPAT Revolution.\nAn exhaustive list of OSC commands to allow a deep remote control of SPAT Revolution."
  },
  {
    "objectID": "Ultimate_And_Essential_Licences.html#ultimate-and-essential-differences",
    "href": "Ultimate_And_Essential_Licences.html#ultimate-and-essential-differences",
    "title": "4  Ultimate and Essential licenses",
    "section": "4.2 Ultimate and Essential: differences",
    "text": "4.2 Ultimate and Essential: differences\nThe main limitations of the Essential license are:\n\nThe number of cumulated input channels is limited to 32.\nThe number of cumulated output channels is limited to 18.\nThe number of rooms is limited to 1: no simultaneous rendering.\nHOA order is limited to 3rd order.\nTracking data cannot be modified\nRTTrp is not allowed.\n\nComplete specification is available here."
  },
  {
    "objectID": "Ultimate_And_Essential_Licences.html#ultimate-and-essential-sessions-compatibility",
    "href": "Ultimate_And_Essential_Licences.html#ultimate-and-essential-sessions-compatibility",
    "title": "4  Ultimate and Essential licenses",
    "section": "4.3 Ultimate and Essential sessions compatibility",
    "text": "4.3 Ultimate and Essential sessions compatibility\nWhen creating or opening a session that contains elements non-compatible with the Essential license, those elements are simply deactivated (not processed). Thus, an Ultimate session can be opened with an Essential license and vice-versa. See [Modules (de)activation and sessions compatibility -@module-de-activation].\n\nCheck Essential compatibility\nIn the top bar menu, click on File &gt; Check Essential Compatibility to check if the current session is compatible with the SPAT Essential restrictions.\n\nIf the session is not compatible, it can be opened with an Essential license, the restrictions due to license limitations will automatically deactivate the non-authorized objects.\n\n\n\n\n\n\nNote\n\n\n\nIf a session contains elements non-compatible with an Essential license, they can be manually deactivated for the session to fit the Essential license restrictions. If all the non-authorized elements are inactive, the session is considered as compatible with Essential license.\n\n\nSee [Modules (de)activation -@module-de-activation] for more information about automatic and manual (de)activation.\n\n\nEssential compatibility mode in Ultimate\nThe Ultimate license offers an Essential Compatibility Mode, for switching between Essential and Ultimate behaviors without any change in your license authorization."
  },
  {
    "objectID": "Spatialisation_Technology_Spatialisation_Technology.html",
    "href": "Spatialisation_Technology_Spatialisation_Technology.html",
    "title": "Spatialization Technology",
    "section": "",
    "text": "In this section, we will discuss on the various spatialization tool used by SPAT Revolution.\nHere are some straight to the point key points:\n\nSPAT Revolution is an object-based audio engine. The mixes you will create will consist in sets of data for each sound object. These data sets will then be decoded for a certain type of spatialization technique.\n\n\n\n\n\n\n\nNote\n\n\n\nWith SPAT Revolution Ultimate license, several render can be done at the same time (multi-room).\n\n\n\nThanks to the object-based engine, you can create sound stages in all spatialized audio format possible: channel-based, ambisonics (up to seventh order), binaural and transaural. If these names does not ring a bell to you, do not fear, we will cover these different techniques later in this section.\nOn top of the object-based engine, SPAT Revolution also covers the acoustic simulation side of things. The build-in reverberation will adapt to your mixes, and, more importantly, to your desired output format.\nSPAT Revolution aims at many use cases, many of them being for live performances. It was designed to not add any more latency than necessary on the signal path.\n\nLet’s start with an important notion of spatial audio: the listener position."
  },
  {
    "objectID": "Spatialisation_Technology_Listener_Position.html#listener-position-and-head-tracking",
    "href": "Spatialisation_Technology_Listener_Position.html#listener-position-and-head-tracking",
    "title": "5  Listener Position",
    "section": "5.1 Listener position and head tracking",
    "text": "5.1 Listener position and head tracking\nIn certain advanced situations which might combine position tracking systems with real time binaural audio, it is even possible to transform the Listener Position in SPAT Revolution. One application of this might be to give the sensation of getting closer to a sound emitter inside a virtual scene for a headset wearing participant at an interactive VR installation. Given the camera position perspective to the listener is as well possible by mapping camera position to the Listener Position of SPAT Revolution."
  },
  {
    "objectID": "Spatialisation_Technology_Binaural.html#introduction",
    "href": "Spatialisation_Technology_Binaural.html#introduction",
    "title": "6  Binaural",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\nThe word “binaural” covers various methods of sound recordings, synthesis and reproduction which can render 3D spatial audio content over headphones. For instance, binaural field recordings can be made by placing miniature microphones in the ear canals of a listener or of a dummy head (like ’ Kemar ’ or ’ KU100 ’) and when played back over headphones such recordings can produce an authentic immersive auditory experience with enhanced spatial aspects. Relatively recent progress in signal processing technology has made it possible to synthesize binaural signals without the need of microphones.\nUsing binaural synthesis, a sound can be arbitrarily positioned around a listener synthesizing the sensory experience of an extended spatialization. Like some other two-channel formats such as Mid-Side Stereo, binaural-encoded audio recordings are not compatible with stereo speakers. If a binaural encoded audio file is played on a normal stereo setup, audio will be heard, but it won’t sound good.\n\n\n\n\n\n\nWarning\n\n\n\nIt is important to point out to a client who might be new to binaural monitoring, that binaural files should only be listened to on a good pair of headphones."
  },
  {
    "objectID": "Spatialisation_Technology_Binaural.html#hrtf",
    "href": "Spatialisation_Technology_Binaural.html#hrtf",
    "title": "6  Binaural",
    "section": "6.2 HRTF",
    "text": "6.2 HRTF\nHRTF is an abbreviation for Head Related Transfer Function. This function is a mathematical model of the filtering effect caused by a listener’s own head, external ear and torso. This filtering plays a significant role in the way we localize sounds around us and is unique to every individual. HRTF is different between the two ears, so we always talk about pairs of HRTFs.\nWhen synthesizing binaural monitoring, a perfect result could be attained by rendering through the exact HRTFs that matches the body filtering effect of an individual. In practice this is not easily done, so SPAT Revolution offers many choices of pre-analyzed HRTFs profiles which you can apply for monitoring and encoding binaural audio. You can manage the selection of HRTFs profiles in the SPAT Revolution Preferences where you will find a number of different profiles including the option to load your own HRTFs. The default HRTFs is the Kemar dummy head model, which is often used as an all-round generic head and shoulder filter."
  },
  {
    "objectID": "Spatialisation_Technology_Binaural.html#hrtf-profiles",
    "href": "Spatialisation_Technology_Binaural.html#hrtf-profiles",
    "title": "6  Binaural",
    "section": "6.3 HRTF Profiles",
    "text": "6.3 HRTF Profiles\nThe included HRTFs profiles in SPAT Revolution are taken from a number of large-scale laboratory research projects where measurements were taken on many individuals*. The chances are that one person’s ears may sound more natural to you than others. For a quick way to monitor binaural, you should try to find a profile that you feel most comfortable with when monitoring your virtual scene on headphones. If you are providing a 3D in-ear monitor mix for a performer or a visitor to an installation, try to find an HRTFs profile that suits them best. This can be fun! If you are not comfortable listening through someone else ears —which is understandable— you could look into creating a personalized HRTFs profile from your own head and upper torso measurements. There already exist a number of services that can create HRTFs profiles taken from laboratory measurements. If you decide to do this, for yourself or someone else, then you can add the personalized profile to the list in the HRTFs Manager. In fact, you can import any HRTFs in SOFA format to the SPAT Revolution binaural encoding list, making SPAT Revolution a very flexible solution for binaural monitoring and rendering.\n\n\n\n\n\n\nWarning\n\n\n\nAn imported HRTFs profile should be in SOFA format and should match the sample rate of your project. It is preferable to use a “SimpleFreeFieldSOS” IIR type of HRTFs.\n* The profiles come from the “LISTEN”, “CROSSMOD” and “BiLi” databases."
  },
  {
    "objectID": "Spatialisation_Technology_Binaural.html#binaural-algorithms",
    "href": "Spatialisation_Technology_Binaural.html#binaural-algorithms",
    "title": "6  Binaural",
    "section": "6.4 Binaural algorithms",
    "text": "6.4 Binaural algorithms\n\nStandard binaural mode\nThis mode uses the selected HRTFs profile in order to recreate the sound field.\n\n\nAdvanced algorithms\n\nNear-field binaural\nHRTFs are generally measured at one or two meters of the listener. In reality, the HRTFs are changing with the distance between the source and the listener, especially when sources are close.\nThe Near Field Binaural tends to recreate close HRTFs, with an additional filter set applied.\n\n\nSpherical head model\nThis binaural synthesis simulates the head like a rigid sphere, instead of using HRTFs.\nAs this model does not use HRTFs, this synthesis consumes less CPU. However, the localization is clearly less precise.\n\n\nSnowman model\nThis synthesis is the improvement of the Spherical Head Model. Besides the head reflections, torso ones are simulated, like two spheres one on the top of the other. Hence, its name, “snowman model.”\n\n\n\nHead scale parameter\nThe parameter “head scale”, available for the four binaural algorithms, allows adapting the head size to the listener. This will adjust the interaural time and level differences. It is available on the room parameter on the Setup page, but also on the output panel of the room.\n\n\n\nHeadscale parameter"
  },
  {
    "objectID": "Spatialisation_Technology_Binaural.html#sec-binaural-monitoring",
    "href": "Spatialisation_Technology_Binaural.html#sec-binaural-monitoring",
    "title": "6  Binaural",
    "section": "6.5 Binaural Monitoring Module",
    "text": "6.5 Binaural Monitoring Module\n\n\n\nBinaural Monitor\n\n\nIn the Setup page of SPAT Revolution, you will find a module dedicated to binaural monitoring. Its purpose is to monitor any kind of speaker setup using headphones and binaural encoding. This can give you an impression of how your spatialization might sound on a particular channel based system when you are off location.\nYou can add a binaural monitoring module by clicking on the + icon of the Monitor row towards the bottom of the Setup page graph. The module is very simple to use. It will automatically detect the type of channel based audio stream you connect into it.\nThe binaural monitoring module works by virtualizing each speaker, not each source, so any real world speaker phenomena will be reflected in the binaural rendering. For example, a virtual source positioned in the center between two virtual speakers will be rendered with the same “phantom speaker” in the binaural monitoring as in the physical world, because there is no virtual speaker at the center point either.\nTo listen to the binaural stream on headphones, you should select the HRTFs profile you would like to use for the encoding, and connect the output from the module to a dedicated Output module at the bottom of the graph. The output should be routed to the headphone monitor outputs of your audio hardware."
  },
  {
    "objectID": "Spatialisation_Technology_Transaural.html",
    "href": "Spatialisation_Technology_Transaural.html",
    "title": "7  Transaural",
    "section": "",
    "text": "Although we said earlier that binaurally encoded files are not compatible with stereo loudspeaker systems, it turns out that in SPAT Revolution there is a way to play binaurally encoded signals on loudspeakers if necessary. You can do this by transcoding a binaural stream into a Transaural stream either at the Input Transcoder stage or at the Master Transcoder stage of the Setup page graph.\nThe term Transaural refers only to the transcoding of binaural signals into loudspeaker-compatible signals. The reproduction mode is also known as “cross-talk cancellation” as it uses this very process to establish the loudspeaker-compatible signals.\n\n\n\n\n\n\nWarning\n\n\n\nTo successfully achieve cross-talk cancellation, it is assumed that the listener will be placed at a particular position with respect to the loudspeaker pair, or the spatial information will not be properly perceived. The loudspeaker pair need to be positioned as a regular stereo setup, Left at -30 degrees and Right at +30 degrees.\n\n\nAn optimum listening position such as that needed for Transaural decoding, is also known as the Sweet Spot (see [_Listener Position_ -@listener-position]). It is a fundamental concept to be aware of as we move into the next section: Channel Based streams and panning algorithms."
  },
  {
    "objectID": "Spatialisation_Technology_Channel_Based_Streams.html",
    "href": "Spatialisation_Technology_Channel_Based_Streams.html",
    "title": "8  Channel Based Streams",
    "section": "",
    "text": "We have already covered the two-channels binaural stream type for monitoring and final encoding into a binaural format. One of the other important Stream Types is referred to as Channel Based. This stream can range from a single-channel mono to a multichannel audio stream (*). These streams will flow as a perfectly synchronized group through the signal graph defined in the Setup page. The channel count of the stream is set by the choice in the Speaker Arrangement pull down menu of a module. A change to the speaker configuration here alters the channel count in and out of a module, depending on its context in the signal graph. When you connect channel-based modules together in SPAT Revolution, they automatically inherit the speaker arrangement and channel count from the stream type at their connected input.\n\n\n\n\n\n\nWarning\n\n\n\n\nThe Essential license limits the total number channels to 32 input channels and to 18 outputs channels.\n\n\n\nChannel based audio streams - when connected to a hardware output module - will render the spatial composition on speakers connected to the physical outputs of your audio hardware. SPAT Revolution is expecting the loudspeaker system specified in the speaker arrangement of the Output module. If the real loudspeaker arrangement does not correctly match the speaker arrangement model or there is a mistake in your routing somewhere, the spatial sound image will then be compromised.\n\n\n\n\n\n\nWarning\n\n\n\nEach output channel must be routed to the correct speaker.\n\n\nThe golden rule for spatialization using channel-based audio is that each rendered channel must be connected only to its corresponding sound emitter in the destination system. An exact correlation from the model to the physical system is assumed by the calculations inside each of the panning algorithms. If the installation is not right for some reason, a listener may experience something with spatial aspects, but not with the intended quality. To correctly install and tune a multichannel sound system is one of the more challenging aspects of working with spatial composition and performance systems. So many things can compromise the spatial image, and sometimes it is hard to tell by ears.\nIn order to try and simplify this process in practice, certain labeling conventions are used by engineers and designers to identify which speaker belongs to which channel. When channel counts are high, angular positioning and distance measurements are used to identify the correct speaker routing. In SPAT Revolution’s Speaker Arrangement editor, you additionally get a 3D graphical rendering of the sound system, where you can select speakers which will be visually identified, so you can label them clearly. These labels will be saved into a speaker arrangement profile, so you can get some more consistent reference points when routing.\n\n\n\nLeft\nCentre\nRight\n\n\n\n\nLeft Surround\nLFE\nRight Surround\n\n\nLeft Back Surround\nCenter Back Surround\nRight Back Surround\n\n\nTop Back Left\nTop Front Center\nTop Back Right\n\n\nLeft Surround Rear\nVOG\nRight Surround Rear\n\n\nTop Front Left\nBack Center\nTop Front Left\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSome common speaker channel naming conventions.\n\n\n\nThe process of matching the correct channel to the correct speaker is absolutely vital to the successful rendering of the spatial composition from a SPAT Revolution Virtual Room into a physical space. Further critical points to a successful project are the choice of panning type in a Virtual Room and consideration of the Sweet Spot for listener positioning. As it is such an important and often misunderstood idea, let us take a look at that topic before going further."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#stereo-exclusive-panning-laws",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#stereo-exclusive-panning-laws",
    "title": "9  Panning Algorithms",
    "section": "9.1 Stereo-exclusive Panning Laws",
    "text": "9.1 Stereo-exclusive Panning Laws\n\nStereopan Law\nThis mode reproduces the basic experience of a pan pot. It comes with some options: + The pan law can follow a sin/cos approach or a square root. This produces a subtle difference in how the sound travel between the left and right speaker. + It is possible to change the center attenuation. By default, a sound placing at the center of the two speakers is played back with an attenuation of 3dB (considering acoustic summing). Other possible attenuation is : -4.5dB, -6dB. + The PMAP, Perceptually Motivated Amplitude Panning, aims at improving sound localization on stereo systems and on any pair speaker system with an arbitrary base angle.\n\n\nXY and AB\nThese two Panning Types will only become available when a Virtual Room is set to be virtualizing a stereo speaker arrangement. They are pan laws that are derived from widely used dual microphone techniques for rendering stereo imaging from an omnidirectional scene.\nAB panning simulates the recording of the sound scene by a pair of spaced cardioid microphones, pointing laterally at azimuths +/- 55 deg. (elevation 0), with a distance of 17 cm between the two capsules. Also known as ORTF.\nXY panning simulates the recording of the sound scene by a pair of microphones in a XY coincident configuration.\n\n\n\n\n\n\nNote\n\n\n\nThe aim is to get the same stereo flavor as these dual microphone tracking techniques. Try them on close miked sources or any mono source, to get a realistic stereo image."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#vector-base-amplitude-panning-vbap",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#vector-base-amplitude-panning-vbap",
    "title": "9  Panning Algorithms",
    "section": "9.2 Vector Base Amplitude panning (VBAP)",
    "text": "9.2 Vector Base Amplitude panning (VBAP)\nVector Base Amplitude Panning has become one of the more standardised methods for multichannel spatialization. It can reproduce on a 2D or 3D configuration. Its sound is characterised by clearly localizable virtual sound sources. Multiple moving or stationary sounds can be positioned in any direction over the speaker array using this method. In theory, VBAP can be used on an unlimited number of loudspeakers and can even be reliable on relatively asymmetric setups.\nHow does it work?\nTraditional VBAP works by manipulating the gain of the signals being routed to the two (in 2D), or three (in 3D), the closest speakers to a virtual sound source. VBAP relies heavily on an accurate speaker arrangement model to do this. It triangulates gain vectors mathematically in order to render a virtual object in the physical space and achieves its characteristic ‘sharp’ focus by using only a few speakers closest to the virtual source location. Additionally, it is possible to uniformly extend the traditional VBAP pair-wise (or triplet-wise) speaker picking and activate more of the sound system, effectively diffusing the relationship between individual speakers and sounds using spread.\n\n\n\n\n\n\nNote\n\n\n\nWiden a VBAP point source by increasing the Spread source parameter.\n\n\nThree important dependencies to consider when using VBAP:\n\nSpeakers must be placed around the listening position.\nSpeakers ideally should be equidistant from the listening position*.\n2D Speakers should be on the same horizontal plane as the ears.\nVBAP works best when the listening room is not very reverberant.\n\n*See the [Alignment -@speaker-editor-alignment] section: the speaker alignment feature provides the impression that the actual speakers are equidistant even when they are not."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#vector-base-intensity-vbip",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#vector-base-intensity-vbip",
    "title": "9  Panning Algorithms",
    "section": "9.3 Vector Base Intensity (VBIP)",
    "text": "9.3 Vector Base Intensity (VBIP)\nVector Base Intensity Panning is a similar variation to the VBAP technique. It can also reproduce a 2D or 3D immersive sound field with sharply localised virtual sound sources.\nHow does it work?\nVBIP was designed to improve on VBAP when calculating the high-frequency (above 700 hz) localisation criteria. The selection of which speakers to use to render a virtual sound source is similar to VBAP, only the gain calculations differ.\nThe same four dependencies mentioned for VBAP, also apply to VBIP. You will need to listen for quite a nuanced difference between these two panning algorithms. Try to compare how each panning type handles the higher frequency content of your material."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#dual-band-vector-based-panning-vbp-dual-band",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#dual-band-vector-based-panning-vbp-dual-band",
    "title": "9  Panning Algorithms",
    "section": "9.4 Dual Band Vector Based Panning (VBP Dual-Band)",
    "text": "9.4 Dual Band Vector Based Panning (VBP Dual-Band)\nBoth Intensity and Amplitude Vector Based panning have an ideal frequency range of action:\n\nLocalization of low frequencies is better with Amplitude Panning.\nLocalization of high frequencies is better with Intensity Panning.\n\nA hybrid approach of vector-based panning has been developed in this way: the Dual Band Vector Based Panning. This panning type merges the two approaches in order to combine the best of both worlds and to reach a better localization. Amplitude panning is applied below the crossover frequency, while the intensity panning is applied above. The crossover frequency has been defined to 700 Hz by default.\nThe dependencies mentioned in the VBAP section also apply to Dual Band Vector Based Panning."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#layer-based-amplitude-panning-lbap",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#layer-based-amplitude-panning-lbap",
    "title": "9  Panning Algorithms",
    "section": "9.5 Layer based amplitude panning (LBAP)",
    "text": "9.5 Layer based amplitude panning (LBAP)\nLayer based amplitude panning can be explained as multiple 2D VBAP layers: The speaker setup is split into several layers, depending on the speaker elevation. The panning used between speakers on the same layer is the VBAP 2D. Between these layers, a crossfade is applied between the two nearest layers.\n\n\n\n\n\n\nNote\n\n\n\nThe difference between VBAP 3D and LBAP is the number of speakers which will be active between the layers: three in VBAP versus four in LBAP."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#distance-base-angular-panning-dbap",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#distance-base-angular-panning-dbap",
    "title": "9  Panning Algorithms",
    "section": "9.6 Distance Base Angular panning (DBAP)",
    "text": "9.6 Distance Base Angular panning (DBAP)\nAs we mentioned earlier, there are a few panning algorithms that are not Sweet Spot dependent. Distance-base amplitude panning is one of them. DBAP is useful in a number of practical situations such as concerts, stage productions, installations and museum sound design where the predefined geometric speaker layouts which immersive sound fields rely on, are not possible to establish.\nDBAP was constructed with two assumptions: - All speakers are always active, independently of the source position. - The resulting level is independent of the source position.\nOnly level differences are used with this panning method.\nHow does it work?\nDBAP localizes sounds towards arbitrarily positioned speakers in a space using a matrix-based technique. It calculates signal amplitudes according to the actual positions of the speakers in a space, while making no assumptions as to where the listeners are situated. Speaker tuning and interesting acoustic features in a room should be more utilized when working with DBAP.\n\n\n\n\n\n\nNote\n\n\n\nSpeakers can be freely positioned when using DBAP - look for reflections and reverberations in a room to enhance spatial aspects."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#sec-panType-KNN",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#sec-panType-KNN",
    "title": "9  Panning Algorithms",
    "section": "9.7 K-Nearest Neighbor (KNN)",
    "text": "9.7 K-Nearest Neighbor (KNN)\nKNN is another panning type that does not depend on a Sweet Spot to be perceived correctly. It is a version of a ‘Nearest-neighbor’ interpolation algorithm. This family of algorithms are also used in the fields of complex systems, 3D graphics and network science to name a few. In SPAT Revolution, you can sonically explore a network of loudspeakers using this panning type and some virtual sound sources.\nHow does it work?\nAn interesting parameter of KNN is that the user gets manual control over one of the main coefficients in the underlying algorithm. The parameter is called Nearest Neighbor spreading. It sets a maximum limit to speakers number that the algorithm can use as neighbors. The parameter becomes available as a continuously variable percentage for each virtual source in a SPAT Revolution room.\n\n\n\nSource Spreading\n\n\nWhat makes this particularly interesting is that different sources can activate less or more of the sound system dynamically and in a very smooth way. For example, one virtual sound source might seem to pop in and out of individual speakers because its Nearest Neighbors Spread parameter is set a low percentage. For example, on a 10-speaker arrangement :1-10% will use 1 speaker, 11% to 20% 2, and so on. Another sound source could seem diffuse over the entire sound system, because its spread variable is set to 100%.\n\n\n\n\n\n\nNote\n\n\n\nTry automating the Nearest Neighbors Spread in a relationship with another source property of the same sound sources such as room presence."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#speaker-placement-correction-amplitude-spcap",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#speaker-placement-correction-amplitude-spcap",
    "title": "9  Panning Algorithms",
    "section": "9.8 Speaker-Placement Correction Amplitude (SPCAP)",
    "text": "9.8 Speaker-Placement Correction Amplitude (SPCAP)\nSPCAP is a 3D panning algorithm which takes its inspiration from VBAP. SPCAP selects not just 2 or 3, but any number of speakers to render a virtual source and weights signal gains according to how much each selected speaker is actually contributing to the overall power output of the speaker configuration. Using this method SPCAP guarantees conservation of loudspeakers power output across any speaker arrangement. Its strengths lie in the down-mixing and up-mixing of virtual scenes from very different channel-based speaker arrangements, and in being able to render wider sound sources by using more speakers in a smart way.\nHow does it work?\nThe result will still be Sweet Spot dependent, although it will be a wider listening area. SPCAP inherits some dependencies of VBAP to get successful spatial imaging.\n\nSpeakers must be placed around the listening position.\n2D speakers should be on the same horizontal plane as the ears.\n\n\n\n\n\n\n\nNote\n\n\n\n★ SPCAP panning can do a good job of translating surround audio mixes from one speaker configuration to another."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#ambisonic-equivalent-panning-aep",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#ambisonic-equivalent-panning-aep",
    "title": "9  Panning Algorithms",
    "section": "9.9 Ambisonic Equivalent Panning (AEP)",
    "text": "9.9 Ambisonic Equivalent Panning (AEP)\nIn common with the channel based panning types we have covered so far, Ambisonics is a technology that also distributes virtual sound sources in space. Yet it achieves this in a fundamentally different way. Ambisonics rely on a two-step process.\n\nEncoding Audio sources along with their positional information are wrapped up together using signal mathematics to create encoded Ambisonic audio. Ambisonic scenes are always carried on at least three channels of audio. They are not intended to be listened to directly they are intended to be decoded.\nDecoding Ambisonic audio signals are unwrapped and the positional information contained within them is decoded specifically for one type of speaker configuration. What we get is an immersive sound field that should accurately render the original spatial composition in 2D or 3D on the specified speaker configuration.\n\nKeeping these two steps separate has a number of advantages. Primarily, that of being able to record the encoded Ambisonic audio signals independently of any fixed speaker arrangement. On the other hand, it is possible to “fuse” the two stages of the process together resulting in what appears to be the output of a generalized channel based type of panning. That is the AEP panning type in a nutshell.\nHow does it work?\nAEP has certain computational and ambisonic mixing advantages and exhibits very different behavior from the VBAP/VBIP pairwise approaches. It is up to you to decide whether to work with pure Ambisonic rooms (more about that in the later section) or to use AEP as a channel based panning law. Both approaches are valid and could be useful. As we have mentioned a few times already, the choice of panning type depends on what sounds best in the context of your material, your compositional goals and the acoustics of the system you are working with."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#angular-and-panr",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#angular-and-panr",
    "title": "9  Panning Algorithms",
    "section": "9.10 Angular and PanR",
    "text": "9.10 Angular and PanR\nThese are legacy 2D pan pot laws from the original IRCAM Spat library. They only become available when using 2D channel based streams and are primarily included for backwards compatibility.\nHow does it work?\nAngular and PanR are pairwise amplitude panning essentially the same as VBAP 2D described on the next page. There is a subtle difference, however, in the way the panning law changes when moving the source from one speaker to another."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#continuous-surround-panning-csp",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#continuous-surround-panning-csp",
    "title": "9  Panning Algorithms",
    "section": "9.11 Continuous Surround Panning (CSP)",
    "text": "9.11 Continuous Surround Panning (CSP)\nThis Panning Type is available in Virtual Room with 5.0 speakers arrangements. It optimizes the render into this arrangement, using circular harmonics. This leads to a continuous law, independently of the angle.\nYou can find more explanation about it in the relative paper."
  },
  {
    "objectID": "Spatialisation_Technology_Panning_Algorithms.html#related-papers",
    "href": "Spatialisation_Technology_Panning_Algorithms.html#related-papers",
    "title": "9  Panning Algorithms",
    "section": "9.12 Related papers",
    "text": "9.12 Related papers\n\nVBAP 2D/3D (Vector Base Amplitude Panning)\n\n“[…] Using the method, vector base amplitude panning (VBAP), it is possible to create two- or three-dimensional sound fields where any number of loudspeakers can be placed arbitrarily. The method produces virtual sound sources that are as sharp as is possible with current loudspeaker configuration and amplitude panning methods.”\n\n\n“[…] the approach enables the use of an unlimited number of loudspeakers in an arbitrary two- or three-dimensional placement around the listener. The loudspeakers are required to be nearly equidistant from the listener, and the listening room is assumed to be not very reverberant. Multiple moving or stationary sounds can be positioned in any direction in the sound field spanned by the loudspeaker.”\n\n\n\nDBAP\n\n“[…] Most common techniques for spatialization require the lis-tener to be positioned at a Sweet Spot surrounded by loudspeakers. For practical concert, stage, and installation appli-cations such layouts may not be desirable. Distance-based amplitude panning (DBAP) offers an alternative panning-based spatialization method where no assumptions are made concerning the layout of the speaker array nor the position of the listener.”\n\n\n“[…] Distance-based amplitude panning (DBAP) is a matrix-based spatialization technique that takes the actual positions of the speakers in space as the point of departure while making no assumptions as to where the listeners are situated. This makes DBAP useful for a number of real-world situations such as concerts, stage productions, installations, and museum sound design where predefined geometric speaker layouts may not apply”\n\n\n\nAEP\n\n“[…] A further advantage of AEP is the possibility to use an arbitrary order of directivity for each individual sound source. It becomes possible to mix pre-recorded low order ambisonic B-format, medium order ambient sounds, high order precise localizable sound and sounds with changing localizability. How the individual sounds are perceived if different orders are used at the same time is an open question that can be answered only by experience.”\n\n\n\nPMAP\n\n“This paper proposes and evaluates a new constant-power amplitude-panning law named ‘Perceptually Motivated Amplitude Panning (PMAP)’. The method is based on novel image shift functions that were derived from previous psychoacoustic experiments. The PMAP is also optimised for a loudspeaker setup with an arbitrary base angle using a novel phantom image localisation model. Listening tests conducted using various sound sources suggest that, for the 60° base angle, the PMAP provides a significantly better panning accuracy than the tangent law. For the 90° base angle, on the other hand, both panning methods perform equally good. The PMAP is considered to be useful for intelligent sound engineering applications, where an accurate matching between the target and perceived positions is important.”"
  },
  {
    "objectID": "Spatialisation_Technology_WFS.html#introduction",
    "href": "Spatialisation_Technology_WFS.html#introduction",
    "title": "10  Wave Field Synthesis",
    "section": "10.1 Introduction",
    "text": "10.1 Introduction\nWave Field Synthesis, also known as WFS, is a technique for spatial audio reproduction. Unlike most of the traditional spatialization techniques, this technique does not depend on a phantom sound source (ie: the stereophonic principles allowing the creation of an acoustical illusion) to recreate an acoustic space.\nWFS aims to reproduce the true physical attributes of a given sound field (the waves front) over an extended area of the listening room. This approach relies on delay and amplitude differences.\nThe goal of WFS is to recreate the wavefront of a primary (or virtual) source synthesized by a large number of individually driven loudspeakers. Thus, this strategy implies a sampling of the original wavefront. This is a direct application of the Huygens’ principle, which states that every point on a wavefront is itself the source of spherical wavelets, and the secondary wavelets emanating from different points mutually interfere. The sum of these spherical wavelets forms the wavefront.\nUnder certain strict conditions, WFS can create the impression of a source positioned in front of the speaker system. This zone in front of a speaker line is referred to as the Focus Zone. That being said, the criteria are quite drastic to get this effect. Ircam states at least 32 speakers should be used with 15 to 20 cm spacing.\n\nAvailability - WFS Add-on license\n\n\n\n\n\n\nNote\n\n\n\nReferred to as a panning type in SPAT Revolution, the WFS spatial audio reproduction technique is available with the WFS Add-on license option, available with Ultimate and Essential version."
  },
  {
    "objectID": "Spatialisation_Technology_WFS.html#spat-revolution-implementation-of-wfs",
    "href": "Spatialisation_Technology_WFS.html#spat-revolution-implementation-of-wfs",
    "title": "10  Wave Field Synthesis",
    "section": "10.2 SPAT Revolution implementation of WFS",
    "text": "10.2 SPAT Revolution implementation of WFS\n\n\n\nWFS\n\n\nWhere traditionally WFS is used on a collinear array of very tightly spaced loudspeakers, SPAT Revolution allows for the use of the spatial audio reproduction technique on systems with greater spacing, in smaller loudspeaker quantity and potentially handling any type of 2D or 3D speaker arrangements.\n\n\n\nWFS\n\n\nThe panning method will become available to the room inspector as soon as a minimum of 5 loudspeakers are available.\n\n\n\n\n\n\nWarning\n\n\n\nEven if a large spacing between speakers is allowed, keep in mind that the greater the spacing you have, the less coherent the results will be.\n\n\n\n\n\nWFS Panning type\n\n\nThe chosen WFS implementation is a minimum latency approach. This simply means that the closest speaker to the source has no delay. In the focus zone, the same principle is used to keep the latency at its minimum.\n\nFocus Zone\nWhen using the WFS panning technique on a collinear frontal line arrangement, the Efficiency zone section in the room output section provides an option to activate the focus zone, i.e. the zone in front of a line of speakers. It is deactivated by default as it is recommended that a certain density and spacing exist for the speaker arrangement.\n\n\n\n\n\n\nWarning\n\n\n\nEnabling this option may trigger an Efficiency zone warning if the system does not respect the 0.4 meter spacing between speaker source elements recommendation.\n\n\n\n\n\nFocus zone Enable\n\n\n\n\n\nFocus zone warning\n\n\nAfter activating, it will extend the efficiency zone with a focus area starting at the listening reference thus allowing sources to freely move inside the listening area.\n\n\n\nFocus zone\n\n\n\n\nFurther readings\n\nGood introduction to WFS\nIRCAM website on WFS\nSound Scene Creation and Manipulation using Wave Field Synthesis"
  },
  {
    "objectID": "Spatialisation_Technology_WFS.html#wfs-settings",
    "href": "Spatialisation_Technology_WFS.html#wfs-settings",
    "title": "10  Wave Field Synthesis",
    "section": "10.3 WFS Settings",
    "text": "10.3 WFS Settings\n\n\n\nWFS Settings\n\n\nFLUX:: WFS implementation uses an interpolation strategy using a very precise calculation mode for delays values. This is to allow for a smooth transition with source movement rather than delay steps (inherent from digital audio). 6 parameters are available in the room inspector of the setup page, and can allow to fine-tune the WFS render\nDelay interp. time: The delay interpolation time is the time it will take to go from one delay value to another delay value. In WFS, interpolation time allows a smooth transition when a source is moved. Depending on your source content, and your scene movements, you may find this setting useful to modify.\nGain ramp time: Similar to the concept of delay interpolation time, the gain ramp time is the time it will take to transition from one set of gain values to another.\nDelay scaling: This parameter allows scaling the computed delays for all sources. It allows shaping the wavefront. Setting the delay scaling at 0% will set all delays to 0 ms, only the amplitude differences will remain.\nGain scaling: This parameter allows scaling of the computed gains for all sources. It is really useful on close WFS line, in order to spread the audio content all along the line or speaker setup, for front-fills for example. For example, you can decrease the percentage in order to activate more loudspeakers serving well audience sitting close to the loudspeaker line.\nuse PreFilter: A spectral correction in WFS systems called Pre-equalization. This parameter enables/disables a low-shelf filter in order to compensate for the low frequencies boost created by the speaker antenna.\nBlend distance: A 2.0-meter distance behind the speaker line is defined by default providing a transition zone as sources get closed to speakers and can help prevent some artifacts."
  },
  {
    "objectID": "Spatialisation_Technology_Scene_based_streams.html#sec-scenebased-introAmbi",
    "href": "Spatialisation_Technology_Scene_based_streams.html#sec-scenebased-introAmbi",
    "title": "11  Scene based streams",
    "section": "11.1 Introduction to Ambisonics",
    "text": "11.1 Introduction to Ambisonics\nSimply put: Ambisonics is a specific method for creating, capturing and playing back spatial audio. It is radically different from other surround techniques as the technology is capable of reproducing a spherical representation of sound where the directional information of a source is located in a 3D soundfield.\nAmbisonic is also both a recording and a spatial synthesis technique, where one can capture the full environment in 3D sound through the use of so called A-Format microphones such as the: Soundfield SPS200, Røde NT-SF1, Sennheiser Ambeo, Coresound TetraMic and more. Alternatively, a sound field can be synthesized from any mono, stereo and multichannel sources to Ambisonics, constructing a virtual 3D sound environment by placing the sources at locations in a virtual 3 dimensional field."
  },
  {
    "objectID": "Spatialisation_Technology_Scene_based_streams.html#encoded-audio",
    "href": "Spatialisation_Technology_Scene_based_streams.html#encoded-audio",
    "title": "11  Scene based streams",
    "section": "11.2 Encoded audio",
    "text": "11.2 Encoded audio\nAmbisonic, as opposed to other surround and spatial techniques and methods does not carry a speaker signal. It is an encoded audio signal that has to be decoded to listen on speakers. This encoding / decoding scheme has the advantage of being very portable and flexible since one is not tied to a specific speaker setup. i.e., you can have your ambisonic mix played on a number of speaker setups, for instance quad, headphones (binaural), 5.1, 6, 8, 7 speakers, etc. based on the chosen decoder.\nWhen Ambisonics is played back on speakers, all the speakers contribute to the directional content, what one is hearing is not the sound coming from a specific speaker but from a specific direction.\n\n\n\n\n\n\n\nNote\n\n\n\nOverview of a fifth-order HOA 3D Ambisonic File created by Tine Surell Lange."
  },
  {
    "objectID": "Spatialisation_Technology_Scene_based_streams.html#order",
    "href": "Spatialisation_Technology_Scene_based_streams.html#order",
    "title": "11  Scene based streams",
    "section": "11.3 Order",
    "text": "11.3 Order\nAmbisonics is a technology that encodes sound sources along with full-sphere positional information, as complex interleaved audio files that need decoding before they can be listened to on speakers. The lowest order, order 1, and the simplest form of 3D Ambisonics require 4 channels, conventionally named as:\n\nW (mono sum)\nX (X-axis information)\nY (Y-axis information)\nZ (elevation information)\n\nThe 4 channels or spherical components W, X, Y and Z can also be described as the pressure patterns found in an omni-microphone (W) and three figure-of-8 microphones for left/right (Y), front/back (X) and up/down (Z) as depicted in the above figure.\nHigh Order Ambisonics (HOA) needs more channels to contain the complex interleaved Ambisonics domain information. The components’ count increases with the order: WXYZUVSTRPQNOLMK… High Orders encode and decode into sharper and more accurate spatial information as the Order gets higher - but the number of channels needed to hold all the ‘spherical harmonics’ along with the serious computation involved increases quickly.\n3D full sphere HOA channel counts are defined by the function (n+1)^2 (where n is the Ambisonic Order).\n\n1st Order 3D -&gt; 4 Channels\n2nd Order 3D -&gt; 9 Channels\n3rd Order 3D -&gt; 16 Channels\n4th Order 3D -&gt; 25 Channels\n5th Order 3D -&gt; 36 Channels\n6th Order 3D -&gt; 49 Channels\n7th Order 3D -&gt; 64 Channels\n\nAmbisonics can also be encoded without elevation - this is called 2D horizontal and is quite suitable for decoding to configurations that do not have speakers on elevated planes. The 2 dimensional Ambisonic data is encoded in multichannel files with a channel count defined by the function 2n+1 (where n still is the Ambisonic order.\n\n1st Order 2D -&gt; 4 Channels\n2nd Order 2D -&gt; 5 Channels\n3rd Order 2D -&gt; 7 Channels\n4th Order 2D -&gt; 9 Channels\n5th Order 2D -&gt; 11 Channels\n6th Order 2D -&gt; 13 Channels\n7th Order 2D -&gt; 15 Channels\n\n\n\n\n\n\n\nWarning\n\n\n\nWith Essential license, 1st, 2nd and 3rd orders are only available."
  },
  {
    "objectID": "Spatialisation_Technology_Scene_based_streams.html#normalization-sorting-and-presets",
    "href": "Spatialisation_Technology_Scene_based_streams.html#normalization-sorting-and-presets",
    "title": "11  Scene based streams",
    "section": "11.4 Normalization, sorting and presets",
    "text": "11.4 Normalization, sorting and presets\nThese different components are organised according to different standards, known as sorting. The three most used are available in SPAT Revolution: - ACN: Ambisonic Channel Number, WYZXVTRSUQOMKLNP… - SID: Single Index Designation, WXYZUVSTRPQNOLMK… - FMH: Furse-Malham Harmonics, WXYZRSTUVKLMNOPQ…\nDifferent normalizations exist also with ambisonics. This normalization defines the relative level of the omni component compared to the other channels. It differs according to the dimension of the Ambisonics: - SN2D/SN3D: Schmidt-Seminormalized. - N2D/N3D: Fully-Normalized. - FuMa: Furse-Malham normalization.\nTo help with these different standards, we have created Ambisonics presets to simplify the use of it. These setups the normalization and sorting with common standards: - AmbiX: used for example by Youtube and Facebook 360. The normalization is SN2D / SN3D and the sorting ACN. - B-Format: the normalization is Fuma, and the sorting FMH. - SPAT Room: the normalization is N2D / N3D and the sorting ACN.\n\n\n\n\n\n\nWarning\n\n\n\nDo not forget to transcode the ambisonic input if the format is different from N2D/N3D and ACN."
  },
  {
    "objectID": "Spatialisation_Technology_Scene_based_streams.html#a-format",
    "href": "Spatialisation_Technology_Scene_based_streams.html#a-format",
    "title": "11  Scene based streams",
    "section": "11.5 A-Format",
    "text": "11.5 A-Format\n\nA-format is a 4-channel audio stream. It is the RAW output of a first-order ambisonic microphone, so it has not been encoded to ambisonic yet. So we need to transcode a A-Format input to an HOA or a channel-based stream. Because each manufacturer has their own strategy to create such microphone, we have almost as many transcoder as A-format microphone builder. SPAT Revolution comes with a comprehensive list of A-Format transcoder, including Sennheiser Ambeo, Soundfield, DPA, Oktava etc."
  },
  {
    "objectID": "Spatialisation_Technology_Scene_based_streams.html#history-and-references",
    "href": "Spatialisation_Technology_Scene_based_streams.html#history-and-references",
    "title": "11  Scene based streams",
    "section": "11.6 History and references",
    "text": "11.6 History and references\nAmbisonics was originally developed by the late British mathematician and sound engineer Michael Gerzon and others in the 1970s. Although it was a commercial failure at the time, this very powerful spatial technique has since been advanced greatly by a number of composers, sound designers and researchers. With the introduction of Virtual Reality, fast decoders and related technology, Ambisonics is getting a new renaissance being a perfect format for such applications.\nIf you want to learn more about Ambisonics and its mathematical foundation here are some good starting points:\n\nhttps://www.researchgate.net/publication/280010078_Introduction_to_Ambisonics\nWikipedia article about normalization and sorting\nFrank Zotter’ book about Ambisonics"
  },
  {
    "objectID": "Spatialisation_Technology_Ambisonic_transcoding.html#default-transcoding",
    "href": "Spatialisation_Technology_Ambisonic_transcoding.html#default-transcoding",
    "title": "12  Ambisonic Transcoding",
    "section": "12.1 Default transcoding",
    "text": "12.1 Default transcoding\nWhen patching an HOA or B-Format input to a source, or a HOA room to a channel-based output, a transcoder will be automatically inserted. This transcoder will, by default, be set to the Ring or Sloane speaker arrangement corresponding to the HOA order, and, will select an AllRad decoder.\n\n\n\n\n\n\nNote\n\n\n\nRing and Sloane are uniform setups which are recommended for optimized transcoding. I will guarantee a precise localization, in particular when transcoding an ambisonic input in order to use it in a room."
  },
  {
    "objectID": "Spatialisation_Technology_Ambisonic_transcoding.html#transcoding-method",
    "href": "Spatialisation_Technology_Ambisonic_transcoding.html#transcoding-method",
    "title": "12  Ambisonic Transcoding",
    "section": "12.2 Transcoding method",
    "text": "12.2 Transcoding method\n\nProjection\nProjection decoding is also sometimes called “sampling ambisonic decoding” (SAD). It is the simplest form of ambisonic decoding. It samples the virtual panning function at the loudspeaker directions. SAD is optimal for loudspeakers arranged as t-design layouts, with t ≥ (2N+1) ( N being the Ambisonics order). Typically, the SAD should only be used for 2D loudspeaker layouts, i.e., regularly arranged in a circle. Avoids this decoder for 3D setups.\nWhat is a T-Design Layout?\nTo keep it really simple, t-design is a mathematical way of constructing sphere perimeters or circle surfaces with an array of point that is homogenous. In 2D the point simply put on a circle and are evenly spaced. In 3D, things get much more complicated many t-design point layouts exist. In SPAT Revolution, we chose to use the method used by the mathematician Sloane for our speaker layouts.\n\n\nRegularized pseudo-inverse\nThe pseudo-inverse decoder, or “mode-matching decoder” (MMAD), is suitable for both 2D and 3D. It is based on a pseudo-inverse of the re-encoding matrix. MMAD is well-behaved for regular loudspeaker arrangements. It can also give good results with slightly irregular setups. However, it can become unstable with strongly irregular setups, i.e., it can completely blow up the speaker feeds. So, be careful.\n\n\nThe regularized pseudo-inverse decoder or “regularized-mode-matching decoder” (RMMAD) is somehow similar to MMAD. However, it uses a regularization factor for stabilization of the pseudo-inverse. This regularization factor (alpha) varies from 0% to 100%. A value of 0% provides results similar to MMAD. A value of 100% generates even energy distribution, i.e., results similar to EPAD. Intermediate values of alpha allow to “blend” MMAD and EPAD.\n\n\nEnergy preserving\nEPAD (energy preserving ambisonic decoding) and AllRAD (All-round Ambisonic decoding) are other HOA decoding methods suitable for 2D and 3D HOA, and they can cope with any kind of loudspeaker arrangement. These decoding methods always work, as soon as there are enough loudspeakers; they are always feasible and by nature numerically stable. EPAD uses a regularized matrix inversion such that the decoded energy is preserved even with non-uniformly arranged arrays (and even for directions with only sparse loudspeaker coverage). EPAD is the default method in spat5 (and the one we usually recommend).\n\n\nAllRAD\n“All-round Ambisonic decoding” (AllRAD) is designed in two steps. First, an optimal virtual loudspeaker layout using t-design arrangement is considered (for which the SAD is optimal). Secondly, the signals of these virtual loudspeakers are mapped to the real loudspeakers via VBAP.\n\n\nImproved AllRAD\n“Improved All-Round Ambisonic Decoding” (AllRAD+) combines AllRAD and SAD. Constant energy that is achieved for the idealized virtual loudspeaker setup in AllRAD is corrupted by the VBAP stage as, per loudspeaker pair, all virtual sources are superimposed linearly instead of energetically. The prevailing linear superposition increases the energy wherever the loudspeaker spacing is large. Roughly, at such directions AllRAD doubles the energy, whereas it is halved at directions with dense loudspeaker spacing. Conversely, SAD might lose all energy where the loudspeaker spacing is large and roughly doubles it where the loudspeaker spacing is dense. AllRAD+ tries to solve this issue by combining (i.e., mixing) SAD and AllRAD. The loudness variation of AllRAD+ is competitive with EPAD and its angular mapping resembles AllRAD."
  },
  {
    "objectID": "Spatialisation_Technology_Ambisonic_transcoding.html#transcoding-types",
    "href": "Spatialisation_Technology_Ambisonic_transcoding.html#transcoding-types",
    "title": "12  Ambisonic Transcoding",
    "section": "12.3 Transcoding types",
    "text": "12.3 Transcoding types\nTo improve the ambisonic render, there are some strategies that can be applied at the decoding stage. The idea is to optimize the phase or the energy to improve the sound localization.\n\nBasic\nThis is the standard way to decode ambisonic, and no optimization is applied.\n\n\nInPhase\nThe audio content will be optimized in phase for the all spectrum.\n\n\nMaxRe\nThe energy of the audio content will be optimized, for the all spectrum.\n\n\nBasicMaxRe\nThe low end of the audio content is not optimized, but a MaxRe method is applied to the high end. The crossover frequency is by default set to 700 Hz.\n\n\nMaxReInPhase\nThe low end of the audio content is optimized in energy (MaxRe), but a in phase method is applied to the high end. The crossover frequency is by default set to 700 Hz.\n\n\nInPhaseMaxRe\nAs phase optimization is more efficient in the low frequencies, and energy optimization is prominent in the high frequencies, this method takes this phenomenon to its advantage by splitting the signal in two frequency bands. The crossover frequency is by default set to 700 Hz and can be adjusted."
  },
  {
    "objectID": "Spat_Environment.html",
    "href": "Spat_Environment.html",
    "title": "SPAT Environment",
    "section": "",
    "text": "This section will go through the SPAT Revolution software environment in more detail. We will step through each of the main Graphic Editor views.\n\nRendering to Speakers\nIn order for the virtual scene to translate correctly as an immersive sound experience in a speaker format, SPAT needs to have an accurate model of a multichannel speaker arrangement which will be used to map the multichannel information to the destination speakers and render the sound field correctly in a real space. To this end, you will find a large library of standard and specialized speaker arrangements already built into SPAT which can be used in various places throughout the Environment Setup.\nSpeaker configurations can be used to fit the format of a virtual room to match the actual speaker system being used to diffuse the mix in a real room. Channel based speaker configurations can also be used to transcode the format of a virtual source into a virtual room. More about this later.\nThe golden rule when working with multichannel based audio is that you must be sure to choose exactly the right formats, speaker arrangements and channel routing throughout; otherwise the virtual space will not map correctly into a physical space.\nVirtual and Real Diffusion\nSuccessful diffusion of a sound field in space relies on every loudspeaker being assigned correctly to each software rendered output channels.\nA diffusion system could range from a simple pair of headphones to a 18 (Essential) or unlimited (Ultimate) speakers array and anything in between. In some of the more virtualized workflows of SPAT Revolution, you may even be thinking about diffusion in a virtual space on configurations of virtual speaker arrangements and channel based formats. The same rule for successful diffusion applies here—the diffusion in the virtual room will be compromised and sound off if the channel assignments to the virtual systems are incorrect.\n\nIn the above illustration, a virtual 5.1 and a virtual Cube arrangement exist together in a High Order Ambisonic Room, which may eventually be rendered to some other channel based end format."
  },
  {
    "objectID": "Spat_Environment_Home_Page.html#welcome-box",
    "href": "Spat_Environment_Home_Page.html#welcome-box",
    "title": "13  Home Page",
    "section": "13.1 Welcome box",
    "text": "13.1 Welcome box\n\nThis simple box lets you access to basic action of session management.\n\nCreate Session\nCreate a session with a wizard to set up the routing.\n\n\nNew session from empty\nCreate an empty session, without calling the wizard.\n\n\nOpen a session\nLet you open a session from a disk."
  },
  {
    "objectID": "Spat_Environment_Home_Page.html#recent-sessions",
    "href": "Spat_Environment_Home_Page.html#recent-sessions",
    "title": "13  Home Page",
    "section": "13.2 Recent Sessions",
    "text": "13.2 Recent Sessions\n\n\nThis box lists the latest open session in SPAT Revolution. You can open one by double-clicking on it."
  },
  {
    "objectID": "Spat_Environment_Home_Page.html#resources",
    "href": "Spat_Environment_Home_Page.html#resources",
    "title": "13  Home Page",
    "section": "13.3 Resources",
    "text": "13.3 Resources\n\nThis box gives you direct access to many resources related to SPAT Revolution: - This documentation - DAW templates for using LAP: Ableton Live, Apple Logic Pro X, Avid ProTools, Steinberg Nuendo, Merging Technologies Pyramix - OSC templates, which include a lemur template and a QLab example session - Live console templates: S6L, Digico and SSL - Examples of various scripts"
  },
  {
    "objectID": "Spat_Environment_Global_Bars.html#navigation-bar",
    "href": "Spat_Environment_Global_Bars.html#navigation-bar",
    "title": "14  Global Bars",
    "section": "14.1 Navigation bar",
    "text": "14.1 Navigation bar\n\nThe Navigation bar appears at the top of all views. As well as links to different editor views and to the preference, it also offers you the possibility to mute and unmute rooms.\nThe status and help bars appear at the bottom of all views. It gives information about the status of audio connections, sample rate, block size and through latency. Some inline help also appears here when the mouse moves over elements of the SPAT Revolution graphical user interface. The Provide feedback button sends a message directly to FLUX:: Immersive support which automatically includes your system information for our support team."
  },
  {
    "objectID": "Spat_Environment_Global_Bars.html#status-bar",
    "href": "Spat_Environment_Global_Bars.html#status-bar",
    "title": "14  Global Bars",
    "section": "14.2 Status bar",
    "text": "14.2 Status bar\n\nThe status bar help you easily monitor many critical information about your hardware and your incoming or outgoing audio stream.\n\nInput stream\nAllows monitoring the good reception of audio through LAP. + When “No connection” is displayed, this means that no SPAT Send plug-in with LAP enabled is seen by SPAT Revolution. + When a connection is validated, it should provide a timecode, corresponding to the DAW transport position. + If the sample rate or block size is unmatched between SPAT Revolution and the DAW used, the “all in sync” mention will turn red and count the sync errors.\n\n\nHardware device\nThis section helps you monitor your audio hardware and how it interacts with SPAT Revolution.\n\nYou can see the name of your input & output device.\nThe block size and sample rate of SPAT Revolution.\nThe whole latency of the system. This depends on the block size and on the selected audio interfaces. Using different audio interfaces can result in a higher latency.\n\n\n\nTimecode source\nHere, you can choose which timecode SPAT Revolution should look at.\n\nBy default, it is set to “Absolute”. It refers to the clock of your computer, no matter of the connection with an audio interface or with LAP streams.\n“LAP Send” looks at the clock provided by SPAT Sends plug-ins.\n“LAP Return” looks at the clock provided by SPAT Returns plug-ins.\n“Audio hardware” looks at the clock provided by the selected audio interfaces.\n\n\n\nTimecode\nLet you monitor the timecode seen by SPAT Revolution. For proper operation of snapshots and automations, it should be always running.\n\n\nClock source\nChoose what clock SPAT should follow. + Internal. + Hardware. + Auto : use hardware if one is connected. \n\n\nSupport\nAllows to send feedback to the FLUX:: Immersive support team.\n\n\n\n\n\n\nNote\n\n\n\nWith Send/Return plug-ins, if sampling rate and block size between DAW and SPAT Revolution are different, the status bar will be red. Double-click on this bar to automatically change them into SPAT Revolution."
  },
  {
    "objectID": "Spat_Environment_Global_Bars.html#snapshot-bar",
    "href": "Spat_Environment_Global_Bars.html#snapshot-bar",
    "title": "14  Global Bars",
    "section": "14.3 Snapshot bar",
    "text": "14.3 Snapshot bar\n\n\n\nSnasphot toolbar\n\n\nThis toolbar has been designed to help to handle snapshots without navigating to the snapshots page. Some of the most important snapshot actions will be found on it: - Recall the Previous snapshot. - The name of the Current snapshot. Clicking on it will display the snapshot list, enabling to recall any snapshot of the list. - Recall the Next snapshot. - Update the current snapshot. - Enable or disable the Relative Recall. - Propagate values between snapshots.\nThis bar can be hided on the snapshot panel of the Preference page.\n\n\n\n\n\n\nNote\n\n\n\nMore information about snapshot can be found on the [snapshots page -@snapshot]."
  },
  {
    "objectID": "Spat_Environment_Setup_Page.html#setup-modules",
    "href": "Spat_Environment_Setup_Page.html#setup-modules",
    "title": "15  Setup Page",
    "section": "15.1 Setup Modules",
    "text": "15.1 Setup Modules\nThe Environment Setup editor is a modular environment. The signal flow starts from the inputs at the top of the graph and concludes with the outputs at the bottom. You add modules to rows using the small + icon to the left of the window. Modules are:\n\nInputs 16\nInput Transcoders 17\nSources 18\nRooms 18\n[Sums -@source-room-modules-master-section]\n[Master Transcoders -@source-room-modules-master-section]\n[Masters -@source-room-modules-master-section]\n[Binaural Monitors -@source-room-modules-master-section]\n[Outputs -@source-room-modules-output-section]"
  },
  {
    "objectID": "Spat_Environment_Setup_Page.html#stream-types-and-associated-options",
    "href": "Spat_Environment_Setup_Page.html#stream-types-and-associated-options",
    "title": "15  Setup Page",
    "section": "15.2 Stream types and associated options",
    "text": "15.2 Stream types and associated options\nModules blocs are characterized by their stream type. In spatial audio, audio streams can be of different natures, as seen in the [Spatialisation Technology -@spat-technology] section.\nStream types and their options are :\n\nChannel-based : most common used bloc where one channel correspond to one speaker or one microphone.\n\nSpeaker arrangment : allow to select the channel configuration of the bloc.\n\nHOA : generic ambisonic bloc.\n\nOrder : select the ambisonic order from 1 to 7.\nDimension : select between a 2D or 3D sound scene.\n\nA-Format : pre-encoding ambisonic stream (raw ambisonic microphone output).\nB-Format : deprecated, prefer a 3D HOA first order bloc.\nUHJ : special 3D first order ambisonic stream meant for archiving and stereo compatibility.\nMS : Mid-side.\nBinaural : headphone oriented render using HRTF.\nTransaural : binaural decoding on speaker."
  },
  {
    "objectID": "Spat_Environment_Setup_Page.html#the-graph-editor",
    "href": "Spat_Environment_Setup_Page.html#the-graph-editor",
    "title": "15  Setup Page",
    "section": "15.3 The graph editor",
    "text": "15.3 The graph editor\nThe modular graph editor handles basic mouse editing.\n\nModule selection\nModules can be select by clicking on them. To select several ones, hold Ctrl/Cmd while clicking on additional modules. It is also possible to use a marquee selection by left-clicking, holding the button, and dragging the mouse over the modules you want to select.\n\n\nDrag & Drop\nThe drag and drop feature allows an easy and ergonomic way to connect and reorganize modules in the setup page.\nConnect modules\n\n\n\nConnect blocs with drag & drop feature\n\n\nTo create a connection between two modules, simply drag one on the other. SPAT will automatically connect the two modules. If it is necessary, SPAT will also create supplementary modules if needed. For example, if we drag and drop an input on a room, SPAT will automatically create a “source” block between them.\n\n\n\nAuto-connect blocs with drag & drop\n\n\nThis feature also works on a selection of multiple modules of the same type. For example, if we wished to connect 5 inputs to 1 output, we can select our inputs a drag them on the output. All the input modules will be patched to a room block through sources, and the room is a patch to the output through a master block, with the default stereo room that can be changed later.\n\n\n\nQuick setup using drag & drop\n\n\nReorganize modules\nThe drag and drop feature also allows reorganizing the modules of the same type. This means that you can now change the order of already created modules. This gives to the setup page a more ergonomic and flexible feel.\n\n\n\n\n\n\nWarning\n\n\n\nImportant to note that this will be changing the index number of the source. So be careful with automation already created. This is specific to OSC like using the plugins with OSC where the index is important. Not the case with software sources/inputs which use a different ID system."
  },
  {
    "objectID": "Spat_Environment_Setup_Page.html#the-setup-wizard",
    "href": "Spat_Environment_Setup_Page.html#the-setup-wizard",
    "title": "15  Setup Page",
    "section": "15.4 The setup wizard",
    "text": "15.4 The setup wizard\nIn our effort to make SPAT Revolution easier to use, we created a small utility to help you set up new SPAT sessions. This is used mainly when dealing with hardware I/O.\nTo open it, you can either:\n\nClick on the Setup Wizard button in the top menu of the Setup page;\nGo to the main menu, into setup, then “Setup Wizard”;\nOr, use ALT + W (the shortcut is not working in Windows).\n\n\n\n\nOpening the Setup Wizard\n\n\nThe top part of the setup wizard allows to create a new room (with associated options) or to select an existing room to patch new sources into. If a new room is created, we can choose its stream type and many options linked to it. We can also choose to associate a binaural monitoring block to it (virtualizing the room output). Lastly, for each new room created, a master block and an output block is also created.\nThe main part of the wizard allows creating up to 8 different types of sources. It works like a table where each line can be used for a specific input stream type. To add or remove a line, simply click on the + or - sign on the left side of a line. You can also use the shortcut Ctrl/Cmd + Go Down or Ctrl/Cmd + Go Up.\n\n\n\nSetup Wizard in action 1/2\n\n\nOther shortcuts have been implemented in this wizard: - Go up and Go down to increase / decrease the number of sources - Go Left or Go Right to change the Stream Type. - Ctrl/Cmd + Go Left or Ctrl/Cmd + Go Right to change the format (if Channel Based), or the Dimension (if HOA). - Ctrl/Cmd + Shift + Go Left or Ctrl/Cmd + Shift + Go Right to change the Order (if HOA).\nWhen we are done creating out different sources, we have two ways to validate the operation. We can either click on Ok, all the sources, rooms and outputs will be created, with a straight routing, or, we can choose to click on Ok +  matrix. This last option will open the input and output matrix of our whole SPAT Revolution session to allow us to quickly customize or validate our patch. Also, if you need to easily create a line in SPAT matrix, simply hold Ctrl and click on the starting point of your line.\n\n\n\nSetup Wizard in action 2/2"
  },
  {
    "objectID": "Spat_Environment_Setup_Page.html#action-menu",
    "href": "Spat_Environment_Setup_Page.html#action-menu",
    "title": "15  Setup Page",
    "section": "15.5 Action menu",
    "text": "15.5 Action menu\nThis menu handles basic operation of modules, like connecting, disconnecting and renaming. Some of these actions are contextual, and depend on the block, or the number of modules selected.\n\n\n\n\n\n\nWarning\n\n\n\nNote that there is no undo in SPAT Revolution. Think twice before operating and save regularly.\n\n\n\nRemove selected\nRemove the selected modules.\n\n\nDuplicated selected\nDuplicate the selected modules.\nRoom duplication\n\nSPAT Revolution allows to quickly duplicate a room with a few options to help the user to optimize the routing process. To access this menu, simply click on the Duplicate Selected button, when only a room selected.\nThe new pop-up windows allows to: * Rename the duplicated room * Choose if the sources routed to the original room are routed the new one, or duplicated, or nothing is patched. * Choose if the outputs of the original rooms are duplicated, mirrored or nothing is done to the duplicated room.\n\n\n\nConnect selected\nConnect selected modules. Modules can be connected to multiple destinations.\n\n\n\n\n\n\nNote\n\n\n\nSPAT Revolution will always try to guess what you try to achieve. For exemple, you can connect an input block directly to an output block and SPAT will create necessary modules in-between.\n\n\n\n\nDisconnect selected\nDisconnect both inputs and outputs of the selected modules.\n\n\nDisconnect selected inputs\nDisconnect connected inputs of selected modules.\n\n\nDisconnect selected Output\nDisconnect connected outputs of selected modules. ### Disconnect between selected\nDisconnect the connections between selected modules."
  },
  {
    "objectID": "Spat_Environment_Setup_Page.html#routing-matrix",
    "href": "Spat_Environment_Setup_Page.html#routing-matrix",
    "title": "15  Setup Page",
    "section": "15.6 Routing Matrix",
    "text": "15.6 Routing Matrix\nAs you can imagine routing and patching high density channel counts can get complicated. When it comes to that, the SPAT routing matrix is there to help. You will find it at many points throughout the Environment Setup graph.\n\n\n\nOutput Matrix\n\n\n\n\n\n\n\n\nNote\n\n\n\nAvoid cable swapping on the loudspeaker setup, use software routing instead.\n\n\nThe routing matrix is available on hardware input and output for routing as well as for remapping within some modules input and output: Input transcoder, Master, and Master transcoder.\nThe speaker configuration editor, a clear channel labeling and the built-in routing matrix system all help to make the process of signal routing, checking and debugging more straightforward on location, in the virtual mix and in the studio.\n\n\n\n\n\n\nNote\n\n\n\nThe shortcut Ctrl + click will route one per one all the following channels.\n\n\nMaster transcoder and master matrix support summing, thus, one input can be connected to several outputs, or the opposite."
  },
  {
    "objectID": "Spat_Environment_Input_Modules.html#name",
    "href": "Spat_Environment_Input_Modules.html#name",
    "title": "16  Inputs Module",
    "section": "16.1 Name",
    "text": "16.1 Name\nAllows to edit the name of an input. It is possible to edit several names at once by selection several blocs and clicking on the “Input Name Wizard” button in the inspector."
  },
  {
    "objectID": "Spat_Environment_Input_Modules.html#inputs-configuration",
    "href": "Spat_Environment_Input_Modules.html#inputs-configuration",
    "title": "16  Inputs Module",
    "section": "16.2 Inputs configuration",
    "text": "16.2 Inputs configuration\n\nInput type : allow to select if the source of the signal is coming from the selected input or from the signal generator included in SPAT Revolution. The nature of the generated signal can be changed in the Preference page 39.\nInput stream : allow to select the stream type of the bloc.\n\n\n\n\n\n\n\nNote\n\n\n\nInput stream types are : channel-based, HOA, A-Format, B-Format, UHJ, MS, Binaural and Transaural.\n\n\nFor more options related to stream type, check the Setup Page 15 section."
  },
  {
    "objectID": "Spat_Environment_Input_Modules.html#routing",
    "href": "Spat_Environment_Input_Modules.html#routing",
    "title": "16  Inputs Module",
    "section": "16.3 Routing",
    "text": "16.3 Routing\nGive access to the routing matrix\n\n\n\n\n\n\nWarning\n\n\n\nThis option is only available on hardware input."
  },
  {
    "objectID": "Spat_Environment_Input_Modules.html#levels",
    "href": "Spat_Environment_Input_Modules.html#levels",
    "title": "16  Inputs Module",
    "section": "16.4 Levels",
    "text": "16.4 Levels\nBasic true peak metering for each block’s channels."
  },
  {
    "objectID": "Spat_Environment_Input_Modules.html#delay",
    "href": "Spat_Environment_Input_Modules.html#delay",
    "title": "16  Inputs Module",
    "section": "16.5 Delay",
    "text": "16.5 Delay\nEach input comes with a delay which can be useful: - in live situation, to compensate delay between microphones. - in studio situation, to compensate the plugins delay when using Local Audio Path.\nThe delay can be set in samples, milliseconds, or distance unit (meters if metric system, feet otherwise). This can be chosen on the Global panel of the Preferences page."
  },
  {
    "objectID": "Spat_Environment_Input_Transcoder_Modules.html#transcoding-matrix",
    "href": "Spat_Environment_Input_Transcoder_Modules.html#transcoding-matrix",
    "title": "17  Input Transcoder",
    "section": "17.1 Transcoding Matrix",
    "text": "17.1 Transcoding Matrix\n\nIn the case where an incoming Channel Based stream needs transcoding into an outgoing Channel Based stream which has fewer channels, the IO Matrix is used to remap the output format by dropping some input channels. This is not strictly Transcoding or decoding but is a useful tool to have in a certain format changing scenarios. This matrix does not give the possibility to up-mix or down mix. To properly up mix or down mix, it is advisable to use a room to take the virtual source of one format, and output with the desired end format."
  },
  {
    "objectID": "Spat_Environment_Input_Transcoder_Modules.html#when-to-transcode-inputs",
    "href": "Spat_Environment_Input_Transcoder_Modules.html#when-to-transcode-inputs",
    "title": "17  Input Transcoder",
    "section": "17.2 When to Transcode Inputs?",
    "text": "17.2 When to Transcode Inputs?\nThe main reason you will need to transcode inputs is when you are mixing and spatializing inputs in a SPAT Revolution Virtual Room. This is because the Virtual Room module requires incoming sources to be in a Channel Based format. Internally, the Room may well be panning in Channel based, Ambisonics or binaural format, but it always needs Channel Based streams as inputs. More about this in the Virtual Room section. Format transcoding may not always need re-spatializing in a room. There are some contexts where you will not use a Virtual Room in the signal flow,\n\nHere is an example of decoding an ambisonic signal using an input transcoder module. This could also be done in the master transcoder section of the graph.\nAs mentioned in Section 11.1, a decoding stage is absolutely necessary to render Ambisonics encoded audio to speakers. It can be done like this without the need of a room."
  },
  {
    "objectID": "Spat_Environment_Input_Transcoder_Modules.html#aggregation-of-input",
    "href": "Spat_Environment_Input_Transcoder_Modules.html#aggregation-of-input",
    "title": "17  Input Transcoder",
    "section": "17.3 Aggregation of input",
    "text": "17.3 Aggregation of input\nAs some DAW does not support multichannel tracks, SPAT Revolution provides on the input transcoder a way to aggregate stereo or mono input in order to make multichannel sources.\nTo do it, connect several inputs on the same input transcoder or source and select on it the wanted format. When selecting it, a combobox “Aggregate Input” will appear, and will allow to aggregate all the inputs.\n\n\n\nInput aggregation\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe order of the channel is determined by the connection order to the input transcoder or source."
  },
  {
    "objectID": "Spat_Environment_Source_Room_Modules.html",
    "href": "Spat_Environment_Source_Room_Modules.html",
    "title": "18  Sources & Rooms Module",
    "section": "",
    "text": "19 Name\nAllow renaming a room."
  },
  {
    "objectID": "Spat_Environment_Source_Room_Modules.html#source-module",
    "href": "Spat_Environment_Source_Room_Modules.html#source-module",
    "title": "18  Sources & Rooms Module",
    "section": "18.1 Source module",
    "text": "18.1 Source module\nSources’ modules are very important and quite unique ones. This is where the object-oriented mixing of SPAT Revolution takes in.\nSources’ modules associated metadata to incoming audio streams. Because of their object-oriented nature, they can only input and output channel-based streams. In practice, this means you cannot patch, for example, an ambisonic stream to a room, even if the room in question is ambisonic itself. It first needs to be transcoded by using and input transcoder.\nThe so-called metadata is the source parameters, such as position and reverberation information. All these parameters are explained in the section Source properties 26.\nOne source can be connected to several rooms. This is one of the advantages of the object-based mixing: it allows to create different mixes in different formats with the same exact information.\n\nName\nAllows renaming a source. By default, it takes the name of the input patched into it.\n\n\nIO Configuration\nAllows selecting the speaker arrangement used by the source. It can be selected from the list or user defined.\nMulti-channel sources is one of the unique SPAT Revolution features.\n\n\n\n\n\n\nNote\n\n\n\nIf you struggle to understand why we talk about speakers at this stage, simply consider them as “virtual” speaker that will be emitting in a “virtual” room.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nA source can and should only be channel-based!\n\n\n\n\nTracking\nSPAT Revolution is able to receive data from RTTrPM open protocol tracking systems. This protocol is supported by BlackTrax™. BlackTrax™ is a vision-based system that connects to different third-party applications, such as robotic lights, media servers and SPAT Revolution. OSC is the other very good method to use for tracking, and various tracking systems support it natively.\n\n\n\n\n\n\nWarning\n\n\n\nRTTrPM protocol is not available with the Essential license of SPAT Revolution.\n\n\nWhen you have correctly set up the BlackTrax protocol (see BlackTrax Integration section 58) then you can directly assign Tracking Number to virtual sources, and also to listener position (see Listener position section 5) for advanced virtual reality interactive audio projects.\n\n\nGain\nChange the input gain of the source.\n\n\nLevels\nBasic true peak metering for each block’s channels."
  },
  {
    "objectID": "Spat_Environment_Source_Room_Modules.html#room-module",
    "href": "Spat_Environment_Source_Room_Modules.html#room-module",
    "title": "18  Sources & Rooms Module",
    "section": "18.2 Room module",
    "text": "18.2 Room module\nIf sources are where localization information is stored, rooms are where the “interpreting” happens. A room is defined by two main criteria: its output stream type and its reverberation. Simply, a room module look at all the information stored in sources and then act as a renderer for a given format.\n\n\n\n\n\n\nWarning\n\n\n\nIt is a classic case of object-based mixing, where source modules associate metadata to channels, and room modules interpret them.\nOnly source modules can be connected to room modules.\n\nThe first thing to notice is that we can add any number of rooms. In the screenshot above, two HOA 3D rooms are being used, each with differently designed acoustics. SPAT revolution offers flexibility, in order to encompass different workflow ideas or experimental approaches. For example, the same virtual sources may be assigned into multiple rooms, with multiple end destinations. Or as in the screenshot above, virtual sources might exist in different spaces that get summed together.\nThe Essential license limits the number of active (processed) rooms to one (1). The other are deactivated (not processed)."
  },
  {
    "objectID": "Spat_Environment_Master_Section_Modules.html",
    "href": "Spat_Environment_Master_Section_Modules.html",
    "title": "19  Master Section",
    "section": "",
    "text": "The Sum row of modules is used to mix the output of two or more rooms of the same output configuration and in some contexts, to sum inputs directly without the use of room.\n\nThe Sum module can handle different input configurations. It will Sum channels based on their channel names, so a correct naming convention is important. Summing a 5.1 and 7.1 rooms together will output a 7.1 where their common L, C, R, Left and Right Surround rear channels will have content summed from both rooms the but Left and Right Back surround will be only from the 7.1 room.\n\n\n\n\n\n\nNote\n\n\n\nSumming can also be done directly in Master and Output Modules, but summing into a Sum module will save resources if the same sum is performed in different blocks.\n\n\nThe Master Transcoder row of modules offers an opportunity to consolidate the various formats you might have been mixing into one (or more) formats for final output routing by the Output modules. The same options and routing are available as in the Input Transcoder modules 17.\nThe Master bloc gives you a last gain staging control, as well as down mixing capabilities. When opening its matrix, it is possible to patch several inputs to one output, or, one input to several outputs.\n\n\n\nMaster matrix\n\n\nFinally, the Binaural Monitoring 6.5 row provides a way to decode the whole scene to headphones only in binaural 3D."
  },
  {
    "objectID": "Spat_Environment_Output_Modules.html",
    "href": "Spat_Environment_Output_Modules.html",
    "title": "20  Output",
    "section": "",
    "text": "The main thing to note at the output stage is that you can have any number of output routes. Like the [Inputs -sec-input-modules], they may be either direct hardware routes, which returns audio streams (via matrix routing) to the physical outputs of an audio interface connected to your SPAT Revolution workstation. The Hardware Output workflow is the most direct way to render in realtime to an actual loudspeaker system (or headphones).\n\n\n\n\n\n\nWarning\n\n\n\nSoftware outputs are created by the instantiation of a SPAT Return plug-in in a compatible DAW, when its local audio path is set to “on”.\n\n\nOutputs may also be linked to SPAT Revolution RETURN plug-ins, which returns audio streams internally on the same workstation to a valid SPAT RETURN plug hosted in your DAW. The software RETURN workflow offers an easy way to render the spatial scene to disk, as Ambisonic encoded, Binaural encoded or Sound system encoded multichannel audio.\n\n\n\n\n\n\nNote\n\n\n\nCreate multiple output routes to capture Ambisonic recordings at the same time as sound system specific rendering."
  },
  {
    "objectID": "Spat_Environment_Modules_channel_count.html#mono-input",
    "href": "Spat_Environment_Modules_channel_count.html#mono-input",
    "title": "21  Modules Channel Count",
    "section": "21.1 Mono Input",
    "text": "21.1 Mono Input\nA one channel audio stream is always treated as a mono signal. It will appear in a Virtual Room as one positionable virtual source with its own directivity and parameters. In many ways, mono signals are the most straightforward format to work with in a spatial composition. This is because a one channel signal discretely contains all its acoustic and spectral properties without inter-channel dependencies, such as those found in a wide stereo image, for example. In practice, such point sources are easier to localise and balance spatially with others.\n\n\n\n\n\n\nNote\n\n\n\nMono sources are simple to work with when balancing a spatial mix."
  },
  {
    "objectID": "Spat_Environment_Modules_channel_count.html#two-channel",
    "href": "Spat_Environment_Modules_channel_count.html#two-channel",
    "title": "21  Modules Channel Count",
    "section": "21.2 Two Channel",
    "text": "21.2 Two Channel\nA two-channel audio stream will appear in the Virtual Room as two mono sources linked together as a group. A two-channel audio input will already open a few more choices for disambiguating the configuration. SPAT needs to know what format the two channels are in, so it knows how to correctly handle the audio stream later in the signal flow.\n\nChannel Based Treated as Normal stereo\nMid-Side (MS) Treated as Mid Side encoded stereo\nBinaural / Transaural Treated as encoded 3D stereo"
  },
  {
    "objectID": "Spat_Environment_Modules_channel_count.html#four-channel-input",
    "href": "Spat_Environment_Modules_channel_count.html#four-channel-input",
    "title": "21  Modules Channel Count",
    "section": "21.3 Four Channel Input",
    "text": "21.3 Four Channel Input\nThe next significant channel count that needs disambiguation from the user is a four-channel stream.\n\nA four-channel stream could contain the format of a four-speaker Channel Based formats (QUAD, 4.0, LCRS) but could also contain different formats of interleaved four-channel Ambisonic audio (A-Format, B-Format). You can read more about A-Format and B-Format in the [Ambisonics -@scene-based] section of this user guide. The important thing to remember here is that confusing Ambisonic audio and Channel Based audio is a significant mistake, even though you might hear something ‘wide sounding.’\n\n\n\n\n\n\nWarning\n\n\n\nDo not confuse multi-channel-based audio formats with multichannel Ambisonic audio formats. They may have the same channel counts but are completely different!"
  },
  {
    "objectID": "Spat_Environment_Modules_channel_count.html#multi-channel-based-input",
    "href": "Spat_Environment_Modules_channel_count.html#multi-channel-based-input",
    "title": "21  Modules Channel Count",
    "section": "21.4 Multi-Channel Based Input",
    "text": "21.4 Multi-Channel Based Input\nAny input module configured to represent a stream of multichannel audio can be configured as a Speaker Arrangement format which would require that number of channels, as a minimum. For example, DTU 7.1 needs 8 channels, and DTU 5.1 needs 6. Auro3D 13.1 needs 14 channels. Unfortunately, things can get complicated in practice, as there are a few variations of standardised speaker layouts which have the same number of channels and seem very similar - but need disambiguation. This is important to get right, and will depend a lot on the context of your project and on changing standards in the audio industry. For example, at least four different 7.1 routing standards are to be found ‘in the wild’ and it’s important to know which one you are actually dealing with. Often, for example, the so-called low-frequency effects channel in cinema surround formats, is not always on the same channel.\n\n\n\n\n\n\nWarning\n\n\n\nEssential license of SPAT Revolution limits total number of channels to 32 input channels and to 18 output channels.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTry to stick to industry standard channel naming conventions throughout a cinematic surround sound project.\n\n\n\n\n\nL\nC\nR\n\n\n\n\nsL\n\nsR\n\n\nsurround Left\n\nsurround Right\n\n\nLFE\n\n\n\n\nLow Frequency Effects\n\n\n\n\nsbL\n\nsbR\n\n\nsurround back Left\n\nsurround back Right\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nSome common Speaker Channel naming abbreviations."
  },
  {
    "objectID": "Spat_Environment_Modules_de_activation.html#create-and-edit-a-session-in-essential-version",
    "href": "Spat_Environment_Modules_de_activation.html#create-and-edit-a-session-in-essential-version",
    "title": "22  Session compatibility and modules (de)activation",
    "section": "22.1 Create and edit a session in Essential version",
    "text": "22.1 Create and edit a session in Essential version\nAny type of session can be created and edited with SPAT Revolution Essential version. This includes the opening and editing of Ultimate sessions with Essential version. However, due to license restrictions, the blocks that do not fit the restrictions are automatically deactivated, and thus not processed. If the block deactivation is due to a license restriction, the deactivation reason appears in the block’s configuration panel on the Setup page:\n\nIt is possible to manually activate/deactivate blocks on the block inspector of the Setup page:\n\nEvidently, if a block has been deactivated for license limitations reasons, the block cannot be manually activated."
  },
  {
    "objectID": "Spat_Environment_Modules_de_activation.html#opening-an-ultimate-session-with-essential-version",
    "href": "Spat_Environment_Modules_de_activation.html#opening-an-ultimate-session-with-essential-version",
    "title": "22  Session compatibility and modules (de)activation",
    "section": "22.2 Opening an Ultimate session with Essential version",
    "text": "22.2 Opening an Ultimate session with Essential version\nIf a session contains non-authorized objects or configurations, the concerned blocks are deactivated and the session behavior is the same as described in the “Create and edit a session in SPAT Essential” section above."
  },
  {
    "objectID": "Spat_Environment_Modules_de_activation.html#opening-an-essential-session-with-ultimate-version",
    "href": "Spat_Environment_Modules_de_activation.html#opening-an-essential-session-with-ultimate-version",
    "title": "22  Session compatibility and modules (de)activation",
    "section": "22.3 Opening an Essential session with Ultimate version",
    "text": "22.3 Opening an Essential session with Ultimate version\nIf a session contains inactive blocks that could be activated, a dialog offers to activate them:"
  },
  {
    "objectID": "Spat_Environment_Modules_de_activation.html#check-essential-compatibility-in-spat-revolution-ultimate",
    "href": "Spat_Environment_Modules_de_activation.html#check-essential-compatibility-in-spat-revolution-ultimate",
    "title": "22  Session compatibility and modules (de)activation",
    "section": "22.4 Check Essential compatibility in SPAT Revolution Ultimate",
    "text": "22.4 Check Essential compatibility in SPAT Revolution Ultimate\nIn the Menu File, click on the Check Essential Compatibility item to check if the current session is compatible with the Essential version restrictions. A dialog then informs of the compatibility.\n \nIf the session is not compatible, it can be opened in Essential version but the non-authorized objects will be automatically deactivate (see paragraph “Create and edit a session in SPAT Revolution Essential” above).\n\n\n\n\n\n\nNote\n\n\n\nThe blocks contained in an Ultimate session can be manually deactivated to fit the Essential version restrictions. The check for compatibility answers that the session is compatible."
  },
  {
    "objectID": "Spat_Environment_Modules_de_activation.html#essential-compatibility-mode-for-ultimate-version",
    "href": "Spat_Environment_Modules_de_activation.html#essential-compatibility-mode-for-ultimate-version",
    "title": "22  Session compatibility and modules (de)activation",
    "section": "22.5 Essential Compatibility Mode for Ultimate version",
    "text": "22.5 Essential Compatibility Mode for Ultimate version\nWhen in Ultimate version, a Compatibility Mode allows it to behave as an Essential version (see paragraph “Create and edit a session in SPAT Essential” above). \nIf the current session is compatible with Essential version a dialog informs the user:"
  },
  {
    "objectID": "Items_Page.html#items-type-selection",
    "href": "Items_Page.html#items-type-selection",
    "title": "23  Items’ page",
    "section": "23.1 Items type selection",
    "text": "23.1 Items type selection\nThe upper left list control allows to choose which kind of items you want to display in the Items’ Page.\n\n\n\nItems’ selection"
  },
  {
    "objectID": "Items_Page.html#parameters",
    "href": "Items_Page.html#parameters",
    "title": "23  Items’ page",
    "section": "23.2 Parameters",
    "text": "23.2 Parameters\nDepending on the selected item’s type, the editable parameters are the following.\n\nCommon parameters\nFor all items, the items’ page allows quick edition of:\n\nNumber: the item number order of the list.\nName: edit this field to change the name of the item.\nActive: define if the item is computed or not. If the item is inactive due to license restriction, the field cannot be edited.\n\n\n\nInput specific parameters\nIn addition to the common parameters, when the Input item’s type is selected, the Items’ Page shows:\n\nType: displays if the input is Live input or Signal generator.\nSpeaker arrangement: select the speaker arrangement of the input.\nDelay (smp): define the input delay in sample.\nDelay (ms): define the input delay in ms.\nDelay (meters): define the input delay in meters.\nDelay (feets): define the input delay in feets.\nConnected: displays if the input is connected to other items.\n\n\n\n\nItems page for sources\n\n\n\n\nSource specific parameters\nIn addition to the common parameters, when the Source item’s type is selected, the Items’ Page allows quick edit of:\n\nColor: select the color of the source.\nRoom: list the rooms’ names the source belongs to. The rows can be grouped by rooms. See Group sources by rooms below\nSpeaker arrangement: select the speaker arrangement of the source.\nRemote: define if the source can be controlled by OSC or not.\nRemote number: define the index of the source on OSC side. If set to 0, the remote number is equal to the source number. Careful with this behavior: this will be edited with the source order.\nAutomation: define if the source can be controlled by automation via Local Audio Path.\nSnapshot: define if the source can be controlled by snapshot recall.\nRTTrPM number: define the RTTrPM beacon number used for control this source. If set to 0, the tracking will be disabled. Ultimate license only.\nGain: define the gain of the source.\nMute: define the mute status of the source.\n\n\n\n\nItems page for sources\n\n\n\n\nRoom specific parameters\nIn addition to the common parameters, when the Room item’s type is selected, the Items’ Page shows:\n\nConnected sources: displays the number of connected sources.\nSpeaker arrangement: select the speaker arrangement of the room. For HOA and Binaural room, this field displays respectively the dimension and the HRTF.\nPan law: select the pan law of the Room, if stream type is Channel-Based or Binaural. For HOA room, this field displays the HOA order.\nReverb enable: define if the reverb is enabled in this room.\nProtection zone width: define the width of the protection zone 29.1.\nEfficiency zone: select the wanted behavior when a source is out of the efficiency zone 29.3 of the room.\nScaling distance: define the [scaling distance] of the room in meters.\nTracking scaling: define the tracking scaling of the room in meters.\n\n\n\n\nItems page for rooms"
  },
  {
    "objectID": "Items_Page.html#navigation",
    "href": "Items_Page.html#navigation",
    "title": "23  Items’ page",
    "section": "23.3 Navigation",
    "text": "23.3 Navigation\nIn order to give an easy navigation on this page and its parameters, keyboard shortcuts have been implemented, including powerful multi-selection and edition.\n\nUp: select the cell of the previous row.\nShift + Up: add the previous row to the row selection.\nDown: select the celle of the next row.\nShift + Down: add the next row to the row selection.\nShift + click: select all the rows in between the two selected\nCtrl + click: select only the wanted rows.\nLeft key: select the previous cell.\nRight key: select the next cell.\nSpace on an on/off button: it will toggle the button for the actual selection.\nEnter (return) on a string or float edit, or a list: it will begin the edit of the selected cell. Using it a second time will edit the cell of the next row.\nHome: go to the first row.\nEnd: go to the last row.\nPage Up: select the cell on the previous page.\nPage Down: select the cell on the next page.\n\nIt is also possible to sort the items according to a specific field, shift-clicking on the header of it."
  },
  {
    "objectID": "Items_Page.html#filtering-and-group-by",
    "href": "Items_Page.html#filtering-and-group-by",
    "title": "23  Items’ page",
    "section": "23.4 Filtering and Group by",
    "text": "23.4 Filtering and Group by\nTo go further in easing the edition of parameters, the Items’ page allows to filter of the displayed data. Moreover, for sources, they can be grouped according to the rooms they belong to.\n\nFiltering\nEnter text in the top search field to filter the displayed objects. This will search on all the field. To search for a specific field, type the name of the field and add “:”. For example, to search the object with the name beginning by “Violin”, type name:Violin.\n\n\nGroup sources by rooms\n\n\n\nGroup by rooms"
  },
  {
    "objectID": "Spat_Environment_Snapshot_Page.html#the-snapshot-list",
    "href": "Spat_Environment_Snapshot_Page.html#the-snapshot-list",
    "title": "24  Snapshots page",
    "section": "24.1 The snapshot list",
    "text": "24.1 The snapshot list\n\nGenerality\n\n\n\nSnapshot list\n\n\nThe snapshot list is the main section of snapshot management and serves many purposes. First, it displays the snapshot organization of your session. The snapshot name can also be edited by clicking on the text field. To recall a snapshot from the snapshot list, simply double-click on the number of one of them.\n\nSnapshot selection\nA snapshot can have different states. First, it can be selected or unselected inside the list. It will serve to make a specific action on the selected snapshot(s) and reveals the versions’ history and inspector section (if only one is selected). The state of selection is a graphical element that let the user know on which snapshot an action is performed.\n Unselected snapshot\n Selected snapshot\n\n\nSnapshot activation and deactivation\nA snapshot can also be disabled using the dedicated toggle. A disabled snapshot will be darkened in the list. It cannot be recalled. The next and previous snapshot buttons on the snapshot toolbar will automatically skip a disabled snapshot.\n Activated snapshot (1) VS. deactivated snapshot (2)\n\n\nCurrent snapshot\nLastly, the last recalled snapshot is displayed with the “current” field set on. This allows the user to monitor where he is in his show.\n In-play snapshot (2) VS. not-in-play snapshot (1)\n\n\n\nThe actions\n\n\n\nAction bar\n\n\nThis snapshot list’s top bar regroups all the snapshot actions:\n\nNew allows creating a new snapshot, storing the current sources, rooms and masters state.\nDuplicate allows duplicating the current snapshot selected in the snapshot list.\nUpdate allows updating the selected snapshot in the snapshot list with the current state of the session. It will create a new snapshot version.\nRemove allows deleting the snapshot(s) selected in the snapshot list.\nMove up moves the selected snapshot(s) up one row in the snapshot list.\nMove down moves the selected snapshot(s) down one row in the snapshot list.\nRecall allows loading a previously saved snapshot selected in the snapshot list.\n\n\n\n\n\n\n\nWarning\n\n\n\nKeep in mind that source with “Snapshot” parameter set off will be stored, but not recalled. Please check the “item page” section for more information.\n\n\n\n\nSnapshot Index\nTo recall through OSC a snapshot, the name or the index is required. As snapshot order can be changed, the snapshot index does not depend on the snapshot position in the list. The snapshot index is indicated on each snapshot, on the left side of the recall options.\n\n\n\nSnapshot index\n\n\nIt is possible to generate new indexes for all the snapshots according to list order. To do so, click on the menu Snapshot/Reindex all snapshots.\n\n\nRecall options\nRecalling a snapshot will use four different options: - The timing is the transition time between the current session state and the session state recalled from a snapshot. This allows smoothing out the transition between two scenes and can also be used to create some movements. - The source option defines if the sources state should be recalled. This refers to the sources’ position and other properties. - The room option defines if the rooms’ state should be recalled. This refers to the reverb parameters of rooms and also the listener head. Be careful with this as some parameters of the reverberation can’t be recalled without sound dropping. - The master option defines if the masters’ state should be recalled. This refers to the master level output.\n\n\n\n\n\n\nNote\n\n\n\nBy default, only sources’ properties are recalled from snapshots. If only some parameters are recalled, the whole session is stored on the creation of a snapshot.\n\n\n\n\nUsing global options or override them\nThe snapshot list exposes the four global recall options on its top right corner : the recall timing, the sources recall option, the rooms recall option and the masters recall option. These parameters affect each snapshot with global options activated.\nBeside each snapshot, there is a checkbox, under a column named “Global options”. If the checkbox is checked, the default values of the recall preferences refer to the global values. If the checkbox is unchecked, it will override the global preferences and use the specific recall values for the snapshot.\n\n\nRelative recall option\nRelative recall is an option of the recall function. It allows recalling a snapshot while preserving anything that was offset from the previous state. This can help to prevent technical problems during a show.\nHere is an example: let’s say you have two snapshots, A and B. Sources inside your project have different gains between the two snapshots: 0 dB for the snapshot A, -5 dB for the snapshot B. Now, let’s presume that once the show is started, you feel that one of the sources is too quiet (the singer preserves his voice). So you grab the gain parameter and trim by 4 dB. The “Relative recall” function will preserve this offset to any of the future recalled snapshot. Recalling snapshot B will set the gain of the singer to -1 dB instead of -5dB. This allows a perfect blend of live mixing and preparation work."
  },
  {
    "objectID": "Spat_Environment_Snapshot_Page.html#version-history",
    "href": "Spat_Environment_Snapshot_Page.html#version-history",
    "title": "24  Snapshots page",
    "section": "24.2 Version history",
    "text": "24.2 Version history\n\n\n\nSnapshot version history\n\n\nIn this panel takes place a very powerful feature. For each snapshot, SPAT Revolution automatically stores the last versions. By default, ten versions are stored. It is possible to increase or decrease this number on the Snapshot panel of the Preferences page. Of course, you can recall any of this ten previous state, remove one.\nAn entry in the version history has for indication its creation date and time. To describe the version, you can insert a custom note.\nThe Active field allows choosing which version will be used when the snapshot is recalled. Only one version can be activated.\nA set of actions is presented on the top: - A previous snapshot version can be recalled by clicking on the Recall button. The recalled version will be indicated by the Current field. - Versions can be deleted, clicking on Delete. - All versions excluding the selected one(s) can be deleted, clicking on Delete all other versions."
  },
  {
    "objectID": "Spat_Environment_Snapshot_Page.html#inspector",
    "href": "Spat_Environment_Snapshot_Page.html#inspector",
    "title": "24  Snapshots page",
    "section": "24.3 Inspector",
    "text": "24.3 Inspector\nThe inspector lets you visualize the difference between the current state of your session and the selected snapshot, and selected version of a snapshot.\nIt allows an easy monitoring of what was changed and how it was changed.\n\n\n\nInspector\n\n\nSelect the snapshot you want to compare, and click on the Show differences, or use the shortcut Ctrl + D on Windows, Command + D on macOS.\nYou can group the list by an object name or a property name, or research for objects or properties."
  },
  {
    "objectID": "Spat_Environment_Snapshot_Page.html#propagate-through-snapshots",
    "href": "Spat_Environment_Snapshot_Page.html#propagate-through-snapshots",
    "title": "24  Snapshots page",
    "section": "24.4 Propagate through snapshots",
    "text": "24.4 Propagate through snapshots\nIn order to edit a large number of snapshots, a propagation system has been implemented into the new Snapshot Page.\nThere are two possibilities to propagate values: - Propagate the differences between the current state and the current snapshot.\nThis behavior happens by clicking on the Propagate button located on the Snapshot bar, or on the top of the snapshot list of the Snapshot Page. - Propagate the differences between the current state and the selected snapshot and version. It is deeply linked to the Snapshot inspector. The Propagate differences action is located on it.\nIt is possible to propagate the selected differences or all the differences (if no differences are selected). To select differences, use Ctrl + Click on Windows, or Cmd + Click on macOS to add several items, or Shift + Click to select all between two items.\n\nPropagate dialog\n\n\n\nInspector\n\n\nOn the propagate dialog, the selected data will be retrieved, displaying the absolute value which can be applied when validating on Propagate absolute values and the trim value which will be added to each snapshot value when validating with Propagate trim values.\n\n\n\n\n\n\nNote\n\n\n\nFor example, if my Accordion has an azimuth value of 50.0, it will become 13.475 propagating with absolute value, and 50.22 propagating with trim value.\n\n\nOn the left panel, the snapshot list is displayed in order to choose the snapshot for which the propagation will be applied.\n\n\n\nInspector\n\n\nOn the right panel, the differences are displayed. It is possible to select them in order to filter which ones will be propagated. Do not select rows for propagate all the values."
  },
  {
    "objectID": "Spat_Environment_Room.html#top-bar-menu",
    "href": "Spat_Environment_Room.html#top-bar-menu",
    "title": "25  Room",
    "section": "25.1 Top bar menu",
    "text": "25.1 Top bar menu\nThis menu allows changing what elements and how they are displayed in the 3D view.\nPresence Infos:\nDisplay the presence factor as a green vector. The brighter it is, the more present the source is. When off, green vector is no more drawn.\nReal Pos. Infos:\nIn some very specific cases, the position of source in the DSP may be different that the one you set up. When on, the DSP position is also displayed.\n\n\n\n\n\n\nNote\n\n\n\nTo understand better what these two first options do, consult the “Understanding the mixing zones 29” section.\n\n\nSource Infos:\nDisplay the name of source even if it is not selected.\nSpeaker Infos:\nDisplay the name of the speakers.\nScale:\nMake the elements bigger of smaller for adjust ease of sight.\nShininess:\nChange the shininess aspect of the graphical elements.\nLightness:\nChange the brightness of the graphical elements.\nNebula Alpha:\nChange the transparency of the Nebula spectral analyzer.\n\n\n\n\n\n\nNote\n\n\n\nWhen set to 0%, Nebula does not take any resources at all.\n\n\nConsult the “Nebula Spatial Spectrogram 36” section for more information.\nNebula Quality:\nConfigure the quality factor of nebula.\n\n\n\n\n\n\nNote\n\n\n\nChanging this factor will significantly change the performances.\n\n\nSpeaker Alpha:\nChange the transparency of the speakers.\nListener Alpha:\nChange the transparency of the listener head.\nGrid type:\nToggle between polar or cartesian grids.\nDisplay Output:\nAllows to display the nebula of a difference setup module, connected to this room. This is useful if you want to see the decoding of an ambisonic stream inside an ambisonic room for example.\nBackground color:\nChange the background color.\nView:\nChoose if the 3D view is seen from: + The top + The front + Or a split view : top and front"
  },
  {
    "objectID": "Spat_Environment_Room.html#display-output-drop-down",
    "href": "Spat_Environment_Room.html#display-output-drop-down",
    "title": "25  Room",
    "section": "25.2 Display output drop-down",
    "text": "25.2 Display output drop-down\nLocated on top of the 3D view, the “display output” drop-down allows choosing which point of the signal path to display.\nFor example, working in an HOA room create 3D view that does not show any speaker. This is because of the very nature of how ambisonic work. But it also means that you cannot use Nebula in that kind of room. This is where this “display output” feature becomes handy. Instead of showing the actual HOA scene, it is possible to choose to look at the sound scene at the transcoding stage to see what happens with Nebula on the speaker array."
  },
  {
    "objectID": "Spat_Environment_Room.html#room-output-parameters",
    "href": "Spat_Environment_Room.html#room-output-parameters",
    "title": "25  Room",
    "section": "25.3 Room output parameters",
    "text": "25.3 Room output parameters\n\nOutput list\n\nThis panel lists all the speakers used in the room (when set to channel based). It allows quick access to the speaker arrangement editor and to the compute function. Each output has a “test” button that sends the signal from the signal generator directly the routed speaker. The signal generator type and level are set in the Preferences page 39.\n\n\nListener\n\nThis panel gives access to the listening point. We can change its position, using the X, Y, Z parameters, and its rotations using Yaw, Pitch, Roll.\n\n\nProtection Zone\n\nThis panel controls the behavior and size of the protection zone. By default, it is set to a diameter of four meters. Please check out the section named Understanding the mixing zone 29 if you want more information about the protection zone. Note that the protection zone is attached to the listener position.\n\nSource fit speakers elevation\nSource over listener head\nWidth\n\n\n\nEfficiency Zone\n\nThis panel contains options related to the efficiency zone.\n\nClamping behavior option (consult the Understanding the mixing zone 29 section for more information)\nDepth - change the depth of the efficiency zone\nTrunc (available only for non-surrounding 2D speakers’ setup) - change the starting distance of the efficiency zone\n\n\n\nScaling\n\n\nDistance\nThis parameter scales all the distance automation (OSC, plugins data and snapshots) by a manual factor. This factor is adapted automatically when editing the arrangement of the room.\n\n\nTracking\nThis parameter changes the scale of RTTrPM protocol data.\n\n\n\nBackground Image\n\nThis panel allows you to import a background image in SPAT Revolution and to position it in the 3D view.\n\n\n\n\n\n\nWarning\n\n\n\nMake sure to have no special character in the path or file name."
  },
  {
    "objectID": "Spat_Environment_Source.html",
    "href": "Spat_Environment_Source.html",
    "title": "26  Source",
    "section": "",
    "text": "27 Barycentric Groups\nWhen a Source in a Room has more than one channel in its format, it will be represented as a single source with ONE unique index. It will be visualized as a group in its assigned channel based speaker arrangement.\nIn the above screenshot, the red source consists of 5 channels arranged as a DTU 5.0 surround sound configuration. A multichannel cluster can be conveniently positioned and manipulated as a single group which maintains its correct internal spatial positioning relationships but moves in relation to the absolute listener position in the Room (the Dummy Head). The dot at the center of each cluster, where each virtual “channel emitter” is attached, is called the “BaryCentric” focus — In other words, a relative listener position that the virtual source configuration remains focused on.\nThese complex spatial positioning algorithms are computed and controlled in real time using SPAT Revolution’s advanced Barycentric and relative direction source parameters. A group that may contain many elements can be transformed, scaled, moved and manipulated in complex ways, through only one set of controls. See dedicated section for a breakdown of the Source Parameters 27."
  },
  {
    "objectID": "Spat_Environment_Source.html#basic-interactions",
    "href": "Spat_Environment_Source.html#basic-interactions",
    "title": "26  Source",
    "section": "26.1 Basic interactions",
    "text": "26.1 Basic interactions\n\nReset to defaults\nA double click on any Source Parameter dial will reset it to a SPAT default setting. The default setting of a parameter is indicated around a dial as a larger tick than the other tick marks. Additionally, a range is graphically indicated between the default setting and the current setting of a variable parameter.\n\n\n\n\n\n\n\nNote\n\n\n\n★ Use the defaults as points of reference in your spatial sound design.\n\n\n\n\nPreset Memories\nEach parameter has the possibility to store useful preset settings of your own choosing. Right-click on a parameter dial, and a contextual menu will pop up. From there you can store the current setting to a Memory Slot, or Recall a setting from a previously saved memory slot."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#room-specific-gain",
    "href": "Spat_Environment_Source_Parameters.html#room-specific-gain",
    "title": "27  Source Parameters",
    "section": "27.1 Room specific gain",
    "text": "27.1 Room specific gain\n\nNew on the 22.02 build, this parameter allows to trim the source gain on each room. A source can so have a different level for each room, which can be useful for monitor, musician headphone monitor, N-1, …\nOnly the parameter dedicated to the current room will be displayed, but it’s possible to display all the specific gains using the filter and selecting “Room gain”."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#sec-sources-parameters-perceptual-factor",
    "href": "Spat_Environment_Source_Parameters.html#sec-sources-parameters-perceptual-factor",
    "title": "27  Source Parameters",
    "section": "27.2 Perceptual Factors",
    "text": "27.2 Perceptual Factors\n\nThis parameter group holds settings affecting the way the sources direct and reverberated acoustic properties are perceived by the listener.\nAs touched on previously, these are not simply names stuck onto a single internal parameter dictated by the inner workings of the algorithm. Instead, a true perceptually oriented approach is used in the design, where a test panel of listeners is presented with a test-set of sounds, constructed from several variations of the reverb engine inner parameters. The listeners are then asked to rate each set onto a few different scales with perceptually and aesthetically meaningful names. Using principal component analysis (PCA) and optimization techniques, we then built an algorithm which reverses the process and automatically maps a given set of perceptual factor values to the many internal reverb engine parameters.\nAs a general guideline, we encourage you to learn the meaning of these parameters by carefully listening to the audible characteristics when adjusting them. We do provide a short explanation of each of them below, but training your ears is really the best way to be able to use these in context.\n\nPresence\nSource’s presence refers to the prominence of the direct sound with respect to the reverberated sound. It is not just equivalent to a dry/wet ratio, and is influenced by other settings such as distance, radius and drop factor.\n\n\nWarmth\nPresence of the low frequency content part of the source.\n\n\nBrillance\nPresence of the high frequency content part of the source.\n\n\nRoom Presence\nProminence of the reverberation with respect to the source, or in other words, how much the room sound dominates the overall sound.\n\n\nRunning Reverberance\nThis parameter controls the amount of perceived reverb when feeding a continuous music message, where the overall sound is a tight blend of the dry and wet signals and the reverb part cannot be mentally separated. It is linked to the early reflections decay time of the SPAT Revolution Reverb engine. N\n\n\n\n\n\n\nNote\n\n\n\nThis setting is not the same as the ‘reverberance’ in the Reverb Properties.\n\n\n\n\nEnvelopment\nEnvelopment corresponds to the perceived notion of how much the listener feels that they are surrounded or immersed by the ambient sound. In a multichannel configuration, one could describe this as the feeling of being wrapped inside the imaginary “sound sphere” that the listener pictures in her mind. It can also be described as the energy of the early room effect with respect to direct sound."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#reverb-options",
    "href": "Spat_Environment_Source_Parameters.html#reverb-options",
    "title": "27  Source Parameters",
    "section": "27.3 Reverb Options",
    "text": "27.3 Reverb Options\n\n\nReverb Enabled\nToggle whether a source will use the reverberation engine.\n\n\nEarly / Cluster / Tail\nToggle whether a source will use only some or all of the different reverberation stages.\nEarly refers to Early Reflections stage of the Room response which is one of the most significant stages involved in our rapid aural perception of spatial properties and sound source localization.\nCluster refers to a secondary iteration of room response reflections and is quite significant in the cognition of room acoustics.\nTail refers to the diffuse reverberations that eventually decay in a direct relationship with the size and reflectivity of an acoustic space. The tail section of a reverb dœs not contribute much to the localizability of a sound source in a space, but instead gives a sense of depth and ambiance.\n\n\nPanRev\nBy default, only early reflections are panned, and the cluster reflections, which form the diffuse part of the early reverberation, are panned dead center. PanRev allows you to modify cluster panning, thus imparting some directionality or perceived direction to the diffuse part of the sound.\n\n\nEarly Width\nControls the width of the sound projection lobe of the early reflections from a source in the virtual acoustic space, in degrees. The minimum setting, 1°, gives a very directional source, whereas 180° makes it omnidirectional."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#axis-omni-filters",
    "href": "Spat_Environment_Source_Parameters.html#axis-omni-filters",
    "title": "27  Source Parameters",
    "section": "27.4 Axis / Omni Filters",
    "text": "27.4 Axis / Omni Filters\n\nThese two spectral processors can be considered as being equalizers that have been especially designed for virtual sound emitters simulated in virtual spaces.\n\nSpectral Omni\nThis filter section is for equalizing the omnidirectional part of the sound radiated by the virtual source. This equalizer mimics the global frequency response of the source, similar to how a loudspeaker colors the sound.\n\n\nSpectral Axis\nThis filter section is for equalizing the on-axis part of the sound radiated by the virtual source. Most, if not all commercially available loudspeakers do exhibit a radically different frequency response whether a listener or microphone is right in front of it or to the side.\nSetting a rather flat on-axis equalizer curve, and maybe cutting the treble and mids for the omni response would be a good starting point to emulate a real-world speaker, so this is the default setting for these filters.\n\n\n\n\n\n\nNote\n\n\n\nSpectral Axis performs more like conventional mixer EQ"
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#radiation",
    "href": "Spat_Environment_Source_Parameters.html#radiation",
    "title": "27  Source Parameters",
    "section": "27.5 Radiation",
    "text": "27.5 Radiation\n\nThis section controls the simulation of acoustic radiation in relation to the location and emitter orientation of the virtual source. Use these parameters to simulate how a source will interact inside the reverberant environment.\n\nRelative Direction\nThis switch is a very simple way for a user to achieve a more consistent result as regards the natural conservation of a source’s presence. The algorithm will continuously maintain the on-axis focus for each virtual source - or for every emitter in a grouped source - so that it is consistently oriented towards the listener position. When not engaged, a source remains in the same constant direction which is what might be preferred if something is passing through in a spatial design.\n\n\nDistance\nDistance from the source to the center reference point (listener position), in meters.\n\n\nAzimuth\nAngle between the source location and the listener position front reference axis, in degrees.\n\n\nElevation\nElevation angle, in degrees.\n\n\nYaw\nAngle of the source direct orientation relative to the listener-source axis, in degrees.\n\n\nPitch\nSource direct orientation pitch angle, in degrees. Think of pitch in the nautical sense of the word, how a boat pitches up and down in stormy seas.\n\n\n\n\n\n\nNote\n\n\n\nPitch and Yaw can be used to make a source more diffuse by turning its direct sound away from the listener.\n\n\n\n\nAperture\nThe aperture parameter relates to the “sound cone” projected by the virtual source in the acoustic space, and is measured in degrees. It determines whether the source will be very directive (small aperture), or omnidirectional (large aperture) inside the reverberant environment.\n\n\n\n\n\n\nNote\n\n\n\nAperture can make a source ‘activate’ more of the acoustic space."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#send-lfe",
    "href": "Spat_Environment_Source_Parameters.html#send-lfe",
    "title": "27  Source Parameters",
    "section": "27.6 Send LFE",
    "text": "27.6 Send LFE\n\nThis panel will only be available when the room is a Channel-Based Format which features one or several LFE speakers in its configuration, such as DTU7.1 / 5.1 / 22.2, AURO and ATMOS for example.\nIt will send an amount of the source into the dedicated LFE speaker channels of the output channel based configuration.\n\n\n\n\n\n\nNote\n\n\n\nAutomate the LFE sends for dynamic low frequency effects."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#barycentric",
    "href": "Spat_Environment_Source_Parameters.html#barycentric",
    "title": "27  Source Parameters",
    "section": "27.7 Barycentric",
    "text": "27.7 Barycentric\n\nThese rotational transformations will only work on a virtual source that consists of more than one emitter in a grouped channel based arrangement. They will also become active when you shift-select mono sources together to form an ad hoc group or shift-select mono sources in combination with grouped channel-based sources. The 3 dimensional group rotations are calculated using a ‘barycentric gravity’ method to transform a network of sound sources constrained in a group relationship.\n\nRotation XYZ\nRotate a group cluster around the XYZ axis of their common barycentric pivot point.\n\n\nScale\nScale the group cluster, maintaining their barycenter and relative relationships.\n\n\nRelative Direction\nThe barycentric transformations will continue to orient their on-axis energy towards the listener position if the relative direction algorithm is enabled."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#options",
    "href": "Spat_Environment_Source_Parameters.html#options",
    "title": "27  Source Parameters",
    "section": "27.8 Options",
    "text": "27.8 Options\n\nFinally, there are some options available for each source. It is possible to edit a global parameter on the room panel on the preferences page.\n\nDoppler\nThe Doppler effect is a well-known wave propagation phenomenon where the height of a sound perceived from a listener standpoint rises when the source is accelerating, and falls when decelerating. This is the fire siren pitch going up then down when passing you. It will only be heard if you rapidly move the source locations quite fast, but thanks to the virtual nature of the SPAT, you can bypass Physics’ laws and manually inhibit it using this switch, should it be unsuitable for the particular application you are dealing with.\n\n\n\n\n\n\nNote\n\n\n\nCareful with this effect: it adds the delay corresponding on the distance between the source and the listener point.\n\n\n\n\nDrop Factor and Drop Log\nOwing to a fundamental law of acoustics and geometry - namely energy conservation - sound pressure drops in level as one moves away from the source. Enable Drop Log for an acoustically accurate setting, which corresponds to a drop value attenuation every time the distance from the source is doubled (logarithmic behavior). The default Drop Factor of 6 dB is also the acoustically accurate setting.\n\n\nAir Absorption\nSimulates the frequency-dependent absorption of air, where high frequencies roll off quicker than low-frequencies with respect to distance. You have most probably noticed this phenomenon when you are far away from a concert venue and only able to hear the bass, and gradually start to hear the whole mix as you get closer.\n\n\nRadius\nSpecifies the radius of a sphere or disc in meters, centered around the listener position, where the drop attenuation is not taken into account, and the sound level is kept constant in regard to distance. This is not only useful to prevent any dramatic sound level peak when placing a source too close to the listener, it also reflects real-world behavior quite accurately, where sources do have a certain physical size, unlike point sources that are commonly used to model far-field acoustics. This “no-drop” zone is displayed as a transparent sphere of matching radius in the Room graphics.\n\n\n\n\n\n\nNote\n\n\n\nThe radius is now depreciated, except on rare case where you really want a source to have a different behavior than others. Please prefer the room protection zone width to prevent the audio drop.\n\n\n\n\nXY translation mode\nSpecifies the two different behaviors: - multichannel sources one regarding internal sources orientation. When set to polar, the source orientation will follow the listener. When set to cartesian, it will face the X-axis. - snapshot interpolation for all sources when position is moving. If set to cartesian, the source will move to the given point with the shape of a straight line, whereas the shape will be a circular when set to polar.\n\n\nZ translation mode\nChanges the behavior of the translation mode regarding the Z-axis. The behavior are the same as XY translation mode."
  },
  {
    "objectID": "Spat_Environment_Source_Parameters.html#spreading",
    "href": "Spat_Environment_Source_Parameters.html#spreading",
    "title": "27  Source Parameters",
    "section": "27.9 Spreading",
    "text": "27.9 Spreading\n\n\nSpread Factor\nSpreading is a percentage factor that defines how a sound source will appear to spread out across speakers or virtual speakers. It is similar to Aperture in its focusing effect but will translate differently across certain channel-based speaker arrangements according to how many speakers are involved.\n\n! The spread factor is not available on binaural and WFS.\n\n\n\nNearest Neighbors\nThis parameter is only available to a source if the room it is simulated in has been specified to be using the [_K Nearest Neighbor_ panning type -@panType-KNN]. It sets a maximum limit to the number of speakers that the algorithm can use as neighbors in its search for speakers to activate in relation to a virtual source. On a 10-speaker setup, 1-10 % will be the closest speaker to source. 11%-20% will be 2, and so forth."
  },
  {
    "objectID": "Spat_Environment_Artificial_Reverberation.html",
    "href": "Spat_Environment_Artificial_Reverberation.html",
    "title": "28  Artificial Reverberation",
    "section": "",
    "text": "29 Reverb Parameters\nEvery variable of the Virtual Room reverberation can be directly edited through the onscreen controls in realtime.\nThe reverb designer excels at creating static acoustic settings that will add all the dimensionality and immersive depth to a virtual scene. It also invites more creative reverberation ideas. Remember it works in 3D and interacts deeply with the parametric design of all virtual objects that are expressed through it.\nThis is no ordinary reverb.\nThe SPAT Reverb is a true acoustic modelling multichannel reverb, not just a so-called true stereo reverb. Despite its internal complexity, the user is invited to morph and modulate the characteristics of the virtual acoustics. To make this process fluid and natural, the parameter controls have been carefully designed so that they do not glitch. This invites continuous parametric modulation ideas, for designing out of this world reverberant spaces, in realtime."
  },
  {
    "objectID": "Spat_Environment_Artificial_Reverberation.html#reverb-design-presets",
    "href": "Spat_Environment_Artificial_Reverberation.html#reverb-design-presets",
    "title": "28  Artificial Reverberation",
    "section": "29.1 Reverb Design Presets",
    "text": "29.1 Reverb Design Presets\nThe Artificial Reverberation editor has its own preset management system, where you can save pre-designed models into a user defined preset list or to disk.\n\nThis is useful for building up a collection of pre-designed reverberation spaces and for designing models that might closely match the measurements of actual spaces you already know."
  },
  {
    "objectID": "Spat_Environment_Artificial_Reverberation.html#reverb-general",
    "href": "Spat_Environment_Artificial_Reverberation.html#reverb-general",
    "title": "28  Artificial Reverberation",
    "section": "29.2 Reverb General",
    "text": "29.2 Reverb General\n\n\nReverb enable\nEnable/disable the entire reverberation engine for the room. All the components (early, cluster and tail) of all sources will be affected.\n\n\nTail\nEnable/disable the tail of the reverberation engine for the room.\n\n\nReverb Density\nInternally, spatial variations are computed using a kind of 3D network of reverb, and this setting toggles between an 8x8 (standard) or 16x16 size (high). The choice of which sounds best is left up to you, as this depends on the source material at hand, although it must be emphasised that the high density setting consumes fairly more CPU and that the colour of the reverb can be altered by this setting, particularly at some extreme parameter setting combinations.\n\n\nSize\nThis is a meta-parameter that takes care of varying several other parameters in order to quickly set the equivalent size of the virtual room, adjusting early, cluster and tail reverb parameters to match the room characteristics.\n\n\nReverb Start\nReverb start sets the duration between the direct, dry source signal, and the first late reflections, or start of the reverb tail.\n\n\n\n\n\n\nNote\n\n\n\nPlease note its value can never go below that of the cluster minimum time, as the reverb tail is fed with a signal derived from the cluster section."
  },
  {
    "objectID": "Spat_Environment_Artificial_Reverberation.html#perceptual-factors",
    "href": "Spat_Environment_Artificial_Reverberation.html#perceptual-factors",
    "title": "28  Artificial Reverberation",
    "section": "29.3 Perceptual Factors",
    "text": "29.3 Perceptual Factors\n\n\nReverberance\nReverberance affects the amount by which the listener perceives the music to be prolonged by the reverb when the musical message suddenly stops. The effect of this setting is also obvious when the source material is of percussive nature. Reverberence is tightly related to overall decay time of mid-frequencies, which in turn is the time taken by the late reflections to vanish into silence.\n\n\nHeaviness\nRelative decay time of low-frequency content.\n\n\nLiveness\nRelative decay time of high-frequency content. Describes the liveliness and movement associated with the reverb tail (late reflections)."
  },
  {
    "objectID": "Spat_Environment_Artificial_Reverberation.html#room-response-parameters",
    "href": "Spat_Environment_Artificial_Reverberation.html#room-response-parameters",
    "title": "28  Artificial Reverberation",
    "section": "29.4 Room Response Parameters",
    "text": "29.4 Room Response Parameters\n\nEarly refers to the Early Reflections stage of the Room response, which is one of the most significant stages involved in our rapid aural perception of spatial properties and sound source localisation.\nCluster refers to a secondary iteration of room response reflections and is quite significant in the cognition of room acoustics.\nTail refers to the diffuse reverberations that eventually decay in a direct relationship with the size and reflectivity of an acoustic space. The tail section of a reverb does not contribute much to the localizability of a sound source in a space, but instead gives a sense of depth and ambiance.\n\nEarly Min\nEarly reflections minimum time, i.e., the time at which the early reflections start to appear, in milliseconds. This is the similar setting of the ubiquitous “pre-delay” found on most reverberation processors. It represents the time between the direct sound and the first early reflection.\n\n\nEarly Max\nEarly reflections maximum time, i.e., the time at which these cease to appear.\n\n\nEarly Dist\nEarly reflections’ distribution. Determines the way early reflections are scattered in time, inside the Early Min. / Early Max. interval. The default setting of 0.5 corresponds to regularly spaced reflections, above these are more grouped towards the Early Max. value, and vice versa.\n\n\nEarly Shape\nGoverns the amplitude rise or fall of early reflections. The default setting of 0.5 corresponds to early reflections all having the same level. This mimics an acoustic space where reflective surfaces are all located at roughly the same distance to the listener. Below 0.5 early reflections decay with time, above 0.5 they rise with time. Decreasing levels of the early reflections would be typical of a space where most of the reflective surfaces are grouped at a range closest to the listener.\n\n\nCluster Min\nSee Early Min. Please keep in mind the cluster is fed with the input of the early reflections’ processor section, as is shown accordingly on the display.\n\n\nCluster Max\nSee Early Max.\n\n\nCluster Distribution\nSee Early Distribution."
  },
  {
    "objectID": "Spat_Environment_Artificial_Reverberation.html#options",
    "href": "Spat_Environment_Artificial_Reverberation.html#options",
    "title": "28  Artificial Reverberation",
    "section": "29.5 Options",
    "text": "29.5 Options\n\n\nInfinite\nWhen activated, decay time temporarily rises to infinity, making the signal recirculate indefinitely inside the reverberation engine. This is best suited for on-off special effects such as “deep-freezing” audio material, or if you’re looking to create something fairly less conventional than a fade-out for the end of your track.\n\n\nAir Absorb\nSimulates the frequency-dependent absorption of air, where high frequencies roll off quicker than low-frequencies with respect to distance. You’ve most probably noticed this real-world phenomenon when you’re far away from a concert venue and only able to hear the bass, and gradually start to hear the whole mix as you get closer.\n\n\nModal Density\nScales the modal density with respect to the current setting, which is internal to the application engine, and depends on other parameters such as reverberation time. The modal density governs the frequency “smoothness” of the verb engine. Increasing this setting reduces the graininess of the reverberation. Adjust to taste, depending on the source material and desired result.\n\n\nAbs. RollOff\nRoll-off frequency for the air absorption simulation. Signal content above this frequency vanishes faster."
  },
  {
    "objectID": "Spat_Environment_Artificial_Reverberation.html#crossover",
    "href": "Spat_Environment_Artificial_Reverberation.html#crossover",
    "title": "28  Artificial Reverberation",
    "section": "29.6 Crossover",
    "text": "29.6 Crossover\n\n\nCrossover L\nSets the frequency below which decay time is determined by the heaviness setting, expressed in Hertz (Hz). Default value: 177 Hz\n\n\nCrossover H\nSets the frequency above which decay time is determined by the liveliness setting, expressed in Hertz (Hz). Default value: 5657 Hz"
  },
  {
    "objectID": "Spat_Environment_Understanding_the_3D_View.html#sec-about3dview-protectionzone",
    "href": "Spat_Environment_Understanding_the_3D_View.html#sec-about3dview-protectionzone",
    "title": "29  Understanding the mixing zones",
    "section": "29.1 The protection zone",
    "text": "29.1 The protection zone\n\nThe protection zone is an area of the 3D space represented as a sphere around the listener head. It is important to understand that as most of the pan law or spatialization techniques are incapable of creating the illusion that a sound source comes from in front of the speakers (some exceptions like WFS) we should try to avoid putting source inside this zone\nWhen a source is placed inside the protection zone, its distance will no more induce a presence factor change, meaning that the distance won’t have any effect in this zone.\nWhen a source is inside the protection zone on a 3D capable stream type/speaker arrangement. the behaviour is set by the Source over listener head parameter, which is on by default. It is the legacy function where any source entering the zone follows the sphere of protection in elevation as it tries to enter. Thus, the source is processed at its elevated position. If disabled, the source will simply keep its elevation. In both cases, reaching the protection zone means the attenuation model based on the distance reaches its threshold. (same as for the Air absorption calculation)\n\n\n\nProtectionZonePanel"
  },
  {
    "objectID": "Spat_Environment_Understanding_the_3D_View.html#the-presence-of-a-source",
    "href": "Spat_Environment_Understanding_the_3D_View.html#the-presence-of-a-source",
    "title": "29  Understanding the mixing zones",
    "section": "29.2 The presence of a source",
    "text": "29.2 The presence of a source\nA sound source in SPAT Revolution has a presence factor. It defines its overall level and brightness inside the virtual acoustic space. This presence factor can be changed by many parameters:\n\nThe distance between the source and the protection zone\nThe presence parameter\nThe drop factor\nThe Air absorption\n\nPutting a source closer or further away from the protection zone will have the consequences of modifying the presence. The closer the source is, the more presence it has. The farther it gets, the less presence has a source.\nThe presence parameter directly affects the presence factor of the source.\nThe drop factor defines the relation between the loss of presence and the distance between the source and the protection zone. It is set by default to follow the acoustic law of our world, where we lose 6 dB of presence each time we double the distance.\nWhen Presence infos on the top bar of the 3D view is enabled, the overall presence of a source is displayed by a green vector, drawn between the source and the protection zone. The intensity of the green color is proportional to the presence factor. If the source is inside the protection zone, the vector will turn red and a small sphere of the same color will be drawn on the surface of the protection zone.\n\n! While a source is in the protection zone, there is no variation in presence."
  },
  {
    "objectID": "Spat_Environment_Understanding_the_3D_View.html#sec-about3dview-efficiencyzone",
    "href": "Spat_Environment_Understanding_the_3D_View.html#sec-about3dview-efficiencyzone",
    "title": "29  Understanding the mixing zones",
    "section": "29.3 The efficiency zone",
    "text": "29.3 The efficiency zone\n\n\nBy definition, the efficiency zone is where the virtual sound sources should be localized. According to the speaker arrangement and coverage capacity, an efficiency zone is calculated for all channel-based panning types. It gets displayed on the 3D view as a grey shadow, and can be considered as a safe source position zone.\nOne of the advantages of this mechanism is that it allows to change a speaker arrangements while providing a tool to manage the sources already positioned in the soundscape but that may be outside the zone.\nInside a channel-based room, the efficiency zone is defined by the speaker arrangement used in a room: + When using speaker setup that surrounds the listeners, the efficiency zone is a sphere (or circle in 2D), which spans from the border of the protection zone to the farthest distance you can put a source (100 m). A speaker array is considered as surround if the angle between the foremost left and right speakers is over 180°. For readability reasons, the efficiency zone is not drawn in this case, but will be if its depth is define to a value inferior to its maximum (100 meters).\n\nWhen using a non-surrounding system (stereo, frontal line, etc.), the efficiency zone becomes a “piece of pie” and is displayed in the 3D view. Its width is defined by the angle between the foremost left and the foremost right speaker. The visualization of the efficiency zone should help to understand the limitation of these systems in terms of spatialization options. For instance, placing a source behind the listener head in stereo will never produce the effect of a source coming from behind.\n\nThe range of the efficiency zone is set by the “depth” parameter. It sets the maximum span. A use case for defining a maximum efficiency zone Depth in CLAMP mode is to limit the attenuation to the arc part of the zone.\nInside a non-channel-based room, the efficiency zone is a sphere, because there is no speaker to constrain the diffusion area. Still, it can be edited with the same “depth” parameters for multi-room and creative applications. More information below.\n\nBehaviour of sources outside the efficiency zone\nWhen a source is out of the efficiency zone, SPAT Revolution offers three behaviours: 1. The source is clamped to the efficiency zone (default for new session) 2. The source is muted 3. It does nothing (default for pre 22.02 release sessions)\nThis option can be set in the room’s output section. Check out the Room section 25 for more information.\n\n\n\n\n\n\nNote\n\n\n\nBy default, the source is clamped to the border of the efficiency zone.\n\n\nClamping the source to the efficiency zone helps to keep coherent sound scene, while the “mute” mode helps to create ins and outs effect. The mute only occurs in the actual room.\n\n\n\n\n\n\nNote\n\n\n\nWhen in mute mode, a slight fade out is applied to avoid clicks. The length of the fade can be adjusting by making the source go faster or slower.\n\n\nNote that the preferred behaviours are clamping or muting. Clamping will prevent an aberrant render in sound and localization.\nThe pictures below shown some key cases of clamping, on non-surround systems:\n\n\n\n\n\n\n\nNote\n\n\n\nOn non-surrounding systems, trying to escape the efficiency zone will result in the source being clamped to its foremost left or right.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf a source is placed in front of the speakers, the source will be clamped to the front line they formed while preserving the azimuth angle.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen a source is on the opposite side of a non-surround system, the projection of the virtual source will mirror the behavior of the actual source, thus, removing any jump or abrupt change in position of the source.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen a source is outside the efficiency zone and mute behaviour is selected, the source is represented differently.\n\n\n\n\nElevation clamping\nThe elevation clamping helps to keep sources inside coherent space in regard to the room speaker arrangement. It only happens with channel-based configurations.\nIt can be activated by the Source fit speakers elevation parameter, in the room options. Elevation clamping works differently depending on if you are working with a 2D or 3D speaker array.\n\n2D Speaker Array\n\nWhen dealing with a 2D speaker array, there is no point at placing a source above or below the horizontal plan. If you choose to do so, or use a 2D room to translate a 3D mix, you will see phantom sources that are the projection of each source on the horizontal plan. The position of the phantom source is used by the DSP to render the actual source position in the virtual space, but, it will preserve its actual presence factor.\n\n3D Speaker Array\n\nMost 3D speaker arrays have at least two speaker layers. Such layers are defined by three non-align speakers sharing the same height (z). Elevation clamping will handle sources as they exceed the extreme layers. This clamping behaviour, like with 2D speaker array, is shown with phantom sources that indicate the position used inside the DSP stage of SPAT Revolution."
  },
  {
    "objectID": "Spat_Environment_Understanding_the_3D_View.html#limit-cases",
    "href": "Spat_Environment_Understanding_the_3D_View.html#limit-cases",
    "title": "29  Understanding the mixing zones",
    "section": "29.4 Limit cases",
    "text": "29.4 Limit cases\n\nElevation clamping does not occur with distance-based pan law (KNN and WFS) when using 3D speaker array, except for the Z=0 plan. This prevents some jumps and aberrations in sound.\nWhen using a 2D non-surrounding speaker array, efficiency and elevation clamping are tied together. If efficiency clamping is activated, SPAT Revolution automatically switches on the elevation clamping. On the contrary, if elevation clamping is turned off, then, so is the efficiency clamping.\nWFS is the only case where it can make sense to put virtual sources in front of the speakers, to take advantages of the focus zone. This zone and the associated behaviour is detailed in the WFS Section 25 of this user guide."
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement.html#rendering-to-speakers",
    "href": "Spat_Environment_Speaker_Arrangement.html#rendering-to-speakers",
    "title": "30  Speaker Arrangement Editor",
    "section": "30.1 Rendering to Speakers",
    "text": "30.1 Rendering to Speakers\nIn order for the virtual scene (our room) to translate correctly as an immersive sound experience on a speaker system, SPAT Revolution needs to have a model of a multichannel speaker arrangement which will be used to apply the panning or synthesis method to map the information to the destination speakers and render the sound field correctly.\nTo this end, you will find a large library of standard and specialized speaker arrangements already built into SPAT Revolution which can be used in various places throughout the Environment Setup.\nSpeaker arrangements can be used to fit the format of a virtual room to match the actual speaker system being used to diffuse the mix in a real room. Channel-based speaker configurations are used to define a multichannel source arrangement, a room speaker source arrangement, and can also be used in the transcoding phase of sound fields.\nThe golden rule when working with multi-channels based audio is to ensure to have the appropriate format, speaker arrangement, and channel routing throughout, otherwise the virtual space will not map correctly into a physical space.\n\n\n\n\n\n\nWarning\n\n\n\nPay attention to arrangements and channel routing, they are the key!"
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement.html#custom-speaker-arrangement",
    "href": "Spat_Environment_Speaker_Arrangement.html#custom-speaker-arrangement",
    "title": "30  Speaker Arrangement Editor",
    "section": "30.2 Custom speaker arrangement",
    "text": "30.2 Custom speaker arrangement\n\n\n\nwidth=700, atl=SPAT Revolution Speaker Position\n\n\nWhile there are many standardized speaker array, such as Dolby Surround, Atmos, Auro 3D, DTS, Quad or even stereo, we are in many cases confronted to a very specific speaker positioning.\nFor such use case, it is possible to create custom speaker arrangements. Using a well-defined custom speaker arrangement will improve the sound stage and the overall impression of immersion of the audience. We always highly recommend taking the time to measure the position of the speakers of your system and to input them in SPAT Revolution.\nWe also create a powerful automatic speaker alignment tool that aligns, in time and in level, all the speakers of the arrangement on the furthest away one. These “virtual” positions are used by SPAT Revolution to process the sound stage through pan law. Please, check the Speaker Arrangement Editor 31 section for more information.\nTo make this task as easy as possible, SPAT Revolution supports both cartesian and spherical coordinate system and can also import speaker configurations from third-party softwares, such as NS-1, Blueprint or ArrayCal."
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement.html#understanding-when-a-speaker-arrangement-or-a-sound-scene-is-2d-or-3d",
    "href": "Spat_Environment_Speaker_Arrangement.html#understanding-when-a-speaker-arrangement-or-a-sound-scene-is-2d-or-3d",
    "title": "30  Speaker Arrangement Editor",
    "section": "30.3 Understanding when a speaker arrangement, or a sound scene, is 2D or 3D",
    "text": "30.3 Understanding when a speaker arrangement, or a sound scene, is 2D or 3D\nWe can quickly be tempted to create very precise speaker arrays, including height information where it may not be necessary and can do more harm than good.\nThe rule of thumb is to think in plan and not in absolute height. If speakers are meant to reproduce the same sound plan, they should have the same height. Also, the main sound plan has to be set at a height of zero meter. If you try to validate a speaker arrangement that only has one plan and is not set to a height of 0, it will correct it automatically. It also applies for older sessions that were created before SPAT Revolution had this feature."
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement.html#automatic-scaling",
    "href": "Spat_Environment_Speaker_Arrangement.html#automatic-scaling",
    "title": "30  Speaker Arrangement Editor",
    "section": "30.4 Automatic Scaling",
    "text": "30.4 Automatic Scaling\nWhen going on the road with a show, the idea of SPAT Revolution is to always keep the same session, which stores our input routing, our mixing metadata and all of our snapshots. But in such use case, each time the venue changes, the speaker arrangement changes too and its size (or diameter) will much likely be different each time.\nAs we use absolute, we solve this common use case by using an automatic scaling process.\nIf you change the speaker arrangement of a room where you already routed some sources, the global sound scene could be scaled to the new speaker arrangement.\nFor example, if you first created your session with a speaker arrangement with a diameter of four meters, and then deploy it in a venue where the actual diameter of the sound system is eight meters, then all the source position, incoming automation and snapshot data will be scaled by a factor of two."
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement.html#speaker-arrangements-examples",
    "href": "Spat_Environment_Speaker_Arrangement.html#speaker-arrangements-examples",
    "title": "30  Speaker Arrangement Editor",
    "section": "30.5 Speaker arrangements examples",
    "text": "30.5 Speaker arrangements examples\nHere are some examples of speaker configurations you can find in some venue, like RadioFrance Studio 115, Montreal Satosphere, or Berlin Planetarium. To discover it into SPAT Revolution, copy the python file on your desktop: Speaker arrangements for various domes and planetariums."
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement.html#speaker-arrangement-python-file",
    "href": "Spat_Environment_Speaker_Arrangement.html#speaker-arrangement-python-file",
    "title": "30  Speaker Arrangement Editor",
    "section": "30.6 Speaker arrangement Python file",
    "text": "30.6 Speaker arrangement Python file\nWrite the speaker arrangement on a python file provides the erasing of the data. It is recommended to do so on fixed installation, or if you really don’t want to lose the speaker arrangement data. If you want to build your own custom speaker arrangement script, explanations are provided into the following python file: Custom Speaker Arrangement Script."
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement_Editor.html#creating-editing-a-speaker-arrangement",
    "href": "Spat_Environment_Speaker_Arrangement_Editor.html#creating-editing-a-speaker-arrangement",
    "title": "31  Speaker Arrangement Window",
    "section": "31.1 Creating & editing a speaker arrangement",
    "text": "31.1 Creating & editing a speaker arrangement\n\n\n\nwidth=500, atl=SPAT Revolution Speaker Config\n\n\n\nSpeaker Arrangement section\nArrangement drop-down menu: this menu allows access to a list of all your existing speaker arrangement.\nDuplicate: create a copy of the current speaker arrangement.\n\n\n\n\n\n\nWarning\n\n\n\nYou cannot overwrite a factory arrangement. Duplicate it before trying to edit it.\n\n\nNew: create a new empty speaker arrangement.\nDelete: delete the current speaker arrangement.\n\n\n\n\n\n\nWarning\n\n\n\nThere is no confirmation before deleting an arrangement.\n\n\nRename: rename the current speaker arrangement.\nImport from: allow importing a speaker configuration from a third-party software. See the next section 31 for more detail.\nExport: open a window to export a selection of speaker arrangement.\n\n\nAlignment section\n\n\n\nwidth=800, atl=SPAT Revolution Speaker Config\n\n\nReset: revert the compute process.\nCompute: opens a dialog to help to set delay and gain on the speaker arrangement. More information of the [dedicated section below -@speaker-editor-alignment]\n\n\nSelected or all speakers section\nTransform: modify the selected or all speakers according to a specified transformation. For more information about it, check out the transformation section 33.\nSet orientation: set the orientation of selected or all speakers.\nFix automatic orientation: for speakers whose orientation is set to automatic, replace it to real orientation (front, back, listener, custom with the given angle, …) instead of automatic.\nDel.: remove the selected speaker(s) in the arrangement.\nMove up: move the selected speaker(s) one row above.\nMove down: move the selected speaker(s) one row below.\n\n\nAdd speaker(s) section\nAdd: create a new speaker in the arrangement.\nAdd along geometries: add new speakers according to a specified geometries.\n\n\nThe speakers list section\n\n\n\n\n\n\nWarning\n\n\n\nNb.:** identify the channel of the speaker.\nThe SPAT Revolution Essential license limits the total number of channels to 32 input channels, and to 18 output channels.\n\n\nName: identify the name of the speaker.\n\n\n\n\n\n\nWarning\n\n\n\nTo create an LFE channel, simply name one speaker of the arrangement “LFE”. It is possible to create until 4 LFE, naming them “LFE 1”, “LFE 2”, “LFE 3” and “LFE 4”. The corresponding sends button will appear on the source parameters panel.\nSPAT Revolution uses speaker naming to sum speaker arrangement.\n\n\nX (m): defines the position of the speaker on the X-axis, in meters.\nY (m): defines the position of the speaker on the Y-axis, in meters.\nZ (m): defines the position of the speaker on the Z-axis, in meters.\nAzimuth (°): define the angle of incidence of the source to the center of the 3D space, in the horizontal plan.\nElevation (°): define the angle between the source, the center of the 3D space and horizontal plan.\nDistance (m): define the distance between the source and the center of the 3D space, in meters.\nOrientation: define the orientation of the speaker. Default settings is “Automatic”\n\nAutomatic: default behavior, the yaw and the pitch angles are determined by the shape of the speaker arrangement. It should be the standard orientation of most cases, but can be inefficient on certain specific designs.\nListener: the speaker points to the listener head\nFront: the speaker points to the bottom of the 3D view\nBack: the speaker points to the top of the 3D view\nSide Left: the speaker points to the left side of the 3D view\nSide Right: the speaker points to the right side of the 3D view\nCustom: the user can define the orientation with the yaw and pitch parameters.\n\n\n\n\n\n\n\nNote\n\n\n\nThe orientation (0°,0°) is pointing to the listener.\n\n\nYaw: rotate the speaker around the Z-axis. 0° degree is pointing the listener. Pitch (°): rotate the speaker in elevation.\n\n\n\n\n\n\nWarning\n\n\n\nOrientation, yaw and pitch are only useful in WFS use case.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTips: to point down (speaker with positive elevation) or up (speaker with negative elevation) a speaker, set the pitch to 90 menus the speaker elevation value;\n\n\nDelay (ms): add a fix amount of latency to a speaker.\nGain (dB): change the sound level of the speaker.\n\n\n\n\n\n\nWarning\n\n\n\nIn many cases, it is wiser to let the delay and gain parameters untouched, and let the “compute” function do the job.\n\n\n\n\nPanning Type Tips section\nHere, we can find information about which pan law is available in regard of our speaker array. Some explanations are displayed to help understand why some pan laws aren’t available.\n\nThere are five colors associated with the possible panning types: + Green: this panning type is valid and functional with the selected speaker array. + Orange: this panning type is somewhat functional, but there certainly is a better solution available. Hovering the panning type with the mouse will display a message to help improve the arrangement. + Red: this panning type is not functional with the selected speaker array. Hovering the panning type with the mouse will display a message to explain why it does not work. + Grey: Two speakers are located at the same spot (i.e. the speakers are coincident). The speaker arrangement is incorrect.\n\n\n\n\n\n\n\nNote\n\n\n\nError displayed with HOA panning type.\n\n\nFor more information about each pan law, check out the section Panning algorithms 9."
  },
  {
    "objectID": "Spat_Environment_Speaker_Arrangement_Editor.html#sec-speaker-editor-alignment",
    "href": "Spat_Environment_Speaker_Arrangement_Editor.html#sec-speaker-editor-alignment",
    "title": "31  Speaker Arrangement Window",
    "section": "31.2 Alignment",
    "text": "31.2 Alignment\n\nSpeakers alignments section lets SPAT Revolution compute the delay and gain for the selected speaker arrangement. To help to deal with them with complex systems, several methods are provided, allowing adapting your alignment according to the wanted behavior:\n\nSpherical: will align speaker according to a sphere. The farthest speaker will determine the sphere radius. This is the old behavior of the compute feature.\nCartesian with minimum delay: will align the speakers according to straight lines.\nCartesian with symmetry: will align left/right and front/back speakers according to symmetrical straight lines. A typical use case will be to help to deal with an asymmetrical arrangement.\n\nAlignment can be made on the all arrangement, but also selecting a certain speaker orientation type. It is possible to select the speakers on each the alignment will be done according to their orientation."
  },
  {
    "objectID": "Spat_Environment_Import_Speaker_Config.html#how-to-import-a-speaker-configuration-from",
    "href": "Spat_Environment_Import_Speaker_Config.html#how-to-import-a-speaker-configuration-from",
    "title": "32  Import Speaker Array",
    "section": "32.1 How to import a speaker configuration from",
    "text": "32.1 How to import a speaker configuration from\n\nEase\nIn EASE software, open the project, and click Edit Project Data on the upper toolbar. In the new window, click on Edit toolbar button, then Loudspeakers, File and finally Send table to file.\nA popup window will open, asking to use only selected rows. If you want to export all the speakers, click on NO. Select the target catalog for the text file you are going to generate, and click on save. The newly created file can now be imported in SPAT Revolution.\n\n\n\n\n\n\nNote\n\n\n\nChances are the reference point used in EASE won’t be the central reference point typically used in SPAT. Simply use the Transform speaker arrangement option. Typical, you will want to offset X / Y position or Rotate the arrangement 180 degrees.\n\n\n\n\nNexo NS-1\nIn NS-1, to export all the speakers : Go to the Speaker Positions Windows, Speakers/Speakers Position or Ctrl + P. Select all the Speakers, and click on Export, File.... This will export a .txt file, readable by SPAT Revolution.\n\n\nAdamson BluePrint\nIn BluePrint, to export all the cabinets: Go to the Cabinet tab. In the line Cabinet Group, click on the 4th button, Export All Cabinets. This will export an .arys file readable by SPAT Revolution.\n\n\n\nimage(1)\n\n\n\n\nd&b ArrayCal\nIn ArrayCal, export all the sources with “Files/Export/EASE/Coordinates of all sources”. This will export a .xld file readable by SPAT Revolution.\n\n\n\nimage(2)\n\n\n\n\nExcel\n\n\n\nimage(2)\n\n\nSpeaker import from Excel template"
  },
  {
    "objectID": "Spat_Environment_Transformation.html#sources-transformations",
    "href": "Spat_Environment_Transformation.html#sources-transformations",
    "title": "33  Transformation",
    "section": "33.1 Sources Transformations",
    "text": "33.1 Sources Transformations\nAs with the custom speaker arrangement editor, we can apply some transformations to one or multiple sources. This feature is especially handy if you wish to quickly set sources on a circle, or to put a selection of sources at the distance for examples.\nTo open the transform menu, right-click on a source in the source panel and choose “Transform.” You can also use the shortcut CMD/CTRL + SHIFT + T.\nPlease check the section about Speaker Arrangement 31 if you want more details about the different transform. Sources’ transformations also include an integration time which allows to create smooth transition between the current and the new source position."
  },
  {
    "objectID": "Spat_Environment_Transformation.html#speaker-transformation",
    "href": "Spat_Environment_Transformation.html#speaker-transformation",
    "title": "33  Transformation",
    "section": "33.2 Speaker Transformation",
    "text": "33.2 Speaker Transformation\nTo modify a speaker arrangement with a predefined action, you can use the “transform” menu. To access it, click on the Transform button. A pop-up window will appear.\n\n\n\nwidth=800, atl=SPAT Revolution Transform Speaker\n\n\nNormalize Distance: The further speaker will be place at the given distance. All the other speakers will be placed at the relative distance from it.\nSet Elevation: The first ring of speakers will be placed at the given elevation.\nOffset Distance: This transformation applies an offset to the distance parameter of all speakers. It preserves the relative position of speakers.\nOffset Position XYZ: Same as above but with XYZ parameter.\nScale Distance: This transformation allows scaling all the speakers inside a certain range of distance. It preserves the relative position of speakers.\nScale XYZ: Same as above but with XYZ parameters.\nRotation Azimuth: With this transform, we can apply a rotation to our speaker array.\nMirror: As its name implies, this transform creates a mirror of the speaker arrangement regarding of a certain axis.\nLinear uniform distribution along the selected axis: This transformation puts all the speakers on the same axis, with an even space between them.\nCircle: This transformation places all the speakers on the same circle, with an even space between them.\nSinus: This transformation creates a sinus shape with the speakers."
  },
  {
    "objectID": "Spat_Environment_Balistic.html",
    "href": "Spat_Environment_Balistic.html",
    "title": "34  Signals visualization and ballistic",
    "section": "",
    "text": "Even if ears are the most valuable tool of a sound engineer, having a good and reliable set of tools for metering and visual monitoring is crucial, especially when handling as many channels as we are in immersive sound.\nIn SPAT Revolution, we have three main features regarding this subject: + Vu-meters for each setup blocs. + Nebula for spatial audio visual feedback. + Option to send audio to the FLUX:: Analyzer at many points of the signal path.\nWe will detail each one of them in the next section."
  },
  {
    "objectID": "Spat_Environment_VU_Meters.html",
    "href": "Spat_Environment_VU_Meters.html",
    "title": "35  Vu-Meters",
    "section": "",
    "text": "Throughout SPAT Revolution’s different editors, you will see a complete set of accurate decibel meters giving you a visual display of all channels activity in an audio stream, whether Ambisonics or Channel Based. They are very useful to see when clipping might be occurring in any of the channels, and to debug signal flow routing in general.\nAlso, notice how the “wire” that graphically connects modules in the setup signal graph does not visually change even though it is handling a load of channels."
  },
  {
    "objectID": "Spat_Environment_Nebula.html",
    "href": "Spat_Environment_Nebula.html",
    "title": "36  Nebula Spatial Spectrogram",
    "section": "",
    "text": "Nebula is a technology adapted from our flagship FLUX:: Analyzer System, a suite of highly regarded professional mastering and mixing visualization tools.\n\n\n\n\n\n\n\nNote\n\n\n\nScreenshot from a Flux Pure Analyzer session.\n\n\nNebula in SPAT Revolution provides a unique representation of the sound field in terms of spectral content and localization rendered directly inside the 3D speaker simulation and virtual room display. It combines the functionality of a spectrum analyzer and a vector scope in a novel real-time display. It is a useful tool to get a real time overview of your SPATial mix in terms of spectral-spatial diffusion, and can give quite accurate representations of ‘where’ and ‘how’ sound will manifest over a real world sound system. A lot of work has gone into optimizing the real-time rendering of the display, not solely for aesthetic reasons, but because we wanted the display to react instantly to all the details in the incoming multichannel audio. The idea is literally for you to be able to see what the listener will hear and feel.\nHow does it work?\nThe overall principles behind Nebula are quite straightforward. At any given time, and for every frequency, the engine computes the position of a frequency in space (2D in stereo and 3D for multichannel surround). This position is taken as the center of gravity of the various channels, weighted by the relative amplitude of the signal in their corresponding channel. A color-intensity mapped projection is computed for the multi-speaker plane, giving a spectrum-space frame constrained to the surround sound field radius or sphere. Past analysis frames are progressively “forgotten”, using blur and dimming, in order to make place for new information, which gives the graphic display increased legibility and its characteristic ‘nebulous’ quality.\n\n\n\n\n\n\n\nNote\n\n\n\nNebula is available for Channel-Based room only."
  },
  {
    "objectID": "Spat_Environment_Analyzer_Workflow.html",
    "href": "Spat_Environment_Analyzer_Workflow.html",
    "title": "37  FLUX:: Analyzer Workflow",
    "section": "",
    "text": "SPAT Revolution provides a close integration with the analyzer designed by FLUX::, the FLUX:: Analyzer, allowing to send audio directly to the FLUX:: Analyzer.\nNothing more simple to do it: on the Setup Page, select a block. On the list Send to Analyzer, select True. On the FLUX:: Analyzer, you will see it as a new Source, called “SPAT Revolution”. Select it, and select the correct speaker arrangement into the Analyzer: that it’s.\n\n\n\n\n\n\nNote\n\n\n\nSend to Analyzer feature is not compatible between all versions of SPAT Revolution and FLUX:: Analyzer. Please note that:\n\nSPAT Revolution 22.02.50151 version and below versions are compatible with FLUX:: Analyzer 22.01.50131 version and below.\nSPAT Revolution 22.09.50200 version and up are compatible with FLUX:: Analyzer 22.09.50XXX (coming version) and up."
  },
  {
    "objectID": "Files_&_folders.html#spat-revolution-files",
    "href": "Files_&_folders.html#spat-revolution-files",
    "title": "38  SPAT Revolution files and folders",
    "section": "38.1 SPAT Revolution files",
    "text": "38.1 SPAT Revolution files\nSPAT uses 3 different file types:\n\n.json\n.ioconfig\n.reverbPresets\n\n.json are the main files of SPAT Revolution: sessions are saved in this file type.\nTo save a session, click on the “Save session” button on the Setup page, or use the shortcut Ctrl + S on Windows, or Cmd + S on Mac, on any page of SPAT Revolution.\nUser created custom speaker arrangement(s) can be exported or imported as .ioconfig files in the edit speaker config window.\nReverb preset can be stored and exported as .reverbPresets. They can later be imported back into a session."
  },
  {
    "objectID": "Files_&_folders.html#preferences-and-ressources-files",
    "href": "Files_&_folders.html#preferences-and-ressources-files",
    "title": "38  SPAT Revolution files and folders",
    "section": "38.2 Preferences and ressources files",
    "text": "38.2 Preferences and ressources files\nUsers/.../Document/FLUX SE\nUsers/.../Document/FLUX SE - IRCAM\nUsers/.../Document/Ircam\nThe FLUX SE Folder contains a subfolder named Config which has 3 files:\n\n.ioconfig contains your added speaker arrangements to SPAT Revolution\n.presets contains your reverb presets\n.theme contains your theme (Dark or Light mode)\n\nA subfolder named Preferences containing:\n\nhrtf.json file which includes your HRTFs files location\nusers.json contains your saved software preferences\nPreferences.xml saves some paths\nUI.xml saves your user interface preferences\nProperty Memory subfolder contains the memory slots saved by parameters\n\nA subfolder named Shell containing:\n\nhistory.txt - a history of the terminal commands\n\nThe FLUX SE - IRCAM Folder contains preferences and presets of the three SPAT Revolution plug-ins.\nThe Ircam Folder contains a subfolder called sofa which contains the sofa.catalog.xml file. The HRTF catalog.\n\n\n\n\n\n\nNote\n\n\n\nWhen backing up a system, make sure to copy all these folders to secure the complete software configuration."
  },
  {
    "objectID": "Files_&_folders.html#paths-for-python-script",
    "href": "Files_&_folders.html#paths-for-python-script",
    "title": "38  SPAT Revolution files and folders",
    "section": "38.3 Paths for python script",
    "text": "38.3 Paths for python script\nUsers/.../Desktop\nUsers/.../Document/FLUX SE/Spat Revolution\n\n\n\n\n\n\nNote\n\n\n\nAn example of a script file is the customSpeakerArrangement that can be used as a method to add arrangements to SPAT Revolution."
  },
  {
    "objectID": "Application_Preferences.html#global",
    "href": "Application_Preferences.html#global",
    "title": "39  Application preference",
    "section": "39.1 Global",
    "text": "39.1 Global\n\n\n\nGlobal Section\n\n\n\nAllow sending error data\nAllow sending error data to FLUX:: support. All the data are sent anonymously.\nOff by default\n\n\nReopen last session on startup\nThe last opened session will be automatically reopened at the start of SPAT Revolution.\nOn by default\n\n\nUse Metric System\nToggle between the imperial system and the metric system.\nOn by default\n\n\nTemperature\nChange the temperature used in the delay line calculation.\nDefault is 20 °C\n\n\nInput delay - Unit of measure\nChange the unit format for delay.\nDefault is sample\n\n\nEdit Frame Rate\nDefine how many times per second the UI is refreshed.\nDefault is 30 Hz\n\n\nEngine Frame Rate\nDefine how many times per second the engine is refreshed.\nDefault is 60 Hz\n\n\nMeter Default Refresh Rate\nDefine how many times per second the meters are refreshed\nDefault is 30 Hz\n\n\nLanguage\nAllow to change the language of SPAT Revolution. English, Italian, German, Korean, French, and Spanish are available. If you wish to help us to translate SPAT in another language, don’t hesitate to contact us.\nDefault is English\n\n\nReset to default\nReset back all the global parameters to default.\n\n\nImport/Export Preferences\nAllow exporting or import preferences."
  },
  {
    "objectID": "Application_Preferences.html#hardware-io",
    "href": "Application_Preferences.html#hardware-io",
    "title": "39  Application preference",
    "section": "39.2 Hardware IO",
    "text": "39.2 Hardware IO\n\n\n\nHardware IO Section\n\n\nThe hardware IO panel allows choosing the audio interface that can be accessed by SPAT Revolution.\n\nInput/Output Devices\nThis menu allows selecting the audio interface. SPAT Revolution audio engine supports all devices compatible with ASIO (Windows) or CoreAudio (macOS).\n\n\n\n\n\n\nWarning\n\n\n\nNote that you should select “None” when using the Local Audio Path connections.\nSPAT Revolution audio engine also supports different input and output interfaces, on both macOS and Windows, for maximum flexibility.\nIn case of different input and output devices, the sample rate and the block size need to be the same.\n\n\n\n\nSampling Rate\nSelect the sampling rate used by the audio engine.\n\n\nBlock Size\nThe block size defines the global latency added by SPAT Revolution. The lower it is set, the lower the latency is, but the greater the CPU consumption is.\n\n\nShow input/output settings\nThis button opens the driver audio panel of the selected interface, if it exists."
  },
  {
    "objectID": "Application_Preferences.html#user-interface",
    "href": "Application_Preferences.html#user-interface",
    "title": "39  Application preference",
    "section": "39.3 User Interface",
    "text": "39.3 User Interface\n\n\n\nUser Interface Section\n\n\nThis panel contains some general user preferences.\n\nAnti-Alias\nWhen enabled, this option smooth out lines in the graphic engine. If you are using an Intel-based computer without a dedicated GPU, we highly recommend deactivating this option to improve performances.\nOn by default\n\n\nSetup Wire\nWhen on, the wires between blocks in the setup page are splined. When off, they are straight.\nOn by default\n\n\nTooltips\nTooltips contain help and complementary informations. When on, they are displayed when the mouse is over a parameter or a control.\n\n\nTheme\nAllows switching between the dark theme and the light theme of SPAT Revolution.\nSet on “dark” by default\n\n\nShortcuts window\nDisplay the list of all the shortcut of SPAT Revolution."
  },
  {
    "objectID": "Application_Preferences.html#osc-main",
    "href": "Application_Preferences.html#osc-main",
    "title": "39  Application preference",
    "section": "39.4 OSC Main",
    "text": "39.4 OSC Main\n\n\n\nOSC Main Section\n\n\nThis panel contains basic OSC options.\n\nOSC Enable\nEnable or disable the OSC communication between SPAT Revolution and other devices.\n\n\nEnable commands log\nAllows displaying the OSC messages in the application’s console.\n\n\nShow invalid OSC input messages\nAllows displaying the unknown and invalid OSC messages in the application’s terminal.\n\n\nDump on socket change\nAllow to dump all properties when a socket change, i.e. when the IP address or the port number has been edited, or the socket is enabled. This ensures a constant synchronisation between any remote control and SPAT Revolution.\n\n\nOutput rate\nDefine OSC output rates in milliseconds.\n\n\nExport Parameters\nThis button exports the OSC parameters to a text file."
  },
  {
    "objectID": "Application_Preferences.html#osc-connections",
    "href": "Application_Preferences.html#osc-connections",
    "title": "39  Application preference",
    "section": "39.5 OSC Connections",
    "text": "39.5 OSC Connections\n\n\n\nOSC Connections Section\n\n\nThis panel allows creating OSC connection between SPAT Revolution and other devices, like tablets, phones, computers and many others. More information is available on the OSC section 41."
  },
  {
    "objectID": "Application_Preferences.html#snapshots",
    "href": "Application_Preferences.html#snapshots",
    "title": "39  Application preference",
    "section": "39.6 Snapshots",
    "text": "39.6 Snapshots\n\n\n\nSnasphot preferences\n\n\n\nRecall sources name\nDetermines if the source names is recalled with snapshots.\n\n\nNumber of saved versions\nDetermines the number of version saved when updating a snapshot. Careful: increasing this number increases deeply the size of the .json SPAT file.\n\n\nAsk for update before recalling\nWhen checked, a dialog will ask you if you want to update the snapshot before each recalled."
  },
  {
    "objectID": "Application_Preferences.html#hrtf",
    "href": "Application_Preferences.html#hrtf",
    "title": "39  Application preference",
    "section": "39.7 HRTF",
    "text": "39.7 HRTF\n\n\n\nHRTF Section\n\n\nThe HRTF panel allows setting up some generic options for HRTF handling.\n\nDefault HRTF\nChoose the default HRTF used in binaural room or binaural monitoring blocks\n\n\nManage HRTFs - Ultimate license only\nThe button open a window that allows downloading or removed HRTF. You can also import your own HRTF from this menu."
  },
  {
    "objectID": "Application_Preferences.html#room",
    "href": "Application_Preferences.html#room",
    "title": "39  Application preference",
    "section": "39.8 Room",
    "text": "39.8 Room\n\n\n\nRoom Section\n\n\nThis panel allows changing some room properties.\n\nRoom gain\nChange the gain of all the rooms of SPAT Revolution.\n\n\nCompute LFE\nOff by default, this option allows including the LFE position in the compute of the speaker alignment process.\n\n\nSpeaker test post “mute/solo”\nChange the behavior of the signal generator for speaker, pre or post speaker’s mute and solo.\n\n\nWFS default truncation distance of Efficiency zone for linear antenna\nAdd a distance offset to efficiency zone when using WFS with linear antenna to avoid issue with focus zone."
  },
  {
    "objectID": "Application_Preferences.html#signal-generator",
    "href": "Application_Preferences.html#signal-generator",
    "title": "39  Application preference",
    "section": "39.9 Signal Generator",
    "text": "39.9 Signal Generator\n\n\n\nSignal Generator Section\n\n\nHere, you will find the options related to the test signals generated by the application itself.\n\nGain\nConfigure the signal generator gain.\n\n\nSignal Type\nConfigure the type of signal generator.\n\n\nSpeaker test post “Mute/Solo”\nAllow the speaker test to be post speaker mute/solo, i.e. the speaker test will pass even if the speaker is muted."
  },
  {
    "objectID": "Application_Preferences.html#engine",
    "href": "Application_Preferences.html#engine",
    "title": "39  Application preference",
    "section": "39.10 Engine",
    "text": "39.10 Engine\n\n\n\nEngine Section\n\n\nThis panel allows to modify the behavior of the SPAT Revolution engine.\n\nAutomation\n\nAutomation Rate\nDefine the automation rate in milliseconds.\n\n\n\nAudio Processing\n\nMax Number Of Cores\nDefine the number of CPU cores used by the engine.\n\n\nParallel Profile\nDefine how the CPU resources are spread among the cores available. In Max Distribution mode, the CPU resources are evenly spread among the available cores. In Favor First Core, the engine will fill the CPU cores one by one. The Balanced Distribution mode is a compromise between both.\n\n\n\nBlackTrax RTTrPM - Ultimate license only\n\n\n\nBlackTrax Section\n\n\nSee the integration chapter about BlackTrax 58"
  },
  {
    "objectID": "Ecosystem_&_integration_Automation.html",
    "href": "Ecosystem_&_integration_Automation.html",
    "title": "Ecosystem & integration",
    "section": "",
    "text": "Almost all SPAT Revolution parameters can be continuously controlled in real time using SPAT’s high resolution automated control features.\n\nControl data can be sent via Open Sound Control (OSC) or through multiple SPAT Revolution plug-ins in your DAW. Parameter control can be played back from precomposed timelines, or performed, generated and captured in a variety of ways. One of the most straightforward ways is to set DAW automation on Write mode on a track that contains a SPAT Send plug-in, and use the graphical interface of the SPAT Room Editor to drag Virtual Sources around or turn source parameter pots. The movements will be captured into the DAW timeline in precisely the same way you would capture automation from a conventional DAW plug-in, like Reaper 46, Reavolution 47, ProTools 48, Nuendo 51, Ableton Live 49, Bitwig 52, or other.\nAlternatively, a wireless OSC control surface could be used to control the parameters of SPAT Revolution in real time, whilst you stand in the middle of the sound system away from the computer. There is already fully programmed remote for SPAT Revolution: - the SPAT Revolution REMOTE 57 can be used on any device as a web-based controller. - the legacy and discontinued Lemur template for SPAT Revolution (see Third party integration - Lemur 57).\nIf you are using Figure53 Qlab for show control, spatial effects can be sent along with the rest of the audio-visual cues for a big show or event (see “Third party integration” - QLab 53).\nIf you are working with algorithmic gesture generators and modulators then your control signals can be easily sent into the SPAT Renderer via OSC to distribute and control spatial sound sources in real time using your own control programs.\n\nGet creative with spatial sound design using OSC and Spat"
  },
  {
    "objectID": "Ecosystem_&_integration_Using_Hardware_IO.html#single-hardware-workflow",
    "href": "Ecosystem_&_integration_Using_Hardware_IO.html#single-hardware-workflow",
    "title": "40  Using Hardware I/O",
    "section": "40.1 Single Hardware Workflow",
    "text": "40.1 Single Hardware Workflow\nWhen you have a high channel count hardware IO connected to your SPAT Revolution workstation, it is possible to receive signals from the hardware unit physical inputs into SPAT at the top of the setup environment and route to the units physical outputs at the bottom of the setup graph - these are labeled as ‘Hardware’ IO in SPAT.\n\nHardware input connections could include:\n\nMic\nLine\nMADI\nDANTE\nAVB\nADAT\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure you have the Hardware Device selected in the SPAT preferences!\n\n\nHardware input formats could be mono, stereo or a format with any number of channels. Channels could be set up as single virtual sources, or as group multichannel sources using only one input/source module."
  },
  {
    "objectID": "Ecosystem_&_integration_Using_Hardware_IO.html#distributed-hardware-workflow",
    "href": "Ecosystem_&_integration_Using_Hardware_IO.html#distributed-hardware-workflow",
    "title": "40  Using Hardware I/O",
    "section": "40.2 Distributed Hardware Workflow",
    "text": "40.2 Distributed Hardware Workflow\nRouting via hardware IO means that in principle the audio can arrive at SPAT’s hardware inputs via MADI or other high channel interconnect from another machine handling the audio playback (and/or recording). This is a powerful and reliable combination as it shares audio computational resources.\nFurthermore, a single machine setup can be converted to a fully automated distributed using OSC to target the single or dual SPAT engine for a real time controllable and interactive distributed hardware setup.\n\n\n\n\n\n\nWarning\n\n\n\nEnable bidirectional OSC communication in SPAT preferences to send automation over the network to another machine. Contact Flux Support if you need to expert support on this kind of advanced distributed setup."
  },
  {
    "objectID": "Ecosystem_&_integration_OSC_Connections_Matrix.html#sec-intro-osc",
    "href": "Ecosystem_&_integration_OSC_Connections_Matrix.html#sec-intro-osc",
    "title": "41  Open Sound Control",
    "section": "41.1 Introduction to Generic OSC",
    "text": "41.1 Introduction to Generic OSC\n\nIf you are developing your own control systems to integrate with SPAT, you might find it useful to know that it is possible to export a detailed description of all OSC patterns, syntax and usage to a text file for reference. You will find that option in the SPAT preferences. You will also find a complete OSC table C in the appendix.\n\n\n\n\n\n\nNote\n\n\n\nEnable commands log will display the received and emitted OSC messages in the log windows to confirm you are receiving data. Shift + F7 will open the log window.\n\n\nIn general, SPAT OSC patterns have the form of:\n/source/[remote number]/x\nwhere [remote number] represents the Remote number of the Virtual Source, or the index (i.e. the room number) of the Room you wish to control with the message.\nThe three positional formats can be packed into one message if that option is set in the OSC Connections Matrix;\n/source/[remote number]/xyz Cartesian co-ordinates in meters\n/source/[remote number]/aed Polar co-ordinates (azimuth, distance and elevation)\n\n\n\n\n\n\nWarning\n\n\n\nTake care to automate EITHER Cartesian OR Polar, not both.\n\n\nSometimes, it is more convenient to have the [remote number] parameter as an argument of the OSC message. This option is available in the OSC Connections Matrix, namely Index as Arg. If this option is switched in, then the messages will be of the pattern\n/source/xyz ifff\nwhere i is an integer denoting the remote number of the target, and f according to convention is a float denoting the values of the message.\nFor more details about the SPAT Revolution OSC dictionary and its usage syntax please refer to Appendix C C.\nThe output rate allows changing how fast the engine will send OSC messages. The lower the value is, the more SPAT Revolution will send OSC message and the remote will display the changes, but it will also increase the stress on the CPU. If you experienced some CPU overload when moving sources through OSC command, you can try to increase the value. By default, it is set to 5.0 ms."
  },
  {
    "objectID": "Ecosystem_&_integration_OSC_Connections_Matrix.html#osc-connections-menu",
    "href": "Ecosystem_&_integration_OSC_Connections_Matrix.html#osc-connections-menu",
    "title": "41  Open Sound Control",
    "section": "41.2 OSC Connections Menu",
    "text": "41.2 OSC Connections Menu\nThere is a lot of flexibility in the OSC connection menu. We find it in the SPAT Preferences page.\n\nEight different connections can be set up, either as input or output connection. It is displayed as a table where each connection is a line.\nThe first parameter is the connection type, which offer many presets for both input and output. These presets come with dedicated network ports, dedicated option and dedicated transform if needed.\n\n\n\n\n\n\nNote\n\n\n\nOSC presets are: - SPAT plugins - SPAT Remote server - ADM-OSC - Lemur - Avid S6L - Digico - SSL Live - SpaceMap Go\n\n\nThen the IP address needs to be set. If the OSC connection is established locally, on the same computer, the port 127.0.0.1 is dedicated to local network usage. For other configurations, we need to inform the IP of the targeted device.\nLastly, the port number can be adjusted to a free one. If a “custom” preset is loaded, we most likely need to edit this parameter to establish a network connection.\nAnd finally, it is possible to name the OSC slot, clicking on the name of the top of the right panel.\nIf we want to deactivate an OSC socket without losing the parameters, it is possible to deactivate an OSC socket. To do this, click right on the OSC socket number and click on Activate/Deactivate, or shift-click on the OSC socket number. As it, the input or output will be deactivated.\nIf we loose the sync between the remote and SPAT, it is also possible to dump all the project properties on a particular socket. To do so, click right on the OSC socket number and click on Dump project. To note that the project is always dumped when the OSC socket is activated, and when the OSC IP address or port are changed."
  },
  {
    "objectID": "Ecosystem_&_integration_OSC_Connections_Matrix.html#osc-transform",
    "href": "Ecosystem_&_integration_OSC_Connections_Matrix.html#osc-transform",
    "title": "41  Open Sound Control",
    "section": "41.3 OSC Transform",
    "text": "41.3 OSC Transform\nInterfacing different devices and software in OSC can be problematic as each piece of equipment can have its own scale of value. To overcome these difficulties, some OSC transform presets have been implemented.\n\nTransform presets are accessible for each OSC connection and allow some quick re-scaling of the values.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nIf the included transform preset does not fit yours needs, you can click on the + button to open the custom OSC transform menu. In this menu, you can choose how to scale our input our output values. You can also choose to exclude specific OSC command from the scaling rules."
  },
  {
    "objectID": "Ecosystem_&_integration_DAW_Automation_Manual_setup.html#daw-automation---manual-setup",
    "href": "Ecosystem_&_integration_DAW_Automation_Manual_setup.html#daw-automation---manual-setup",
    "title": "42  SPAT PI : Automation",
    "section": "42.1 DAW Automation - Manual setup",
    "text": "42.1 DAW Automation - Manual setup\nWhen you are not using the local audio path workflow, and instead working directly with a connected hardware interface, then you must set up automation manually.\nThe first step is to go to the SPAT Preferences and Enable OSC.\n\n\n\nOSC Main\n\n\nYou then need to set up an OSC connection in order to connect with SPAT plug-ins via OSC. In one of the SPAT Revolution OSC connections, you can simply choose an input preset for a SPAT plug-in and do the same for the output preset configuration.\n\n\n\nOSC Connection SPAT Plug-ins\n\n\nThe port and host should match that of the SPAT plug-ins. By default, the plug-in ports are set according to the SPAT Revolution preset, requiring you simply to choose / set the IP address.\nIf you are running SPAT and the DAW software on the same machine, then the IP address is always the so-called LocalHost (127.0.0.1).\nRemember that the index number of each SPAT plug-in links it to a virtual source with the same remote number - or in the case of a SPAT Room plug-in - it is used to identify which Room you wish to control.\n\n\n\n\n\n\nWarning\n\n\n\nSome systems require you to press Tab key and not Returner editing a field in the Plug-in.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll send plug-in instances in one DAW will have the same IP and port number in the DAW, but different and unique Index numbers."
  },
  {
    "objectID": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#setting-up-a-local-audio-path-connection",
    "href": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#setting-up-a-local-audio-path-connection",
    "title": "43  SPAT PI : Local audio path",
    "section": "43.1 Setting up a local audio path connection",
    "text": "43.1 Setting up a local audio path connection\nIn order for the audio software integration to function correctly, the user needs to take into account certain principles of configurations.\n\n\n\n\n\n\nWarning\n\n\n\nSample Rate and buffer size must match in both SPAT Revolution and the Plug-in Host\n\n\nYou can configure these settings in the SPAT Revolution Preferences, and matching settings also need to be configured in the host DAW Preferences.\n\n\n\n\n\n\nNote\n\n\n\nIf the sample rate and the buffer size don’t match in SPAT Revolution, double-clicking over the “Sync section” at left bottom will automatically adjust them.\n\n\n\n\nAdditionally, there is an IO configuration setting inside each plug-in, accessible from the small ‘cogs’ icon. Set the IO Channel Count for each of the plug-ins this way. Each plug-in instance can carry up to 64 channels to and from SPAT Revolution. Once you have selected the channel count, Enable the software routing using the Local audio path switch.\n\nIf SPAT Revolution is running, then a Send or Return IO module will automatically appear in the Environment Setup labeled with the Track Name of the SPAT plug-in, and set to the channel count you have configured in the plug-in. If all is well configuration wise, and a successful local audio stream has been established, the Send and Return modules will have a small green indicator.\n\n\n\n\n\n\nNote\n\n\n\nOn some machines, you need to use the Tab key to register a new Track Name or IP address change in a SPAT Plug in."
  },
  {
    "objectID": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#plug-ins-parameters",
    "href": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#plug-ins-parameters",
    "title": "43  SPAT PI : Local audio path",
    "section": "43.2 Plug-ins parameters",
    "text": "43.2 Plug-ins parameters\nIndex - Relates the plug-in automation to a virtual source. - Index is assigned automatically and can only be changed manually to an index number that is not yet in use by another SPAT Plug-in. - On SPAT Revolution, Index is designed as Remote number. Initially set to the object number, you can customize it by object.\nPosition mode - In Send only, choose the recorded and read coordinate mode.\nLocal audio path - Enable the inter-application software stream.\nThru - In Send only, choose if you do not want to mute the sent audio through the plug-in.\nOSC Second Output - Set up a second parallel OSC destination.\nReport Latency - Activate latency compensation reporting for the DAW.\nOverride - In Return only, override the DAW input path."
  },
  {
    "objectID": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#daw-routing-priority",
    "href": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#daw-routing-priority",
    "title": "43  SPAT PI : Local audio path",
    "section": "43.3 DAW routing priority",
    "text": "43.3 DAW routing priority\nIn order to make sure that no sync error can happen between SPAT Revolution and the DAW of your choice, it is obligatory to make sure that each track containing a Spat Send plug-in have to be routed to every and each track containing a Spat Return plug-in.\nThis routing forced digital audio workstations to process SPAT Send plug-ins before SPAT Return ones. Without this prioritization, you can end up in a situation where the DAW call for samples from SPAT that have never been sent. This led to sync errors, and most likely to audio drop. This is an absolute golden rule when working with SPAT Revolution and a DAW on the same computer.\n\n\n\n\n\n\nWarning\n\n\n\nBe always sure that each track containing a SPAT Send plug-in is routed to every and each track containing a Spat Return plug-in.\n\n\nFor more DAW specific information, please consult our ?sec-third-party section."
  },
  {
    "objectID": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#dealing-with-daw-cpu-optimizations",
    "href": "Ecosystem_&_integration_DAW_Automation_Local_Audio_Path.html#dealing-with-daw-cpu-optimizations",
    "title": "43  SPAT PI : Local audio path",
    "section": "43.4 Dealing with DAW CPU optimizations",
    "text": "43.4 Dealing with DAW CPU optimizations\nSome DAWs, like REAPER, use some technic to reduce the load of VST plug-ins on the CPU. One common trick is to process an audio track ahead of time and then delay the buffer to play it back at the intended moment. It is called anticipative processing. This is often very efficient and can drastically reduce the CPU load (up to 30-50% !)\nOther DAWs, like Ableton live, put plug-ins that does not receive or send any audio in an off-line state. Although it is not necessarily displayed to the user, this can create some major issues when working with SPAT Revolution plug-ins.\n\n\n\n\n\n\nWarning\n\n\n\nBe sure to consult our ?sec-third-party section for more DAW specific information."
  },
  {
    "objectID": "Ecosystem_&_integration_Snapshot.html",
    "href": "Ecosystem_&_integration_Snapshot.html",
    "title": "44  Snapshot",
    "section": "",
    "text": "45 Handle snapshots with OSC\nDifferent snapshots actions could be launched by OSC messages. The complete list of them is available on the OSC Table C.\nThe snapshot name could be added in argument (optional).\nIndex: the snapshot index to recall. Used as an argument, it can be replaced by the snapshot name.\nTime: optional, it will define the recall time. If not given, the default value is 0s.\nRecall Effective Selection: optional, if the value is True, the sources’ selection on the snapshot creation will be recalled. It’s the default value. If False, selection will not be recalled.\nRecall Actual Selection: optional, if the value is True, only the parameters of selected sources’ will be recalled. Else, all the sources will be recalled (default behavior).\nEnable sources recall, Enable rooms recall, Enable masters recall: optional, enable to define if sources, rooms and masters parameters will be recalled. If not given, the default set value will be used.\nindex: the snapshot index to update. It can be replaced by the snapshot name.\nThis will return the list of the snapshot, index and name.\nThis will return the total number of snapshots.\nindex: the snapshot index to rename. Name: the new name of the snapshot.\nindex: the snapshot index to remove. :::{.callout-warning} can be replaced by the snapshot name.\nBe careful: there isn’t any confirmation. :::\nState: 0 will disable the recall of related objects, 1 will enable it.\nTiming: Timing in seconds.\n/snapshot/options/recall [State] [State] [State] takes the three options (sources, rooms and masters)"
  },
  {
    "objectID": "Ecosystem_&_integration_Snapshot.html#create-a-snapshot",
    "href": "Ecosystem_&_integration_Snapshot.html#create-a-snapshot",
    "title": "44  Snapshot",
    "section": "44.1 Create a snapshot",
    "text": "44.1 Create a snapshot\nWe can create a snapshot: - by using the Create action into the “Snapshots” menu, or the Create snapshot available on the snapshot bar. In this case, the snapshot will be added, following the current snapshot (if there is any). The shortcut Alt + Space could also be used to capture a snapshot (currently not working on Windows).\n\nby using the “Insert Before” action. This option is available only if another snapshot exists. The snapshot will be inserted before the selected snapshot, and all the snapshots will be renumbered.\nby using the “Insert After” action. This option is available only if another snapshot exists. The snapshot will be inserted after the selected snapshot, and all the snapshots will be renumbered."
  },
  {
    "objectID": "Ecosystem_&_integration_Snapshot.html#recall-a-snapshot",
    "href": "Ecosystem_&_integration_Snapshot.html#recall-a-snapshot",
    "title": "44  Snapshot",
    "section": "44.2 Recall a snapshot",
    "text": "44.2 Recall a snapshot\nRecalling a snapshot will interpolate all the current properties with the stored values of the snapshot. Different options located on the Snapshots page could alter the snapshot running:\n\nRecall relative\n\nThis option enable to keep differences between the current state and the current snapshots. More information about it on the snapshot page section 24.\n\nGlobal\n\nThis option enables to follow the global snapshot recall settings. It is also possible to setting up a particular one, disabling this option on the snapshot page.\n\nRecall time\n\nThis option is available in the menu “Snapshots/Options recall.” The values are ranged between 0 and 3600 seconds.\n\nRecall Sources / Room / Master\n\nAs all the properties are stored into snapshots, this option gives us the possibility to enable or disable the recall of some properties. The recall of each section could be separately activated.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful with the Room properties recall, changing some properties like Reverberation Density or Size causes reverb reconstruction (and audio drops).\nIf Ask for update before recalling option is checked and changes are detected between the current snapshot and current state, a window will propose to update the current snapshot if there are differences between the current state and the snapshot."
  },
  {
    "objectID": "Ecosystem_&_integration_Snapshot.html#snapshots-handling",
    "href": "Ecosystem_&_integration_Snapshot.html#snapshots-handling",
    "title": "44  Snapshot",
    "section": "44.3 Snapshots handling",
    "text": "44.3 Snapshots handling\nDifferent actions could be executed with snapshots:\n\nupdating a snapshot\nrenaming a snapshot\nremoving a snapshot\nremove all snapshots"
  },
  {
    "objectID": "Ecosystem_&_integration_ADM_OSC.html#adm-osc-in-spat-revolution",
    "href": "Ecosystem_&_integration_ADM_OSC.html#adm-osc-in-spat-revolution",
    "title": "45  ADM-OSC",
    "section": "45.1 ADM-OSC in SPAT Revolution",
    "text": "45.1 ADM-OSC in SPAT Revolution\n\n\n\nSPAT Revolution ADM OSC\n\n\nSPAT Revolution supports ADM-OSC in input as an alternate grammar, and on output as an option. The specification calls for normalized (linear) data value to provide interoperability and tend to align with the ADM protocol. Typically, object-based mixing renderers will handle the scaling based on the system configuration.\nSpecifications calls for:\n\nLinear 0.00,1.00 for Gain and LFE (aux send) messages\nInvert Azimuth to clockwise\nDistance normalized to 0.00,1.00\nXYZ to a normalized cube -1.00,+1.00 (square in 2D, XY)\n\nTo configure ADM-OSC, make sure OSC is enabled and go to the OSC Connection section in the software preferences.\n\nChoose an input | ADM preset to receive ADM-OSC data and select the receiving network interface.\nChoose an output | ADM XYZ (or AED) preset to send ADM-OSC data.\nEnter the IP address of the destination.\n\n\n\n\nOSC I/O presets\n\n\nOn the OSC input connection, you can see that Port #9000 is our default incoming port and that and ADM Transformation preset is applied to match the specification. To modify the incoming range (the automation zone), simply enter your desired value. In this example, we are scaling to -3.00, 3.00.\n\n\n\nOSC I/O presets\n\n\nOn the OSC output connection, you can see that port #9001 is our default sending port and that an ADM Transformation preset is applied to match the specification. To modify the incoming range (the automation zone), simply enter your desired value. In this example, we are sending data from the -3.00, 3.00 zone. All output options are already set with the preset.\n\n\n\nOSC I/O presets"
  },
  {
    "objectID": "Ecosystem_&_integration_ADM_OSC.html#third-party-example",
    "href": "Ecosystem_&_integration_ADM_OSC.html#third-party-example",
    "title": "45  ADM-OSC",
    "section": "45.2 Third party example",
    "text": "45.2 Third party example\nRecently, L-Acoustics released their new L-ISA controller that can now output ADM-OSC as an alternate method (hardware required) and is functional to be received by SPAT Revolution, for example. OSC messages can be sent using the ADM-OSC format and be interpreted identically by any ADM-OSC compatible device.\n\n\n\nL-ISA\n\n\nFurthermore, Nuendo V11 adds the support of external OSC renderers, by mapping bidirectionally the multi-panner\n\n\n\nNuendo"
  },
  {
    "objectID": "Third_Party_Integration.html",
    "href": "Third_Party_Integration.html",
    "title": "Third Party Integration",
    "section": "",
    "text": "In this final section, we will cover a few working scenarios integrating SPAT with different setups. Of course, third party systems are subject to many changes, and we cannot cover everything available. Please consider the following as guiding principles which should be applicable in general to other situations not featured here. If you need more specific help, don’t hesitate to contact FLUX:: Support and we will try to assist you."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#templates",
    "href": "Third_Party_Cockos_Reaper.html#templates",
    "title": "46  Cockos Reaper",
    "section": "46.1 Templates",
    "text": "46.1 Templates\nNew recent templates are available for use with Reaper. They are start sessions and can be used as examples to see how to integrate SPAT Revolution using the SPAT plugin suite SEND, RETURN and ROOM.\nA tutorial on How to set up SPAT Revolution with Reaper is available here for a quick dive into this integration.\nYou can download the following session templates:\nProject Sessions and Templates downloads.\n\nReaper Tutorial Template is the template used in the above video tutorial and includes send and return setup for rendering Binaural, 5.1 and NHK 22.2 output formats.\nBasic music REAPER is a basic template using send and return to render Stereo, 5.1, Atmos 5.1.4 output formats with Binaural monitoring.\nAdvanced multi-format REAPER is an advance template using send and return to render Atmos 7.1.2, NHK 22.2 and multiple binaural output.\nAmbisonic HOA mixing REAPER is a template for using 3rd order HOA and binaural monitoring output formats."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#reavolution",
    "href": "Third_Party_Cockos_Reaper.html#reavolution",
    "title": "46  Cockos Reaper",
    "section": "46.2 ReaVolution",
    "text": "46.2 ReaVolution\nRelease in 20.12 is ReaVolution. ReaVolution is an attempt to provide a customization to Reaper standard configuration in order to simplify its integration to SPAT Revolution and provide a complete simple immersive audio creation package.\nThe ReaVolution package includes macros (scripts), customized toolbars, system behaviour preference enhancements and makes the integration of SPAT Revolution to Reaper a charm.\nPlease follow this link for more information on ReaVolution 47."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#setting-up-sync",
    "href": "Third_Party_Cockos_Reaper.html#setting-up-sync",
    "title": "46  Cockos Reaper",
    "section": "46.3 Setting Up Sync",
    "text": "46.3 Setting Up Sync\nAs described in section SPAT PI : Local audio path 43, when you are using the Local Audio path, the buffer size and sample rate must be matched in both SPAT Revolution and Reaper. In SPAT, you set this in the preferences and in Reaper in the Audio Device preferences."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#setting-up-tracks",
    "href": "Third_Party_Cockos_Reaper.html#setting-up-tracks",
    "title": "46  Cockos Reaper",
    "section": "46.4 Setting Up Tracks",
    "text": "46.4 Setting Up Tracks\nIt is a good idea to work with Track Folder structure for your organisation.\n\nIn the above screenshot, the B-Format Master has been set to be a Folder Parent with 4-Track Channel. Reaper channel routing is set on a track by track basis, using the TrackIO Route button of each Track. All the Child tracks routed to the parent can be assigned to one of the four receiving channels on the Parent track. In this example, the W is assigned to Track 1 by setting the track Pan to the left and routing to parent Channels 1-2. Similarly, the X to Track 2 (setting the track Pan to the right). The Y Track is assigned to Parent Channels 3-4 and hard panned left and so on.\nAlternatively, an interleaved 4-channel audio file (B-Format audio in this example) can be placed on one Child Track, which has been specified to have 4 channels.\n\nNow different interleaved files in the same format can overlap and be composed on the same Track, and they will be summed to the Folder track, and therefore to the same virtual source/object in SPAT. All automation for that source should happen in the Envelope Lanes of the Parent Folder track."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#setting-up-spat-send",
    "href": "Third_Party_Cockos_Reaper.html#setting-up-spat-send",
    "title": "46  Cockos Reaper",
    "section": "46.5 Setting up SPAT SEND",
    "text": "46.5 Setting up SPAT SEND\n\nSimply insert the SPAT SEND plug-in on a Parent Track. This means that as the composition grows, you may have multiple Child tracks sending different audio material to the same virtual source/object in SPAT, through one SEND plug-in on the Parent Folder Track.\nThis is the least complicated way to build up a large project because the automation for the spatialization is managed in one place even though source material may be different at different stages of the composition. It is maybe not always necessary to have a different SPAT SEND source/objects for every single audio file. The source automation can change in the envelope lanes of the Parent Folder, making it so that one SPAT SEND is shared by child tracks with the same format. This will make more sense in practice.\nCheck the number of channels streamed between plug-in and SPAT. Press on the little COG wheel icon at the top corner of the SEND plug-in to open the plug-in preference menu. The SPAT IO Config should have inherited the Channel count of the Track, which you have specified in the TrackIO of the Reaper Track.\nIn the main page, enable Local Audio Path. If all is well, you will see the SEND appear as an input at the top of the setup environment in your SPAT Revolution application. If you do not see it, you can try clicking on Get send/return on the top actions or in Setup/Pipes/Get send return to force SPAT to look for virtual IO.\n\nIn the above screenshot, the Orange ’ BFormat ’ Send input is the one being routed by the SEND plug on the Parent Track on the previous example. At first, it will appear in SPAT as a Channel Based input by default - in this case it appeared as a 4.0 QUAD. If dealing with ambisonic 1st order such as AmbiX or B-Format, the input stream type in SPAT needs tobe assigned manually."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#optimization",
    "href": "Third_Party_Cockos_Reaper.html#optimization",
    "title": "46  Cockos Reaper",
    "section": "46.6 Optimization",
    "text": "46.6 Optimization\nThere are a couple of things to make sure to optimize the integration and avoid inconsistent behaviour:\n\n\n\n\n\n\nWarning\n\n\n\nDisable Full Plug-in State set by default in Plug-in Compatibility Preferences.\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n“Prevent Anticipative FX” should be enabled on tracks where SEND / RETURN are inserted."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#sourceobject-automation",
    "href": "Third_Party_Cockos_Reaper.html#sourceobject-automation",
    "title": "46  Cockos Reaper",
    "section": "46.7 Source/Object Automation",
    "text": "46.7 Source/Object Automation\n\nNow it is simply a case of adding some Envelope lanes for parameters you wish to automate from the DAW timeline. Here the B-Format source is being introduced from a distance automating Aperture, Warmth and Distance."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#setting-up-controllers-and-lfo",
    "href": "Third_Party_Cockos_Reaper.html#setting-up-controllers-and-lfo",
    "title": "46  Cockos Reaper",
    "section": "46.8 Setting up controllers and LFO",
    "text": "46.8 Setting up controllers and LFO\nIn Reaper, it is easy to map any MIDI controllers (including 14-bit) to a Plug-In parameter. This is a great way to control source properties like Azimuth or Yaw using external MIDI controllers, so you can control some sources live by hand during a performance or while mixing for example.\n\nIn the Automation parameter list for SPAT SEND just click on the LEARN... button to manually assign an external controller that you have set up in the Reaper Controller preferences.\nFrom this page by clicking on the MOD… button of an automatable parameter, it is also possible to animate sources with independent LFOs that run all the time in the background, quick and dirty way to spatialise live inputs sources with autopan type effects for example."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#setting-up-spat-return.",
    "href": "Third_Party_Cockos_Reaper.html#setting-up-spat-return.",
    "title": "46  Cockos Reaper",
    "section": "46.9 Setting up SPAT RETURN.",
    "text": "46.9 Setting up SPAT RETURN.\nNow, to render the scene from the multichannel room output to disk as an interleaved 3rd Order HOA, for example, we need to add a RETURN plug-in. We can calculate that 3HOA3D needs 16 channels.\n\nFirst, set up a Track in Reaper that can handle 16 channels at once. Then add a SPAT RETURN plug-in on this track. It should automatically inherit the channel count, if not do it manually using the IO config of the plug-in, available from the little cog wheel in the top corner of SPAT RETURN.\n\nEnable the Local Audio Path: you should see a Return output module appear in the SPAT Setup Environment. Connecting it to the 3HOA3D stream output from the Room (or Rooms in a mixer/transcoder) and it should inherit the format."
  },
  {
    "objectID": "Third_Party_Cockos_Reaper.html#recording-immersive-creation.",
    "href": "Third_Party_Cockos_Reaper.html#recording-immersive-creation.",
    "title": "46  Cockos Reaper",
    "section": "46.10 Recording Immersive creation.",
    "text": "46.10 Recording Immersive creation.\nTo do this, it is necessary to make Reaper record the software OUTPUT of the audio track:\n\nthe audio coming into the Track is a virtual audio path through the SPAT RETURN plug-in, so it will not appear at the Inputs list of the Track. Right-click on the record arm button on the track, and the Track record contextual menu will appear.\n\n\nArm the track to record, press play and render the scene to a 3HOA3D interleaved 16-channel WAV file (avoid using FLAC for higher than 8 channels). This is done in realtime.\n\nThe same process can be followed to render any Channel Based or other stream type from SPAT Revolution to disk for further composition, mastering or final delivery."
  },
  {
    "objectID": "Third_Party_ReaVolution.html#credits-acknowledgements",
    "href": "Third_Party_ReaVolution.html#credits-acknowledgements",
    "title": "47  ReaVolution",
    "section": "47.1 Credits & acknowledgements",
    "text": "47.1 Credits & acknowledgements\nReaVolution was developed by Jean-Loup Pecquais, between Orléans and Paris, from 2019 to 2020.\nThe author would like to acknowledge a few peoples:\n\nGael Martinet, FLUX:: Immersive CEO, to support and believe in this project\nHugo Larin, SPAT Revolution product manager & business Development at FLUX:: Immersive, for his help and interest\nNicolas Erard, to have tested almost every corner of ReaVolution and cramped my todo list with too many bugs report\nSylvain Lambinet, which has followed this idea from the very start and always inputted some great feedback\nJustin Frankel and the whole Cockos team to have put on the market such an incredible tool.\n\nReaVolution is built upon the following Reaper extensions:\n\nSWS extension : https://www.sws-extension.org/\nJS API extension : https://forum.cockos.com/showthread.php?t=212174\n\nReaVolution theme uses graphical elements provided to the Reaper community by the creator of the original Reaper 6 theme, White Tie."
  },
  {
    "objectID": "Third_Party_ReaVolution.html#introduction",
    "href": "Third_Party_ReaVolution.html#introduction",
    "title": "47  ReaVolution",
    "section": "47.2 Introduction",
    "text": "47.2 Introduction\nWhat is ReaVolution?\nReaVolution is an attempt to provide a customization to Reaper standard configuration in order to simplify its integration to SPAT Revolution and provide a complete simple immersive audio creation package.\nAt the base of ReaVolution is Reaper, a DAW developed by Cockos. It is a very stable and fully-featured DAW with lots of customization possibilities. With its high track channel count capacities on support for any speaker arrangements, it is one of the most complete flexible DAW regarding immersive sound production.\nAs the default configuration of Reaper is somehow of a blank slate to create your immersive sound workflow, ReaVolution provides a start point and customization that makes any first approach to Reaper and Spat work like a charm…\nReaVolution’s goal is to solve these common problems and smooth out the transition gap for users that comes from other DAWs.\nThis package includes macros (scripts), customized toolbars, system behaviour preference enhancements. The ambition of ReaVolution is to give a more pleasant starting point for users that are coming from other DAW while giving a new set function dedicated to immersive audio production."
  },
  {
    "objectID": "Third_Party_ReaVolution.html#table-of-content",
    "href": "Third_Party_ReaVolution.html#table-of-content",
    "title": "47  ReaVolution",
    "section": "47.3 Table of content",
    "text": "47.3 Table of content\n\nInstallation\nPresentation\nUse cases"
  },
  {
    "objectID": "Third_Party_ReaVolution.html#installation",
    "href": "Third_Party_ReaVolution.html#installation",
    "title": "47  ReaVolution",
    "section": "47.4 Installation",
    "text": "47.4 Installation\nIf you already are a Reaper user, don’t worry, ReaVolution will install itself next to your existing Reaper install. You will not loose your current customization and user data. If you wish to take some features from ReaVolution to your current Reaper install, simply use the user configuration import/export feature of Reaper.\nTo install ReaVolution, you need to follow this steps:\n\nDownload the latest version of Reaper on reaper.fm (currently v6.15)\nDownload the latest version of ReaVolution on the Flux center\nLocate the place of the ReaVolution folder. For MacOS users, go to your Application folder, and found the ReaVolution folder. For Windows users, go to C:\\Program Files\\Flux\\ReaVolution.\n\nOn MacOS, launch the install package and drag and drop the application into the ReaVolution folder.\nOn Win10, launch the install executable, choose “install as portable installation” and choose the ReaVolution folder as the install folder.\nIf you already have a Reaper (&gt; v6.xx) install, you can also copy paste the existing binary inside the ReaVolution folder.\n\n\nAnd that’s all!"
  },
  {
    "objectID": "Third_Party_ReaVolution.html#presentation",
    "href": "Third_Party_ReaVolution.html#presentation",
    "title": "47  ReaVolution",
    "section": "47.5 Presentation",
    "text": "47.5 Presentation\n\nWindows arrangement and menus\nThe basic layout of ReaVolution is a bit different from the default Reaper settings.\n\n\n\nreavolution.jpg\n\n\nThe transport bar is now at the top of the user interface. Just bellow there is the main toolbar. Here you will find all the main state you need to keep an eye on.\n\n\n\nmaintoolbar.jpg\n\n\nFirst is the play mode. When off, the play cursor comes back to its initial state when the playback is stopped. When on, the play cursor stays at its position when the playback is stopped.\nNext, there is a command to show/hide all the automation lane.\n\n\n\n\n\n\nNote\n\n\n\nThis action is also available with the shortcut “A”\n\n\nIn third, we’ll find the “Show takes lane” button. As its name implies, it shows/hides the different takes. It is very useful to organize its session and only see the various take when we actually need to edit them. It is also safer to turn it off to remove any risk to change a take by clicking on a wrong spot in the arrange view.\nIn the middle group of icons, we’ll first a toggle to activate the metronome. A right-click on it will open a complete metronome configuration window. Next, there is the Snap toggle. It allows snapping the items we move to the grid or other items. Then, we have something less common. This icon allows locking the time selection. The last button in this group is the ripple editing mode.\nThe third button group contains four actions. The first one automatically group newly recorded items when on. The second one links the automation point to the item position. This means that if the item is moved, the automation point will move with it. Then there is the master group toggle. When on the item’s groups are effective. When off, all item’s groups are set to off. Lastly, the foremost right icon activates the auto-crossfade option.\n\n\n\ntoolbar2.jpg\n\n\nOn the left side of the arrangement view, above the track panel control (TCP), there are two buttons. The red “M” one is a master mute, the other one is a master solo. If at any point one of the track is muted or soloed, the respective toggle will display on. By setting it off, it clears, respectively, all the mute or all the solo.\n\n\n\n\n\n\nNote\n\n\n\nTo display the mixer, use CTRL/CMD + =\nTo display the midi editor, use CTRL/CMD + M\n\n\n\n\nSPAT Revolution library\nReaVolution is designed to work seamlessly with the software SPAT Revolution developed by Flux:: Immersive. SPAT Revolution is a stand-alone application to create immersive sound content and support almost any surround sound technologies. Flux:: has also developed audio pipe technologies which allow sending audio from a DAW to SPAT Revolution using a VST/AAX/AU plug-ins. This is a very powerful tool, but it can be quite time-consuming to setup.\nReaVolution comes with a set of action that automates all the things that needs to be done prior to sending audio from Reaper to SPAT Revolution and work in pairs with the Audio Stream library to support any channel configuration.\n\n\nAudio Stream library\nThis library is the core of ReaVolution. Its goal is to provide a way to overcome the limitation that Reaper imposes on track format. By default, tracks and channels can only be even numbers. But in the real world, numerous audio streams come in odd channel numbers, mono being the really obvious one.\nHow does it work? the library uses the combination of a JSFX called “Audio Stream” and some scripts. This JSFX is present on every track and is used to store and display the stream type to the user. It supports the same streams as SPAT Revolution: channels based, HOA, Ambisonics, binaural and transaural.\n\n\nVarious library\nRouting library\nReaVolution comes with some powerful macro to quickly manage your routing task: sending tracks, creating busses, folders, you name it. It uses the Audio Stream library to support any kind of channel arrangement and be fully compatible with an immersive sound workflow.\nEditing library\nOne of the concerns of ReaVolution is to provide an editing experience closer to the industries standard. Editing is certainly with what most of the new Reaper’s user are struggling with. This library takes its inspiration in softwares that have made their proof in editing task: Pro Tools, Pyramix & Live.\nDDP library\nThis one is a little bonus. It actually was the first one done to satisfy some frustration of the author. Reaper comes with the full support of DDP files, but it is not very easy to create markers and editing them. This DDP library aimed to solve this with a simple set of scripts."
  },
  {
    "objectID": "Third_Party_ReaVolution.html#use-cases",
    "href": "Third_Party_ReaVolution.html#use-cases",
    "title": "47  ReaVolution",
    "section": "47.6 Use cases",
    "text": "47.6 Use cases\n\nCreating sessions\nEach new created track comes with a JSFX Audio Stream plug-in inserted. It does not process audio : it is a simple pass thru. If we open it, we will find no parameters to set and only GUI that display a number of channels/order and a color code that represent the stream type. This GUI is by default shown in the Reaper mixer (also called MCP).\n\n\n\n\n\n\nNote\n\n\n\nTo create a new track, you can either double-click in an empty part of the MCP, or of the TCP. You can also hit CTRL/CMD + N or CTRL/CMD + Shift + N to insert multiple tracks.\n\n\nAll this new tracks are by default mono tracks. We can insert track to a precise format by right-clicking in an empty area of the MCP or TCP and by searching the “Audio stream::insert track” menu. Inside you’ll find all audio format supported by the Audio Stream library.\nIn the same vein, we can set the audio stream of an already created track by right-click on it and going to the menu “Audio stream::set to”. This can also be done for a selection of tracks.\nIf you are working on a session that has not been created with ReaVolution, you still can use the “Audio stream::set to” menu. It will insert an Audio stream plug-in on each selected tracks.\n\n\n\n\n\n\nWarning\n\n\n\nInserting an Audio Stream plug-in will not be sufficient to display the stream type in the MCP. You have to right click on the instance and select “Show embedded UI”.\n\n\n\n\n\ncreateSession.gif\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen defining a channel based audio stream, you can either enter a number of channels (12 for example) or enter a speaker arrangement (5.1, 7.1, 7.1.4, 22.2 etc…).\n\n\nYou can also right click in an empty space of the mixer and select “Audio Stream::Insert track”. A pop up window will ask you how many tracks of the selected audio stream type you want to insert in your session.\n\n\nDealing with routing\nCreating auxiliary tracks\nTo send tracks to another one, we have three shortcuts : one for post-fader, one for pre-fader and one for pre-fx.\nA new auxiliary track gets his audio stream info from its source track. In other words, if you create an auxiliary track for a A-Format track, the destination track will also be A-Format.\n\n\n\n\n\n\nNote\n\n\n\nShortcuts:\nALT + S → Create auxiliary track (post-fader) ALT + Shift + S → Create auxiliary track (pre-fader) ALT + Shift + CTRL/CMD + S → Create auxiliary track (pre-FX)\n\n\nCreating busses\nIn Reaper, the concept of busses is merged with the concept of folders. A folder track has children tracks which are, by default, routed to their parent.\n\n\n\n\n\n\nNote\n\n\n\nTo create a bus, select the desire tracks to group and hit the command CTRL/CMD + G\n\n\nA bus created with this command checks the audio stream of each track and adjusts its number of channels to fit them all. It also looks at the parent channel of each track. For example, if you have one mono track going to 3-4 channels and another one going to 5-6 channels, it will create a bus routed to 3-4 and reroute the child track to 1-2 and to 3-4.\n\n\n\nbus.gif\n\n\nCreating multi-busses\nThis is a new concept brought by ReaVolution.\nWhen working with software like SPAT Revolution, we often encounter one problem. Let say we have a drum kit recorded with four microphones: kick, snare & stereo overheads. A common mixing workflow is to create a summing bus and do some processing on it (compression and/or EQing). But then, we can only fed a summed stream to SPAT Revolution and we cannot spatialized each element independently.\nHere comes the multi-busses. It is a simple trick actually. If we create a multi-bus from our drum kit, it will create a folder track where the kick is routed to channel 1, the snare is routed to channel 2 and the overhead are routed to channel 3-4. So each element has its channel so nothing is summed here.\nNow the trick is to use multichannel compatible plug-ins such as the Flux:: Immersive suite. Their compressors allow to “link” channels to have the same detection signal for all the channels.\nThis way we can have “bus-like” processing without losing the possibility of spatializing each element.\n\n\n\n\n\n\nNote\n\n\n\nTo create a multi-bus, select the desire tracks to group and hit the command CTRL/CMD + ALT + G\n\n\n\n\nSending tracks to SPAT Revolution\nAs discussed bellow, it is possible to send and receive audio to and from SPAT Revolution with the help of SPAT Revolution plug-ins suite. The “Send” plug-in allows to send audio from the DAW to SPAT and the Return plug-in receives audio from SPAT to the DAW.\nWithout ReaVolution, there is a certain number of things to do prior to correctly use this plug-ins. First, each track hosting a Send plug-in has to be routed to each track hosting a Return. This has to be done to be sure that the DAW does not process a “return track” before a “send track”.\nThen, each track hosting a SPAT plug-in has to be set to “prevent anticipative fx processing”.\nWhen all this set-up is done, we can guarantee a good sync between Reaper and SPAT Revolution. But it can be quite tedious to do manually.\nReaVolution comes with an action that do all of this automatically. With the help of the Audio Stream libraries, it does all the routing automatically. It can even handle multi-bus and access to child tracks’ information.\nThis action is found by right clicking on a track, inside the menu “SPAT Revolution”. It is called “Route selected tracks to SPAT Revolution”. This action will create a new auxiliary for each selected track, with the right routing, the right configuration and a SPAT Revolution Send Plug-in inserted.\n\n\n\nsendToSpat.gif\n\n\nAfter running this action, you should be done at least at 95% of your configuration.\n\n\nReceiving audio from SPAT Revolution\nTo receive audio from SPAT Revolution, simply create a track at the wanted format using “Audio stream::insert track”. Then, go back to the “SPAT Revolution” menu by right-clicking on the track we just created and choose “Receive audio from SPAT Revolution on selected track”.\n\n\n\nreceiveFromSpat.gif\n\n\nYou will find an option related to SPAT routing in the top bar menu, under Extension&gt;ReaVolution&gt;When tracks are routed to SPAT.\n\n\n\nreavolutionNewExtensionMenu.png\n\n\nThis option allows to configure the default behavior of sending audio to and receiving audio from SPAT Revolution. By default, the local audio path, which allows sending audio from Reaper to SPAT using virtual audio pipe, is on, the same as the thru option of SPAT send plug-in and the override option of SPAT Return plug-in.\n\n\nEditing audio\nThe editing workflow of ReaVolution has been thought to be simple and straightforward.\nFirst thing first, we need to discuss briefly about the basic mouse behavior in ReaVolution :\n\n\n\n\n\n\nNote\n\n\n\nLeft click/left drag : select time & items Right drag : select only items Middle click : change edit/play cursor position\n\n\nUsing the mouse\nIn ReaVolution, some scripts try to simplify the editing behavior. It tooks its inspiration from various DAWs, such as Pro Tools, Pyramix and Cubase.\nItems are now divided in two halfs. The top half handles the selection action and the bottom half handles the movement action. It is also displayed to user : when the mouse is over the bottom half of an item, the mouse cursor change to a “hand” cursor.\nBy default, ReaVolution makes the time selection and the loop selection totally independent. The time selection is drawn by left dragging the mouse over the arrange view or the top half of items. The loop selection is drawn by left dragging the mouse in the ruler.\nRegarding the time selection, it is now quite volatile and easy to clear. A simple click in the arrange view will clear it. The only exception is to click on the bottom half of an item inside the time selection.\nYou will also notice that the play/edit cursor is know very static. To move it, you can either left click in the ruler of the use the middle click of the mouse in the arrange view.\n\n\n\nmouseEditing.gif\n\n\nMoving items\nItems can be move by simply dragging them by clicking on the bottom half. It is also dependent on the time selection. There is no need to cut the items prior to move part of them. If the time selection is longer than the selected items, the time selection is trimmed to adjust to the item selection.\n\n\n\nitemMove.gif\n\n\nAdvanced mouse usage\n\nSelecting time between two items\n\nDouble clicking in an empty area of a track selects the time between two items or between the beginning of the session and the first item on the track.\n\n\n\nselectEmptyArea.gif\n\n\n\nQuickly move items\n\nReaVolution has some quick way to move items to the play cursor:\n\n\n\n\n\n\nNote\n\n\n\nW : move the start of the selected items to the cursor position\nX : move the end of the selected items to the cursor position\n&lt; : move snap offset of the selected items to the cursor position\n\n\nYou can set the snap offset of an item by using the mouse modifier SHIFT+CTRL and by clicking on the top half of the item.\n\n\n\nmoveItem.gif\n\n\n\nAutomatic ripple edit\n\nRipple edit is a very powerful feature to quickly edit and move lots of items. The problem is that forgetting to turn it off can do a lot of damage to a session.\nReaVolution comes with a set of shortcuts and mouse modifiers that take advantage of ripple editing without having to engage or disengage it.\n\n\n\n\n\n\nNote\n\n\n\nSHIFT + Left click : move item with ripple edit on all activated tracks SHIFT + CTRL/CMD + Left click : move item with ripple edit on selected tracks CTRL/CMD + Backspace : delete content of time selection CTRL/CMD + SHIFT + Backspace : delete content of time selection on selected tracks\n\n\n\n\n\nrippleEdit.gif\n\n\nUsing the keyboard\nReaVolution comes with a complete set of shortcuts to easily edit audio items. To make it really simple, a zone of the keyboard is dedicated to editing.\n\n\n\nkeyboard.jpg\n\n\nTo keep things logical, there is two sets of shortcuts provided by ReaVolution : an AZERTY one and a QWERTY one. By default ReaVolution is set in AZERTY. To change this layout, go to the action list (shift+?), click on “Key Map” and choose “Import shortcut key map”. In the newly opened explorer/finder window, choose the desire ReaVolution key map file. This key maps only affect the shortcut shown in this section.\n\n\n\n\n\n\nNote\n\n\n\nMouse editing :\nB : split item N : insert stretch marker H : Heal split in item G : group/ungroup items D : set item fade in F : set item fade out A or Q : trim item start S : trim item end Z or W : set time selection start X : set time selection end C : “special copy” V : “special paste”\n\n\nWith all of this, you should already have most of your editing workflow. There is a few ones more that depend on the cursor or time selection :\n\n\n\n\n\n\nNote\n\n\n\nCTRL/CMD + B : split all items that cross edit cursor or time selection ALT + B : trim selected item(s) to time selection CTRL + D : duplicate items (follow time selection) BackSpace or Delete : Remove items (follow time selection)\n\n\n\n\nThree and four points editing\nWhen we need to edit big chunck of audio, across multiple takes, it’s hard to beat Pyramix. It uses a “source-destination” system. Sources are the different takes and destination is our final editing. To do the actual editing, we set a time selection inside the source and put a cursor in the destination (3 points edit). The selected time selection will be copied at the destination cursor, moving later destination items further. Or we can also set a time selection for the sources and the destination (4 points edit). This way the selected source will be paste inside the selected time of the destination.\nReaVolution supports a similar way of editing with the shortcut C, V and ALT+V.\n\n\n\n\n\n\nNote\n\n\n\nC : copy source items V : paste source items at cursor position (move later items) ALT + V : paste source items inside the time selection\n\n\nZoom and movement shortcuts\n\n\n\n\n\n\nNote\n\n\n\nR : Zoom out arrange view T : Zoom in arrange view Mousewheel : Scroll thru tracks SHIFT + mousewheel : Scroll in the timeline CTRL/CMD + mousewheel : Zoom in/out arrange view ALT + Z : Go back to the last view/zoom position\n\n\nSome various useful shortcuts\nThese last shortcuts are not directly related to audio editing, but it can help with this task anyway.\n\n\n\n\n\n\nNote\n\n\n\nCTRL + ALT + Mousewheel : Waveform Zoom In/Out Shift + S : Toggle solo for selected tracks Shift + M : Toggle mute for selected tracks or selected items Shift + R : Arm/disarm selected tracks for recording CTRL/CMD + A : Select all items/all tracks CTRL/CMD + SHIFT + A : Select all items in time selection CTRL/CMD + R : Create a new region based on time selection M or Enter (num.) : Insert a marker at current position 0 : Toggle mute for selected items Alt + R or 3 : Record"
  },
  {
    "objectID": "Third_Party_ProTools.html#workflow",
    "href": "Third_Party_ProTools.html#workflow",
    "title": "48  Avid Pro Tools (2022 Update)",
    "section": "48.1 Workflow",
    "text": "48.1 Workflow\nAs mentioned in the integration documents and troubleshooting guide, using specific tracks (such as aux) as your SPAT object is the best practice for dealing with these sources/objects you are sending for external rendering. This way you can leave the session audio tracks and their channel insertions as they are, and simply send these audio tracks to the SPAT Revolution object tracks. This allows you to send a single audio track or multiple ones (stem) to the SPAT Revolution object tracks. Being with local audio integration (LAP) or alternate audio routing methods in single or dual computer setups (virtual audio bridge, network I/O, etc), this is flexible approach."
  },
  {
    "objectID": "Third_Party_ProTools.html#technical-articles",
    "href": "Third_Party_ProTools.html#technical-articles",
    "title": "48  Avid Pro Tools (2022 Update)",
    "section": "48.2 2022 Technical Articles",
    "text": "48.2 2022 Technical Articles\nRecent technical articles covers various aspects of Pro Tools integration.\n\nPro Tools integration to SPAT Revolution (2022) is a good overview of the different possible integrations.\nUsing Pro Tools routing folders with SPAT Revolution introduces the concepts of using routing folders as SPAT Revolution object tracks. (Requires Pro Tools 2020.03 and above)\nPro Tools 2022.9 AUX I/O routing with SPAT Revolution covers the Pro Tools newly AUX I/O & Bridge device feature (macOS) and how this can be used to route to/from SPAT Revolution the SPAT Object track and the various renders.\nReporting latency for delay compensation in SPAT Revolution covers the subject of reporting track latency when using Local Audio Path in order for SPAT Revolution to habdle delay compensation."
  },
  {
    "objectID": "Third_Party_ProTools.html#templates",
    "href": "Third_Party_ProTools.html#templates",
    "title": "48  Avid Pro Tools (2022 Update)",
    "section": "48.3 Templates",
    "text": "48.3 Templates\nTemplates downloads\nNew updated templates are available for use with Avid Pro Tools. They are .ptxt session template files and can be used as examples to see how to integrate SPAT Revolution, using the SPAT plug-in suite SEND, RETURN and ROOM. While some templates use the Local Audio Path (LAP) feature, others rely on alternate audio devices such as audio bridge on single machine computer or other high channel count audio devices in dual computer setup.\nThe Avid Pro Tools Session Templates is a complete .zip package of all the 6 available templates and can be copied to your Pro Tools Session Templates folder.\n\nmacOS and Windows: : Document/Pro Tools/Session Templates/\n\n\n\n\n\n\n\nWarning\n\n\n\nCreate a FLUX:: Folder for your templates\n\n\nAfter copying the templates to the proper folder, they will appear in the template in the Pro Tools dashboard:\n\n\n\nCreate a new session\n\n\nAll accompanying SPAT Revolution .JSON session file for the above templates are available as a single download as well: [SPAT Revolution Session Templates](https://public.3.basecamp.com/p/yoAYTeMkGK9mBdMaNkToj2HU).\nYou can download the following session templates and presets:\nPro Tools Templates and SPAT Revolution Sessions\n\nAVID Pro Tools – Basic Music Local Audio Path is a basic music template using Local Audio Path SEND and RETURN to render Binaural, 5.1, Atmos 7.1.2 output formats with Binaural monitoring. It contains 8 Mono and 4 Stereo object tracks.\nAVID Pro Tools – Multiformat Local Audio Path is a advanced multiformat template using Local Audio Path SEND and RETURN to render Atmos 7.1.2, NHK 22.2 (with 3 x 8 channel buses in Pro Tools) and 3 binaural outputs. It contains 8 Mono and 4 Stereo, 1 5.1 and 1 7.1 object tracks.\nAVID Pro Tools Studio – Audio Bridge (32ch) is a template for using audio interface for routing (single or dual computer) and is tested for support to Pro Tools 2022.09 AUX I/O & bridge feature. It renders Atmos 7.1.2, Binaural and HOA 3rd order. It contains 24 Mono and 4 Stereo object tracks for compatibility with Pro Tools Studio.\nAVID Pro Tools Studio – Local Audio Path (32ch) is a template for using Local Audio Path SEND and RETURN for routing (single computer). It renders Atmos 7.1.2, Binaural and HOA 3rd order. It contains 24 Mono and 4 Stereo object tracks.\nAVID Pro Tools Ultimate - Audio Bridge (64ch) is a template for using audio interface for routing (single or dual computer) and is tested for support to Pro Tools 2022.09 AUX I/O & bridge feature. It renders Atmos 7.1.2, Binaural and HOA 3rd order. It contains 32 Mono, 8 Stereo and 4 HOA 1st order object tracks.\nAVID Pro Tools Ultimate - Local Audio Path (64ch) is a template for using Local Audio Path SEND and RETURN for routing (single computer). It renders Atmos 7.1.2, Binaural and HOA 3rd order. It contains 32 Mono, 8 Stereo and 4 HOA 1st order object tracks.\n\n\n\n\n\n\n\nWarning\n\n\n\nMore object tracks can be added depending on audio interface and/or computer resources\n\n\nFor troubleshooting, please review the Appendix B - Troubleshooting B"
  },
  {
    "objectID": "Third_Party_ProTools.html#setting-up-sync-when-using-local-audio-path-lap",
    "href": "Third_Party_ProTools.html#setting-up-sync-when-using-local-audio-path-lap",
    "title": "48  Avid Pro Tools (2022 Update)",
    "section": "48.4 Setting Up Sync when using Local Audio Path (LAP)",
    "text": "48.4 Setting Up Sync when using Local Audio Path (LAP)\nWith the latest release of SPAT Revolution, buffer size in Pro Tools needs to be set to 1024 samples, in both ProTools and SPAT Revolution if using the Local Audio Path option. In ProTools, go to Setup/Playback Engine then set H/W Buffer Size to 1024 samples.\n\n\n\n\n\n\nNote\n\n\n\nWe highly recommend de-activating dynamic Plug-in processing.\n\n\n\nIn SPAT, go to Preferences/Hardware IO , then set:\n\nDevice: None\nExternal Sampling Rate: Enabled\nBlock Size: 1024\n\n\n\nThe SPATSync (aka dummy bus) and why\nQuite simply, all tracks or Aux object tracks that have a SPAT SEND need to be outputting to a common bus that is then feeding to each the input SPAT RETURN buses, in order for the SPAT Send to be computed before the SPAT Return. Using FLUX:: Immersive Pro Tools templates and sessions provided prevents the user having to do these steps.\nA simple, nice and clean way to handle SPATSync bus for all scenarios and formats is to create a 16-channels ambisonic dummy bus (the largest bus that Pro Tools supports) and include all the sub arrangements from mono all the way to 3rd order ambisonic: HOA3, HOA2, HOA1, Atmos 7.1.2, 7.1, 6.1, 5.1, 5, 4, LCR, Stereo and Mono. Whatever the track format SPAT SEND plug-in is, it can be sent to this dummy bus that can handle all the formats. Then all these buses are available to feed any SPAT RETURN whatever the channel count.\nThis is the strategy used in templates.\n\n\nPro Tools license versions\nThe Ultimate and Studio versions of Pro Tools are highly recommended because of the use of multichannel buses. Using a below version of Pro Tools forces us to return our audio streams by groups of maximum two channels. For example, you will need 12 SPAT RETURNS plug-ins (and 12 x 2-channels tracks) to return a 22.2 stream from SPAT Revolution.\nThis strategy is still used when dealing with channel-based format higher than the supported bus in Pro Tools. So for example for a NHK 22.2 bus, we can return this to 3 x 8-channels (7.1) bus or to 2 x 16-channels ambisonic buses where only 8 channels will be used on the second bus. So, Pro Tools Ultimate and Studio are highly recommended. Pro Tools Advance Multi-format template for SPAT Revolution reflects this."
  },
  {
    "objectID": "Third_Party_ProTools.html#spat-sourceobject-automation",
    "href": "Third_Party_ProTools.html#spat-sourceobject-automation",
    "title": "48  Avid Pro Tools (2022 Update)",
    "section": "48.5 SPAT Source/Object Automation",
    "text": "48.5 SPAT Source/Object Automation\nTo automate variable parameters in the SPAT rendering engine from Pro Tools automation lanes, it is necessary to activate the parameters for each plug-in instance first. This is already done in the above templates and track presets.\n\n\nTo do this one by one can be a laborious task. Save time by editing the Pro Tools preference for automation and enabling the ‘Plug-in Controls Default to Auto-Enabled’ option. When inserting a plug-in, all its parameters will then be available for automation automatically.\n\n\nSource/Object Index, moving from LAP to OSC\nAnother thing to keep in mind is that as you instantiate plug-ins, they generate automatically an Index # that gets used when in OSC mode (without local audio path enable). So, if you take a template (or a fully deployed session) and delete a bunch of plug-in instances or create new instances, you end up with a mix of index numbers which may mean manually having to change them later. That can be a tedious job when dealing with a larger session. Granted this is not important when using LAP, but the day that you decide to separate your playback of the rendering computer, disengaging the Local Audio Path (LAP), you end up with the same reality of Index # not reflecting your setup.\nThe rule of thumb is simple. The index # presents the Source # in SPAT Revolution and deleting (or re-ordering in the case of SPAT) will change the index number. When using the plug-in in OSC mode, this will have an impact on the source that the SPAT plug-in is speaking too."
  },
  {
    "objectID": "Third_Party_AbletonLive.html#templates",
    "href": "Third_Party_AbletonLive.html#templates",
    "title": "49  Ableton Live",
    "section": "49.1 Templates",
    "text": "49.1 Templates\nAbleton Live is a very well known DAW for its creative possibility and has been preferred by content creator since many years. The fact that audio tracks in Ableton Live are always stereo, or at least, they only support two channels audio streams, does bring limitation to dealing with multi-channels immersive content and the ability to return to Live the various streams.\nOne workflow is to use Ableton Live sources as objects to SPAT, use the SPAT plug-ins suite SEND and ROOM for automation parameters and route audio via various hardware audio interface (including virtual soundcards and network audio) in a single or dual computer setup. The dual scenario is preferred as this level of processing can become heavy on larger session, at a higher sample rate, and with much automation.\nIn order to use the Local Audio Path (LAP) feature of the SPAT SEND and RETURN plug-in, a workaround to the stereo limitation needs to be applied if wanting to integrate the audio portion in this manner.\nNew templates are available for use with Ableton Live. They are start sessions and can be used as examples to see how to integrate SPAT Revolution using the SPAT plug-in suite SEND and RETURN. Now let’s dive in how to use SPAT Revolution with Ableton Live and how our templates work.\nYou can download the following session templates:\nProject Sessions and Templates downloads.\n\nSimple Stereo Binaural Project Template\n\n\n\n\nLIVE_TMPLT__simpleStrBin\n\n\nThe console is organized in this way:\n\nThe eight first tracks are the one where you will put audio event or even live input.\nThen is a folder containing eight other tracks. Each of our audio input tracks are routed to one of these tracks. These tracks are hosting SPAT SEND plug-in. They are your SPAT sources/objects and the bridge between Live and SPAT Revolution.\nA “REC” folder contains another bunch of tracks. They are for recording your audio streams returning from SPAT Revolution.\nLastly are a couple of “return tracks”, as named after Ableton Live nomenclature, which host your SPAT RETURN plug-ins.\n\n\n\n\n\n\n\nNote\n\n\n\nTo keep the console organized, we put tracks inside folders.\nBut, as there is a SPAT SEND on each of the sending tracks, and as the recording tracks are routed straight to our audio interfaces, there will never be any audio on these folders."
  },
  {
    "objectID": "Third_Party_AbletonLive.html#daw-optimization",
    "href": "Third_Party_AbletonLive.html#daw-optimization",
    "title": "49  Ableton Live",
    "section": "49.2 DAW optimization",
    "text": "49.2 DAW optimization\nHow to bypass Ableton Live optimization\nAs you may now, Ableton’s DAW is very focus on live performance and comes with many optimizations to reduce CPU usage. Its strategy seems to deactivate every processing unit, like tracks or plug-ins, that does not receive any signal at their input and does not send any to their output. If a track is actively monitoring input, no optimization is applied.\nIf it may be very efficient from the point of view of CPU consumption, it is a real problem with our SPAT plug-ins. This means that if a track hosting a SPAT plug-in does not play audio for a certain amount of time, the plug-in will be deactivated behind the hood and SPAT Revolution will lose the sync.\nTo each problem, a solution\nTo overcome this behavior, we create a very simple Max4Live device which keep a track “alive”. It’s called “SyncBox”: it generates an inaudible pink noise to keep the processing of following devices on. To unsure a steady sync, you will have to add this device upfront every SPAT send devices in your session.\nIf you do not own a Max4Live device, you have to make sure each track hosting a SPAT SEND plug-in must be fed with audio at any time. Another trick may be to route a silent input of your audio interface to tracks hosting a SPAT SEND plug-in and activate the monitoring input to force these tracks to stay awake.\nHow to install our Max4Live device\nTo install our Max4Live device, simply go to your Ableton Live’s user library. If you don’t know where it is located, go to your preferences, under the tab “Library”. You will find the information like in the screenshot bellow.\n\n\n\nLIVE_TMPLT__simpleStrBin_userLib\n\n\nThen, from the User Library, go to this location:\nUser Library\\Presets\\Audio Effects\\Max Audio Effect\nNow, simply drop the SyncBox.amxd device in this folder. It can be downloaded here.\nSyncBox Optimization workaround"
  },
  {
    "objectID": "Third_Party_AbletonLive.html#ableton-live-routing",
    "href": "Third_Party_AbletonLive.html#ableton-live-routing",
    "title": "49  Ableton Live",
    "section": "49.3 Ableton Live routing",
    "text": "49.3 Ableton Live routing\nThe golden rule when working with SPAT Revolution plug-ins is to make sure each track containing a SPAT SEND plug-in is routed to every and each track containing a SPAT RETURN plug-in. This way, we are absolutely sure every SPAT SEND plug-in are processed before each SPAT RETURN plug-in.\nFor our purpose, Ableton Live has a very interesting type of track called a “Return track”. It is very similar to an auxiliary bus in an analog console. When a new return track is created in Ableton Live, all the audio and midi track are automatically routed to it. This is a very good solution to work with SPAT Revolution as it save us from a lot of routing we have to do in other DAWs.\n\nAudio source tracks\nYour audio tracks will have their audio to routed to “send only”. This way, they do not send any audio to the master track.\nSource audio are being play/read on these tracks. If you are wondering where their signal is going, just continue reading, it will become clear below.\n\n\n\nLIVE_TMPLT__simpleStrBin_inputIO\n\n\n\n\nObject tracks “Send to SPAT”\n\n\n\nLIVE_TMPLT__simpleStrBin_sendIO\n\n\nIn the “Audio From” section, you will notice that you are receiving audio from your source tracks. Again, these tracks are not routed to the master.\nYou will notice than these tracks have their send volume set to -inf dB. We do not need to send audio to validate the routing priority.\nIf you select one of this track, you will reveal a SPAT send plug-in and our SyncBox workaround.\n\n\n\nLIVE_TMPLT__simpleStrBin_chProcess\n\n\n\n\nReturn tracks\nOur return tracks in Ableton Live host our SPAT Return plug-in and are unrouted from the master.\n\n\n\nliveTemplate1_returnIO"
  },
  {
    "objectID": "Third_Party_AbletonLive.html#recording-the-immersive-creation",
    "href": "Third_Party_AbletonLive.html#recording-the-immersive-creation",
    "title": "49  Ableton Live",
    "section": "49.4 Recording the immersive creation",
    "text": "49.4 Recording the immersive creation\nNow that we have audio going to, and coming from SPAT, we can record our work to publish or archive it. As it is not possible to record audio on a return track in Ableton Live, the output of your return track are sent to the actual audio tracks.\nTo do so on a manual setup, we need to create as many audio tracks as we have return tracks hosting a SPAT RETURN plug-in. Then, for each new audio track, we will go to the I/O and under the label “Audio From” choose each return track. Now for the actual return track, we will unroute them from master. In the I/O of each audio tracks, we will go under the label “Audio to” and choose “send only”.\nLastly, to ear our audio, we will need to put the monitoring mode of our recording track on “In”. Of course, to record something we will also need to arm our audio track.\nIn the template, the tracks allocated to recording are configured to get their audio from the return track of Ableton Live. Their monitoring is switched on, and they are armed for recording. Also, their output is routed directly to the audio interfaces.\n\n\n\n\n\n\nNote\n\n\n\nYou will need to manually adjust this routing for your needs.\n\n\n\n\n\nliveTemplate1_recIO"
  },
  {
    "objectID": "Third_Party_AbletonLive.html#higher-number-of-channels",
    "href": "Third_Party_AbletonLive.html#higher-number-of-channels",
    "title": "49  Ableton Live",
    "section": "49.5 Higher number of channels",
    "text": "49.5 Higher number of channels\n\nDolby Atmos 7.1.4 and Binaural Project Template\n\nAs we discuss above, Ableton Live can only handle two channels audio streams. To overcome this limitation, we have to use several return plug-ins to get our signal from on a multichannel room output stream. In this template, we show how to return the audio from a 7.1.4 Dolby Atmos room. As we need 12 channels, 6 different SPAT stereo RETURN plug-ins are used.\n\n\n\nliveTemplate1_SpatSession\n\n\nThe internal routing in Ableton Live remains the same as in the earlier stereo & binaural template above."
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#introduction",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#introduction",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.1 Introduction",
    "text": "50.1 Introduction\nThis is a complete guide of a workflow with a set of custom-built Ableton Live Devices, created to increase significantly the compatibility between the DAW and SPAT Revolution.\nWe will focus on everything from downloading and installing the tools, setting them up, optimizing your computer, a complete description of the provided tools, and then the actual workflow and how to create an entire project in the most efficient way possible!\n\nWhy using Ableton Live with SPAT Revolution?\nMaybe Ableton Live is your main DAW and so the most obvious choice, this is the case for some of us at FLUX:: and is also why we created this workflow in the first place, but we would also like to add, that Live could be a great choice for anyone getting into creating, sound designing, etc… in an Immersive Audio Context.\nThe capabilities of Ableton Live in terms of automations are monstrous and so make this DAW an incredible tool for making great Immersive Audio content that will include lots of spatial movements and effects.\n\n\nWhy using SPAT Revolution at all?\nImmersive Audio is gaining more and more traction recently, Apple Spatial Audio, Dolby Atmos, Binaural, if you have been working in the music industry at any level this past few years you probably have heard of those.\nSo SPAT Revolution will help you to create and to expand ideas into a whole new world or should I say, into new spaces!\nAnd now after reading this guide, it will be as easy as making good old fader automation, as this is not just a do this and it will do that guide, but more of a do this and here why it does that, type of guide!\nThis guide works as a base and not an “end all be all”, any ideas on how to improve this workflow, the devices provided, the templates, and any other type of feedback is very welcomed!\n\n\n\n\n\n\nWarning\n\n\n\nDISCLAIMER: This workflow has been specifically thought of for maximum compatibility between Ableton Live and SPAT Revolution under macOS. Some parts of this guide (mainly the devices provided) can still be applied to Windows or/and other DAWs."
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#demo",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#demo",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.2 Demo",
    "text": "50.2 Demo"
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#installation",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#installation",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.3 Installation",
    "text": "50.3 Installation\n\n\n\n\n\n\nNote\n\n\n\nIf you already have a FLUX:: account as well as an iLok account and already have a SPAT Revolution License or Trial you can jump to the next section of the guide.\n\n\nYou can also follow this part with the dedicated video as well:\n\n\nSo we are going to first create our FLUX:: account here.\n\nDon’t forget that you need to activate your account, an email will be sent to your email address.\n(if you don’t see it, please check your spam inbox or search for the email directly using its name: “email address verification”)\n\nOnce your FLUX:: account has been created we are now going to create an iLok account here.\n\nFor those who don’t know, iLok is simple a license platform and will allow us to activate our SPAT Revolution license.\nSame as for the FLUX:: account don’t forget to activate your account with the email sent to you.\nWe are now going to download the FLUX:: Center and the iLok License Manager app.\nDownload: - FLUX:: Center: https://www.flux.audio/download - iLok License Manager app: https://ilok.com\nNow that both accounts have been created and activated, and both the FLUX Center and iLok license manager apps have been downloaded and installed, we can now link our iLok account to the FLUX:: account.\nTo do so simply go into the iLok Licenses section of your FLUX:: account, and follow the procedure.\nLast step is to go into the trial section and request a trial for SPAT Revolution Ultimate or Essential. The license will be automatically placed on your iLok account.\nNow open the iLok License Manager app and activate your license by drag and dropping it to your computer. You can then close the iLok app and open the FLUX:: Center.\nConnect to your FLUX account and download the SPAT Revolution, when you download the SPAT Revolution the plugins and the Ableton Live Tools for SPAT Revolution will be automatically installed as well.\n\nTools\n\nmacOS\nOnce the SPAT Revolution and the Ableton Live Tools for SPAT Revolution have been installed from the FLUX:: Center you can go look for them in the following folder /Library/Application Support/Flux/Ableton Live Devices/SPAT\nIt is possible to go to the folder location by opening the Finder and use the shortcut: CMD + Shift + G and copy the previous address.\n\n\n\n\n\n\n\nWarning\n\n\n\nPlease do not change the location of this folder.\n\n\nTo go faster later, you can add this folder to your Finder’s sidebar:\n\n\n\nWindows\nIf you are on Windows and want to use the devices, please download the archive from this link: download\nYou can place it anywhere on your computer and then add the folder to your Ableton Live using the Add folder in the sidebar of Live.\n\n\n\nVirtual Audio Driver\nIn order for this workflow to work, we will also need to get some Virtual Audio Drivers to route audio from Live to SPAT Revolution.\nFor our Virtual Audio Driver, BlackHole from Existential audio is my preferred choice as it is simple to install, has many options in terms of channel count, is free, and is open-source!\nYou can also have all the different versions (2ch/16ch/64ch) installed at the same time and have a different use for them simultaneously. We will see later in the guide that there are many ways this can be very helpful and how to take advantage of that, So my advice is to install them all.\nBlackHole virtual audio driver can be found here\n\n\n\n\n\n\nNote\n\n\n\nIf you plan to have a dual computer setup, you don’t have to get BlackHole. More on that workflow later.*\n\n\n\n\nUseful addition\nSoftware such as Loopback from Rogue Amoeba can be very useful to route audio between multiple devices/apps and can be a very good alternative to Aggregate and Multi-Output devices that you can already make inside the Audio MIDI setup of macOS.\n\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget to restart your mac after installing all that."
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#optimization",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#optimization",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.4 Optimization",
    "text": "50.4 Optimization\nNow that everything is installed, let’s optimize a few parameters in your macOS before getting into the setup.\nWhen working with SPAT Revolution, and this can extend to any other audio work, you do not want any interference or background apps refreshing that would consume even the tiniest bit of CPU, so disabling Bluetooth, Wi-Fi as well as AirDrop is a great way to start and very simple to do.\nYou can make it even more simply using the provided Shortcuts package we created to do just that. They are located in the same folder as the other device so: /Library/Application Support/Flux/Ableton Live Devices/SPAT/macOS Shortcuts\nWhat are Shortcuts?\nShortcuts is simply an app (native in macOS) that lets you combine multiple steps across multiple apps to create powerful task automations. To add the provided Shortcuts, simply double click each of them and select the Add Shortcut button.\n\nYou will have 3 shortcuts available:\n\nSPAT MODE ON: will disable WI-FI, Bluetooth, AirDrop, and start-up SPAT Revolution if it is not already running.\nSPAT MODE ON with WI-FI: all the same as the previous one but will let the Wi-Fi on if you are planning to use OSC control devices via Wi-Fi.\nSPAT MODE OFF: will start back the WI-FI, Bluetooth, and AirDrop.\n\nThese shortcuts are very simple to make using the Shortcuts app inside macOS if you want to modify them or make them yourself:\n\nOnce added they should appear in your top bar for easy access:\n\nOf course, you do not have to do this at all, everything else should work properly anyway, this is simply to save you a bit of CPU."
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#setup",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#setup",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.5 Setup",
    "text": "50.5 Setup\n\nAbleton Live\nBefore getting into the workflow we need to set up just a few things inside Live and SPAT Revolution.\nSo open Ableton Live and configure the following:\n\nMake sure Live is scanning for VST2 plugins\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you work with MIDI controller, we also highly recommend that you go into the Live Preferences, into the MIDI tab and change the Takeover Mode to Value Scaling so that parameters you play with don’t get too jumpy.\n\n\n\n\nSet BlackHole as your Output Device and enable all the channels of the driver:\n\n\nYou can do this part when you need more channels, the only advantage of doing it now is that you don’t have to do it later!\n\nAdd the SPAT folder containing the Tools using the add folder in the sidebar of Live:\n\n\n\nPlace on a track the devices SEND, ROOM and RETURN located in the SPAT Folder:\n\nThe small windows poping up are the actual spat revolution plugins, on which the devices are based on. They are here to host to parameters of the Sources (SEND), Room/Reverb (ROOM), Master Gain (RETURN) and send the automation data to SPAT Revolution using the OSC protocol.\n\nverify that they are all set on the following:\n\nIn IP: 127.0.0.1 (for all)\nIn Port (SEND): 8101\nIn Port (ROOM): 8102\nIn Port (RETURN): 8103\nOut IP: 127.0.0.1 (for all)\nOut Port: 8100 (for all)\nSEND:\n\n\n\nROOM:\n\n\n\nRETURN:\n\n\n\n\nSPAT Revolution\n\nOpen SPAT Revolution and go to the Preference panel to set BlackHole as the input device and your preferred Output device:\n\n\n\nActivate the OSC and set up the connection (find more about OSC configuration on the OSC documentation section 41.1:\n\n\n\n\nWhat is OSC?\nOpen Sound Control (OSC) is a protocol for networking sound synthesizers, computers, and other multimedia devices for purposes such as musical performance or show control. OSC’s advantages include interoperability, accuracy, flexibility and enhanced organization and documentation. The first specification was released in March 2002.\nHere, we will use the OSC to send the automation information made in Live to SPAT Revolution.\nWant to learn more about OSC? wikipedia.org"
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#devices-description",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#devices-description",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.6 Devices Description",
    "text": "50.6 Devices Description\nNone of those devices add any latency nor modification to the audio being pass through them, so do not worry about adding them anywhere in your chain!\n\nSEND\nThis device lets you control some of the most useful parameters inside SPAT for the currently selected source.\nYou will need to set up the OSC connection between Ableton Live and SPAT Revolution. The default settings of the plugins should already be set to connect with SPAT Revolution.\nPlease check the setup part of the guide to learn more about the OSC Connection.\n\n\nDEFAULT: Reset the parameters of the source to the default settings.\nGain: Configure the gain of the source.\nAzimuth: Configure the angle between the source location and the center reference point.\nElevation: Configure the elevation angle of the source.\nDistance: Configure the distance from the source to the center reference point.\nRoom Presence: Configure the prominence of the reverberation of the source.\nPresence: Configure the prominence of the direct sound.\nWarmth: Configure the presence of the low-frequency content part of the source.\nBrilliance: Configure the presence of the high-frequency content part of the source.\nEnable: Mute or un-mute the currently selected sources inside SPAT Revolution.\nReverb: Enable or disable the reverb inside SPAT Revolution for the currently selected source.\nDoppler: Activate the Doppler effect for the currently selected source.\nSpatRevolution-Send-x64: The original plugin on which the device is based, you can still access the individual parameters by un-folding the device or access the GUI by clicking the small key at the bottom.\nHow to use: This is a small notepad device with additional notes to prevent you from having to check back the guide if you forget something.\nMacro Controls: Click this button to hide the encoder knobs of the device (ref from n°2 to n°9)\nMacro Variation: Click this button to hide the macro variations (ref to n°1)\nShow/Hide Devices: Click this button to hide everything after the encoder knobs. (ref from n°10 to n°14)\nInfo View: This open/close Live’s built-in text info box, every parameter in the device has text info so this box might be useful if you need to know which does what.\n\nAdditional Information❗️\n\nAutomations:\n\nNote that Ableton Live takes over the automation parameters inside the DAW so you can move the source inside SPAT Revolution without the parameter moving inside Ableton Live. To fix this simply, right-click on the parameter in question and select Remove Mapping to Send.\n\nMoving the device in Live:\n\nMoving this device to another track instead of deleting and creating a new one will un-map the Enable, Reverb, and Doppler buttons. It is safer to delete the device first and then place a new one on the new track. It also could help you prevent any OSC Index related issues.\nDuplicating the track will result in the same issue. So you should manually place the device on each new track you create, although you can still duplicate your track (if needed) and simply delete the device and place a new one on the track.\n\nUndo/Redo:\n\nUsually in SPAT Revolution we currently cannot do undo/redo action, but in Live with this device it does work! As long as the action you are backtracking is something that has been operated inside Ableton Live directly.\n\nSEND - LAP: (available in the Alternate Versions folder)\n\nThe LAP version is exactly the same but is programmed to have the Local Audio Path activated right of the start if you prefer working with this instead of virtual audio drivers.\n\nSEND - Advanced: (available in the Alternate Versions folder)\n\nA more advanced version of the original device, with simply most of the available source settings inside SPAT Revolution.\n\nSEND - LAP - Advanced: (available in the Alternate Versions folder)\n\nA combo of the two versions described above, so Local Audio Path activated and more source control parameters.\n\n\nROOM\nThis device allows you to quickly control the reverb, you will have a lot more parameters available if you go directly into the Reverb settings inside your Room.\nYou will need to set up the OSC connection between Ableton Live and SPAT Revolution. The default settings of the plugins should already be set to connect with the SPAT Revolution.\nPlease check the setup part of the guide to learn more about the OSC Connection.\n\n\nDEFAULT: Reset the parameters of the Room to the default settings.\nGain: Configure the gain of the room.\nSize: Change the reverb size value.\nLiveness: Configure the relative decay time of high-frequency content, relative to the reverberance.\nCross HiFreq: Configure the frequency above which decay time is determined by the Liveness setting.\nReverb Gain: Configure the reverb gain.\nReverberance: Change the reverberance value.\nHeavyness: Configure the relative decay time of low-frequency content, relative to the reverberance.\nCross LowFreq: Configure the presence of the high-frequency content part of the source.\nReverb: Disable the reverb completely for the currently selected Room.\nEnable: Mute or un-mute the currently selected room.\nInfinite: Toggle the infinite more of the reverb, be careful with your gain when using this one.\nSpatRevolution-Room-x64: The original plugin on which the device is based, you can still access the individual parameters by un-folding the device or access the GUI by clicking the small key at the bottom.\nHow to use: This is a small notepad device with additional notes to prevent you from having to check back the guide if you forget something.\nMacro Controls: Click this button to hide the encoder knobs of the device (ref from n°2 to n°9)\nMacro Variation: Click this button to hide the macro variations (ref to n°1)\nShow/Hide Devices: Click this button to hide everything after the encoder knobs. (ref from n°10 to n°14)\nInfo View: This open/close Live’s built-in text info box, every parameter in the device has text info so this box might be useful if you need to know which does what.\n\nAdditional Information❗️\n\nAutomations:\n\nNote that Live takes over the automation parameters inside the DAW, so you can move the source inside SPAT Revolution and without the parameter moving inside Ableton Live. To fix this, simply right-click the parameter in question and select Remove Mapping to Send.\n\nMoving the device in Live:\n\nMoving this device to another track instead of deleting and creating a new one will un-map the Enable, Reverb, and Infinite buttons. It is safer to delete the device first and then place a new one on the new track. It also could help you prevent any OSC Index related issues.\nDuplicating the track will result in the same issue. So if you have more than one Room, you should create a new track and place the ROOM device manually.\n\nUndo/Redo:\n\nUsually in SPAT Revolution we currently cannot do undo/redo action, but in Live with this device it does work! As long as the action you are backtracking is something that has been oparated inside Ableton Live directly.\n\nROOM - Advanced: (available in the Alternate Versions folder)\n\nA more advanced version of the original device, with simply most of the available reverb settings inside SPAT Revolution.\n\n\nRETURN\nThis device allows you to control the gain of the selected Master. You can find this block between the Room and the final output.\nYou will need to setup the OSC connection between Ableton Live and SPAT Revolution. The default settings of the plugins should already be set to connect with the SPAT Revolution.\nPlease check the setup part of the guide to learn more about the OSC Connection.\n\n\nMacro Variations: Quick shortcuts to jump to specific values instead of using the encoder knob.\nGain: Set the gain of the currently selected Master.\nSpatRevolution-Return-x64: The original plugin on which the device is based, you can still access the individual parameters by un-folding the device or access the GUI by clicking the small key at the bottom.\nHow to use: This is a small notepad device with additional notes to prevent you from having to check back the guide if you forget something.\nMacro Controls: Click this button to hide the encoder knobs of the device (ref to n°2)\nMacro Variation: Click this button to hide the macro variations (ref to n°1)\nShow/Hide Devices: Click this button to hide everything after the encoder knobs. (ref from n°3 and n°4)\nInfo View: This open/close Live’s built-in text info box, every parameter in the device has text info so this box might be useful if you need to know which does what.\n\nAdditional Information❗️\n\nAutomation:\n\nNote that Live takes over the automation parameters inside the DAW so you can move the source inside SPAT and without the parameter moving inside Ableton Live. To fix this, simply right-click the parameter in question and select Remove Mapping to Send\n\nMoving the device in Live:\n\nUnlike the Send and Room devices which have specific M4L devices that can’t be moved from one track to another without being unfortunately un-mapped, you can easily move this device around without any issues.\nAnd again unlike the two previously mentioned devices with the return if you have more than one master in your SPAT Revolution session you can easily duplicate the track hosting the RETURN device and it will automatically set up everything correctly.\n\nUndo/Redo:\n\nUsually in SPAT Revolution we currently cannot do undo/redo action, but in Live with this device it does work! As long as the action you are backtracking is something that has been oparated inside Ableton Live directly.\n\n\n\n\n\n\nNote\n\n\n\n“Don’t forget to rename your tracks for an easier read of your session!”\n\n\n\n\n\nAutomator\nThe Automator device allows you to make the selected source move around in SPAT Revolution in a more organic and continuous way compared to traditional automation.\n\n\nMacro Variations: Quick shortcuts to reset to the default parameters of the device, you can create new macros to quickly change the automation of a source.\nRate (Note): The base rate of the automation (expressed in note values).\nRate (Hz): The base rate of the automation (expressed in hz).\nJitter: Introduces some jitter in the automation signal.\nSmooth: Smooths value changes (and jitter, as well).\nDepth: Depth of the LFO automation.\nStart Point: Shift the start point of the automation.\nShift: This allows you to shift the placement of the automation relative to other LFOs in Live (requires to restart the session to get all the LFO sync together).\nStyle: Change the automation style (Sine, Saw, Square, etc…).\nPlay/Stop: Play or stop the automation.\nRate Style: Toggles between Beat Sync and Free running (hz).\nLFO: The LFO is used to generate automation on the main SEND device, click the Map button, and then select the Azimuth parameter.\nMap: Click this button to activate the Map Mode, you can then click the parameter in the SEND device that you wish to automate.\nMultimap: This is the Multimap browser, it can allow you to map the same automation to multiple parameters, you can then tweak each one separately using the Min/Max percentage.\nHow to use: This is a small notepad device with additional notes to prevent you from having to check back the guide if you forget something.\nAutomator Guide: Same as the “How to use”, this one contains specific information about the different type of automation you can generate with the different LFO shapes.\nMacro Controls: Click this button to hide the encoder knobs of the device (ref from n°2 to n°9)\nMacro Variation: Click this button to hide the macro variations (ref to n°1)\nShow/Hide Devices: Click this button to hide everything after the encoder knobs. (ref from n°10 to n°16)\nInfo View: This open/close Live’s built-in text info box, every parameter in the device has text info so this box might be useful if you need to know which does what.\n\nAdditional Information❗️\n\nMoving the device in Live:\n\nMoving this device to another track instead of deleting and creating a new one will un-map the Play/Stop and Rate Style buttons, it is safer to delete the device first and then place a new one on the new track."
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#workflow",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#workflow",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.7 Workflow",
    "text": "50.7 Workflow\n\n\n\n\n\n\nNote\n\n\n\nWatching the corresponding video is highly recommended for this part.\n\n\n\nNow that we are completely setup, the formula is very simple:\n\nOptional Step: Use the SPAT MODE ON Shortcut to turn off your external connections\nOpen Live and select the “SPAT” folder in the Sidebar of Ableton Live\nOpen the “SPAT Default.als” Template\nOpen SPAT Revolution and load the Template “SPAT Default.json” from the same archive\n\nIf you have lost the location of the archive, it’s here: /Library/Application Support/Flux/Ableton Live Devices/SPAT/Templates\nWith both templates open, you will have a direct connection between Ableton Live’s output and your physical output so that you can start making music without thinking about spatialization in the first place.\n\nJust make sure your “Cue Out” and “Master Out” are both set to 1/2, that your Output device in Live is “BlackHole 64ch” and that your Input device in SPAT Revolution is “BlackHole 64ch” as well, the device controlling the output Level of Live directly is placed on the Master Track in Live\nYou can also note that the Ableton Live Template will setup a small group call “SPAT CTRL” which already contains a ROOM device and RETURN device, each on individual tracks for better visibility.\nThe ROOM device control the room gain and reverb in the room and the RETURN controls the master volume.\n\nYou can change the space you are working with by changing the Reverb using the device on the ROOM track inside Ableton Live but also in by clicking Reverb in the Room page of SPAT Revolution.\n\n⚠️ This will change the virtual space sonority but not what your actual output is, you can do change your speaker arrangement or stream type by going back to the setup page, select the Room block and you will have option, Stream Type, Speaker Arrangement (you can make or re-create your own), and the Panning Type used.\n\nNow, once you want to convert a track to an object in SPAT Revolution simply start by attributing a channel to the track in Ableton Live.\n\nDepending on which type of sound you are going to spatialize you have the choice between Stereo Tracks and Mono Tracks. We would for example attribute a Kick to a single channel as we want to keep it Mono, a pad to a stereo and so on. To be noted that the default parameters of the input block in SPAT is Mono\n\nThen go back to the SPAT Revolution Setup page and add an Input Block\nselect the same channel(s) your just attributed in Live and connect it to your Room\nNow you can go in the Room page and see your object in the 3D view of SPAT Revolution\nFrom there you can double-click the Source and Start playing with the parameters that will appear before you.\n\nYou can also click the ball in the 3D view and move it around in the Space\n\nYou can also add the “SEND” device from our “SPAT” folder in the sidebar of Live to Control the source directly from the DAW.\n\nWhen adding a “SEND” device to your track UI of the original send plugin will open you can take the type to rename the track in the plugin before closing the GUI so that the name translate automatically into SPAT Revolution.\n\nYou can also start automating it using traditional automation or the “Automator” device in the same folder as the other devices.\n\n\ndirect link if not loading: https://youtu.be/xarMJBSSwU0\nHappy Immersive Creating!"
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#printing-an-immersive-mix",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#printing-an-immersive-mix",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.8 Printing an Immersive Mix",
    "text": "50.8 Printing an Immersive Mix\n\n\n\n\n\n\nNote\n\n\n\nThis part is also available as a YouTube Video\n\n\n\nNow comes the time to think about how to render what we made inside Ableton Live and SPAT Revolution.\nThere’s a few strategies about this, which have multiples solutions, and a few factors to consider like the number of Room, Return, Channels, etc…\nBut the absolute main thing we cannot avoid is that we need to render real-time everything we made.\nLet’s have a use case to demonstrate how you can print our mix.\nHere is a session which we are going to render for the Binaural (3d on headphones) Version and at the same time generate a Bed for an Atmos render later.\n\nWe will start by creating an “Aggregate Device” in the “AUDIO MIDI SETUP” panel of macOS: \n\n\n\n\n\n\nWarning\n\n\n\nBoth Ableton Live and SPAT Revolution need to be relaunched to detect the newly created Aggregate.\n\n\nThen we will use this device as Output in SPAT Revolution and Input in Ableton Live, set the out channels of the binaural output block to the two corresponding channels of my 2ch device and the rest to the Atmos output.\nThen the only thing left to do is to create the tracks in Live that will receive the audio coming out of SPAT Revolution, routing them accordingly and press record and letting the thing play!"
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#from-single-machine-to-dual-computer-setup",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#from-single-machine-to-dual-computer-setup",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.9 From Single Machine to Dual Computer Setup",
    "text": "50.9 From Single Machine to Dual Computer Setup\n\n\n\n\n\n\nNote\n\n\n\nThis part is also available as a YouTube Video here: https://youtu.be/TnZSjCVULlQ\n\n\n\nThe process of switch this all workflow from a single computer to a dual one is fairly simple.\nBut why? If you have heavier Ableton Live Session and want to reduce the load on your computer is often the why here.\nWe will need two things to make it possible, beside having two computers of course.\n\na network audio solution such as MADI, DANTE, RAVENNA, etc…\nand a network switch to create send the OSC automations from the computer hosting Live to the one with SPAT Revolution\n\n\n\n\n\n\n\nNote\n\n\n\nWe could do it via a Wi-Fi network, but this isn’t the best in terms of speed and stability.\n\n\nSo now, let’s change the Output device in Ableton Live for our network audio solution, do the same for the Input device in SPAT Revolution.\n\n\n\n\n\n\nNote\n\n\n\nCheck that all the channels are active in Live\n\n\nDepending on which Network Audio Solution you use you might need to re-route some of your channels, as output one will not always mean it will go into input one.\nAnd now we need only to setup the new IPs as we are not sending the OSC automations localy.\nSimply go into the SPAT Preferences and change (in the OSC Connections part) the plugin Outputs to the IP address of the Live Computer.\n\n\n\n\n\n\nNote\n\n\n\nMake sure you are using the IP of the correct network if you work with multiple ones.\n\n\nSelect the corresponding IP for the plugin Input.\nNow we need to do the same inside for the spat plugins inside Live.\nGo back to Live open the plugin ROOM in your ROOM track, and put the IP address of the Computer hosting SPAT as the output and select the IP corresponding IP address as your input. Do the same for the RETURN, and the SEND.\nOf course don’t forget to check if the OSC is enabled in the preferences or SPAT will simply not receive anything.\nOnce this is done, our automation should now be received in SPAT.\nAnd that is it!"
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#uninstall",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#uninstall",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.10 Uninstall",
    "text": "50.10 Uninstall\n\nWith the FLUX Center\nTo Uninstall the Ableton Live Tools for SPAT Revolution with the FLUX:: Center, simply open the Center and click uninstall next to the Ableton Live Tools for SPAT Revolution.\n\n\nManually\nTo Uninstall the Ableton Live Tools for SPAT Revolution simply go to this location:\n/Library/Application Support/Flux\nAnd delete the Ableton Live Devices Folder."
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#credit",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#credit",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.11 Credit",
    "text": "50.11 Credit\nRyan Farber for his M4L device: (Simple One-Button Macro 2.0) - https://www.ryanfarber.com - https://www.maxforlive.com/library/device/5353/simple-one-button-macro\nELPHNT for his M4L device: (NTPD2 Lite) - https://elphnt.io - https://maxforlive.com/library/device/4997/ntpd-lite\nDevin Roth for creating BlackHole: - https://existential.audio - https://www.devinrothmusic.com\nTo the Ableton Team for making such an amazing DAW."
  },
  {
    "objectID": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#troubleshooting-qa",
    "href": "Third_Party_Ableton_Live_Tools_for_SPAT_Revolution.html#troubleshooting-qa",
    "title": "50  Ableton Live Tools for SPAT Revolution",
    "section": "50.12 Troubleshooting / Q&A",
    "text": "50.12 Troubleshooting / Q&A\n\n\nWindows?\nQ: Do you plan on making a Windows specific guide?\nA: Probably if we get some requests for it.\n\n\nOSC issues? (Automation not going to SPAT)\nIf a source in SPAT doesn’t seem to receive the Automation parameters please check the following:\n\nis the OSC Output port and IP Output in the send plugin (ref n°13 in the SEND description) match the ip and port inside the OSC settings (Preference panel in SPAT)?\n\n\n\nis OSC enabled (Preference panel in SPAT)\n\n\nIf you want to see if SPAT is correctly receiving the OSC messages you can activate the “Enable commands log” option which will now display every message received by SPAT in the Terminal.\nYou can open the SPAT Terminal with the following shortcuts:\n\nShow/Hide Terminal = F7\n\n\nShow/Hide Terminal (mini) = shift+F7\n\n\nPopup Terminal = cmd+F7\n\n\n\nalso make sure the OSC Index number in the SPAT plugin (inside the send device) match the number of the track inside SPAT Revolution\n\n\nYou can apply the same treatment to the ROOM and RETURN has well if the automations on those aren’t working too.\nSo to sum up again: - IP in/out check in both the plugins and in the SPAT Revolution Preferences - OSC Index check in both the plugin and the source number in SPAT Revolution - And of course, check if OSC is simply not activated\nIf you work with moving setup you might sometimes get an error showing the OSC Port in red. To fix it simply change the IP address to another network then go back to the original one.\nIf that doesn’t do it you can also change the OSC Port to something else, and then set back the correct port number.\n\n\n\nSPAT Revolution Essential license?\nQ: Is this workflow compatible with the Essential license of SPAT Revolution?\nA: Yes, you do not have to get the Ultimate version to start creating with this workflow.\n\n\nDemo Sessions?\nQ: Is there demo sessions so I can have a quick look?\nA: Yes they are located in the same folder as the rest of the tools located here: /Library/Application Support/Flux/Ableton Live Devices/SPAT/demo sessions"
  },
  {
    "objectID": "Third_Party_Nuendo.html#templates",
    "href": "Third_Party_Nuendo.html#templates",
    "title": "51  Steinberg Nuendo",
    "section": "51.1 Templates",
    "text": "51.1 Templates\nThe following session templates are available for use with Nuendo. They are start sessions and can be used as examples to see how to integrate SPAT Revolution using the SPAT plug-in suite SEND, RETURN and ROOM.\nYou can download the following session templates:\n\nSteinberg Nuendo Tutorial Template is the template used in the above video tutorial and includes sends and returns setup for rendering Binaural, Atmos 5.1.4, NHK 22.2 with binaural monitoring.\nBasic music NPR is a basic template using sends and returns to render Stereo, 5.1 and Atmos 5.1.4 output formats with binaural monitoring.\nAdvanced multi-format NPR is an advance template using sends and returns to render Atmos 7.1.2, NHK 22.2 and multiple binaural outputs.\nAmbisonic HOA mixing NPR is a template for using 3rd order HOA and binaural monitoring output formats.\n\nFor troubleshooting, please review the Appendix B - Troubleshooting B."
  },
  {
    "objectID": "Third_Party_Nuendo.html#nuendo-and-external-osc-rendering",
    "href": "Third_Party_Nuendo.html#nuendo-and-external-osc-rendering",
    "title": "51  Steinberg Nuendo",
    "section": "51.2 Nuendo and External OSC rendering",
    "text": "51.2 Nuendo and External OSC rendering\nStarting with Nuendo V11, it is now possible to deploy object-oriented sessions using open sound control (OSC). This brings the possibility to send/receive metadata from/to the Nuendo object VST MultiPanner. This functionality allows the support of SPAT Revolution as an external rendering engine using OSC thanks to the ADM-OSC 45 initiative. More information and specifications on the ADM-OSC initiative can be found on the dedicated GitHub repository, immersive-audio-live/ADM-OSC.\nOnce configured, you can playback or record object-oriented sessions (audio and metadata) for live production and immersive creations workflows while using SPAT Revolution mixing and rendering capabilities.\nAs Nuendo can import and export ADM files, this allows for an ADM master, exported from another environment, to be imported into a Nuendo session and mapped to SPAT Revolution. This integration brings the ability to render the object-based mix for various stream types (Ambisonic, Binaural, Channel-based), from standard to custom speaker arrangements and using multiple spatialization options and techniques.\nThe functioning is based around the declared ADM object approach in Nuendo. At the base, as soon as a track is being assigned to a multichannel output bus, the VST MultiPanner becomes available and can work in bed or object mode. Here, we are interested in the object mode that will give us the possibility to stream or listen to the object position.\nComplete information on dealing with objects in Nuendo available in their documentation, steinberg.help - Nuendo 11.\n\n\n\nObject-based in Nuendo V11"
  },
  {
    "objectID": "Third_Party_Nuendo.html#using-adm-osc-in-nuendo-use-cases",
    "href": "Third_Party_Nuendo.html#using-adm-osc-in-nuendo-use-cases",
    "title": "51  Steinberg Nuendo",
    "section": "51.3 Using ADM-OSC in Nuendo / Use cases",
    "text": "51.3 Using ADM-OSC in Nuendo / Use cases\nAlthough controlling SPAT Revolution source objects from Nuendo audio tracks is possible with the SPAT send plugin and the automation of it, the actual integration of the Nuendo VST MultiPanner with SPAT Revolution brings the ability to remain in the mixer environment. With this, users can stay within the typical mixer panner automation and use the same common remote control tools (HUI, MCU, and EUCON compatible controllers can be used, bringing tactile functionality to SPAT Revolution). It can be used with current sessions by simply adding the connection to SPAT Revolution as an external rendering tool, leading to a perceptual factors of objects and an acoustic simulation helping build soundscapes. Various use cases are possible:\n\nImport an ADM file from another environment, render with SPAT Revolution in channel-based (various panning and speaker arrangement formats) or scene-based (binaural, ambisonic up to 7th order).\nDeliver alternate formats from the same session you’ve rendered your Dolby Atmos deliverables.\nRe-render old sessions using the existing VST MultiPanner position but with SPAT Revolution as rendering engine.\nRecord all SPAT Revolution object position metadata (from live or studio) to the Nuendo VST MultiPanner(while still being able to use the SPAT Send for other parameters).\n\n\nSystem schematics - Nuendo and SPAT Revolution\n\n\n\nSystem schematics - Nuendo and SPAT Revolution - Software In / Hardware Out\n\n\nBasic setup where Nuendo is playing back to SPAT Revolution via software input and the system output / monitoring is going out directly to you audio hardware device in SPAT Revolution.\n\n\n\nSystem schematics - Nuendo and SPAT Revolution - Software I/O with SPAT Plugins\n\n\nSetup where you are using SPAT Send and Return Local Audio Path mode to route the signal to/from Nuendo and SPAT Revolution. The return(s) allows to bounce in Nuendo the rendering result and manage the monitoring bussing needs.\n\n\n\nSystem schematics - Nuendo and SPAT Revolution - Core Audio / Audio Bridge\n\n\nSetup where audio bridge devices are use to connect Nuendo to/from SPAT Revolution. Typical scenario involves masOS system with the audio bridge part of an aggregate device with your actual audio interface used for monitoring.\n\n\n\nSystem schematics - Nuendo and SPAT Revolution - Dual Computers\n\n\nTypical dual computer setup where AoIP AES67 (Ravenna), AVB, Dante or other multchannel audio interfaces such as with MADI are used to send and receive signals between Nuendo and SPAT Revolution.\n\n\nCreating an up to 64 objects session in Nuendo\n\nFirst create an empty Nuendo project\nIn the menu Studio / audio connection:\n\nDelete any outputs not required in the audio connection/studio menu.\nAdd Bus: 1 x 7.1.4 Atmos Master and 1 x 7.1.2 Bed (in some cases you won’t need the 7.1.2 as it would get created by the ADM import process if all goes well).\nMake sure output 1 to 64 remains unpatched, leaving this part of the patch to objects.\nPatch 7.1.2 bus to 65 to 74 and 75 to 84 for the Atmos master bus.\n\n\n:::{.callout-note} Even if you aren’t going to be using the Dolby capabilities of Nuendo and are planning only to render with SPAT Revolution, you need the 7.1.4 Atmos Master bus as this is being used to declared tracks as objects and assign objects IDs\n\n\n\nAudio Connection in Nuendo V11"
  },
  {
    "objectID": "Third_Party_Nuendo.html#nuendo-v11---setting-spat-revolution-as-external-renderer",
    "href": "Third_Party_Nuendo.html#nuendo-v11---setting-spat-revolution-as-external-renderer",
    "title": "51  Steinberg Nuendo",
    "section": "51.4 Nuendo v11 - Setting SPAT Revolution as external renderer",
    "text": "51.4 Nuendo v11 - Setting SPAT Revolution as external renderer\nThe first steps consist of configuring SPAT Revolution as the External Renderer. You can access the setup window by choosing External OSC Renderer setup in the Studio Menu.\nIn the Studio / External OSC Render setup menu:\n\nMake sure the OSC Data Transmission is activated.\nMake sure the port number is set to 9000, as it is the default SPAT Revolution ADM OSC preset input port.\nSet IP address to 127.0.0.1 (localhost) for single computer setup, or set the IP address of the second computer hosting SPAT Revolution (the rendering computer).\nHeader: Insert the ADM-OSC header message, /adm/obj/[index]/xyz\nDevice Port Mapping: Map All - 1 to 1\n\n\n\n\nNuendo OSC Renderer Setup"
  },
  {
    "objectID": "Third_Party_Nuendo.html#importing-adm-file",
    "href": "Third_Party_Nuendo.html#importing-adm-file",
    "title": "51  Steinberg Nuendo",
    "section": "51.5 Importing ADM File",
    "text": "51.5 Importing ADM File\nIn order to start you project from an existing ADM master file of another environment, go to the File menu and choose Import ADM\n\nSelect all tracks in the ADM import menu\n\n\n\n\nNuendo Import ADM\n\n\n\nWhen the import is done, make sure the Atmos_bed track is assigned to 7.1.2 output bus.\nSelect all Atmos_Obj and assign them to the 7.1.4 Atmos master bus created (Shift + Control + choose the 7.1.4 bus assignment to do them as a batch).\nKeeping all Atmos_Obj tracks selected (only, not the bed), go to the menu Project / ADM Authoring for Dolby Atmos. If objects already exist, start by deleting them.\n\n\n\n\nNuendo ADM Authoring for Dolby Atmos 1\n\n\n\nChoose External OSC renderer on the Renderer pulldown.\nMake sure Auto-Connect Objects Busses is marked.\nClick on the Functions arrow pulldown and choose Create Objects from the Selected Tracks.\nIt should create all what you need. All objects mapped to index 1 to N.\nNew output buses are getting created to match objects 1 to N.\n\n\n\n\nNuendo ADM Authoring for Dolby Atmos 2"
  },
  {
    "objectID": "Third_Party_Nuendo.html#nuendo-audio-connections-configured-for-object",
    "href": "Third_Party_Nuendo.html#nuendo-audio-connections-configured-for-object",
    "title": "51  Steinberg Nuendo",
    "section": "51.6 Nuendo audio connections configured for object",
    "text": "51.6 Nuendo audio connections configured for object\n\n\n\nAudio Connection in Nuendo V11 with Bus and Object outputs\n\n\n\n\n\nNuendo Surround VST MultiPanner in Object Mode"
  },
  {
    "objectID": "Third_Party_Nuendo.html#nuendo-object-position-to-spat-revolution-source-objects.",
    "href": "Third_Party_Nuendo.html#nuendo-object-position-to-spat-revolution-source-objects.",
    "title": "51  Steinberg Nuendo",
    "section": "51.7 Nuendo object position to SPAT Revolution source objects.",
    "text": "51.7 Nuendo object position to SPAT Revolution source objects.\nAfter the following setup details, object position data you have in your Nuendo session will be streaming to SPAT Revolution for an external rendering.\nAs this metadata is sent with normalized value according to the ADM-OSC specification, SPAT Revolution ADM-OSC input preset and transformation will allow scaling to the desired automation zone range.\nNuendo can as well receive normalized position data from SPAT Revolution ADM-OSC XYZ output (preset), map them to the VST MultiPanner (position tracking) and write automation data with the corresponding audio object if desired."
  },
  {
    "objectID": "Third_Party_Nuendo.html#setting-up-nuendo-osc-object-position-tracking",
    "href": "Third_Party_Nuendo.html#setting-up-nuendo-osc-object-position-tracking",
    "title": "51  Steinberg Nuendo",
    "section": "51.8 Setting up Nuendo OSC Object Position Tracking",
    "text": "51.8 Setting up Nuendo OSC Object Position Tracking\nThis next part covers incoming data to Nuendo. This would be to actually record the object information (from a live performance for example) to the Nuendo VST MultiPanner so ultimately use it as automation.\n\n\n\n\n\n\nNote\n\n\n\nAt the time of writing it is not recommend to configure the objects bi-directionally as some workflow challenges exist with object index ID when dealing with a mix of mono, stereo or multichannel objects.\n\n\nGo to the Studio menu and choose OSC Object Position Tracking.\n\n\n\nNuendo OSC Object Position Tracking\n\n\n\nMake sure Object Position Tracking is activated.\nMake sure port # is set to 9001. This is the default ADM-OSC output port for SPAT Revolution preset.\nStage Dimensions: This is the ability to scale incoming OSC into Nuendo. By default, it is currently at 0,1. This is not the default ADM-OSC specifcation. You can simply change this by entering -1.0 m as a minimum and 1.0 m as a maximum.\nTrack Mapping allows you to map the incoming Index from SPAT Revolution to the actual Nuendo object."
  },
  {
    "objectID": "Third_Party_Nuendo.html#spat-revolution-adm-osc-settings-for-nuendo",
    "href": "Third_Party_Nuendo.html#spat-revolution-adm-osc-settings-for-nuendo",
    "title": "51  Steinberg Nuendo",
    "section": "51.9 SPAT Revolution ADM-OSC settings for Nuendo",
    "text": "51.9 SPAT Revolution ADM-OSC settings for Nuendo\n\nADM-OSC Input setup\nIn the SPAT Revolution OSC Connection preferences:\n\n\n\nSPAT OSC settings for Nuendo ADM-OSC\n\n\n\nChoose Input ADM-OSC preset and select you network interface. If Nuendo and SPAT Revolution are on the same computer, choose Localhost 127.0.0.1, otherwise choose the network interface where OSC messages are incoming.\nYou can edit the transform double-clicking on it. This is where you will define the SPAT Revolution automation zone range (scaling to). For example, here we are using -3, 3.\n\n\n\n\n\n\n\nNote\n\n\n\nThe “scaling to” is you defining what will be the maximum position value when the Nuendo panner is in its extreme corners.\n\n\n\n\n\nModifying (edit) the transform of scaling\n\n\nYou are done for the input!\n\n\nADM-OSC XYZ Output to Nuendo\nThis configuration is for sending SPAT source objects data to Nuendo.\n\n\n\nADM XYZ Output\n\n\n\nChoose the Output ADM-XYZ preset and set the IP address of the Nuendo computer.(if local, use localhost .0.0.1)\nThe transformation preset is configured by default, as long as your OSC Object Position Tracking setup in Nuendo as stage dimensions -1.0, 1.0.\nYou can edit your automation zone (range) that you are sending to Nuendo. This is the same as used for input range. For example -3, 3.\n\n\n\n\n\n\n\nNote\n\n\n\nThe “scaling from” is you defining the SPAT Revolution position stage zone where object are sending to Nuendo in a normalized manner.\n\n\nEt voila! You are set.\nReady to move info an object-oriented workflow!"
  },
  {
    "objectID": "Third_Party_Bitwig_Studio.html",
    "href": "Third_Party_Bitwig_Studio.html",
    "title": "52  Bitwig Studio",
    "section": "",
    "text": "Bitwig Studio is a DAW designed in Berlin with a live hands on philosophy to it. Along with its highly animated and intuitive graphic interface, it offers well-designed clip-based and timeline arrangement paradigms for composing. The Bitwig designers have included a complete suite of powerful and great sounding native effects and digital instruments, with many performance and modulation features for any type of users. Its parameter modulators and their well-designed routing system make it compelling to create music and sound design in BitWig.\n\nSetting Up Sync in BitWig\nWhen using the Local Audio path (LAP), the buffer size and sample rate must be matched in both SPAT Revolution and Bitwig Studio. In SPAT, you do this in the preferences, and in Bitwig, you do in the audio engine settings. If they don’t match at first, you may need to restart both applications to get the correct green sync status between the apps.\n\n\nSetting Up Tracks in BitWig\nOne good way to work with Bitwig and SPAT together is to set Bitwig tracks to output their audio to Effect Track types - they are like Aux busses in other software you do that routing from an audio track output assignment settings.\n\nSetting Up SPAT SEND in BitWig\nPut the SPAT SEND plug-ins on individual Effect Tracks, enable the local audio path with THRU set to off, so all audio streams are rendered to output in SPAT Revolution.\n\nLike in all Local Path Audio workflows, you should see SPAT SEND inputs appearing in the SPAT Environment Setup, which relate directly to the plug-ins hosted in the other software environment, reflecting their TrackName and channel count.\nSPAT Source Automation in BitWig\nNow the fun starts - on the Bitwig Send tracks, which host the SPAT SEND plug-ins, you will see all the parameters of SPAT sources available as dials.\nUse the Bitwig + to open the Device Parameter Modulators and assign the many and varied modulation sources to control Azimuth, Distance or other Source Parameters.\n\nSetting Up Controllers in BitWig\nBitWig has comprehensive support for many popular MIDI controller surfaces. These can be very easily mapped to SPAT SEND parameters for hands on control of virtual objects and rooms.\nTroubleshooting\nFor troubleshooting, please review the Appendix B - Troubleshooting B"
  },
  {
    "objectID": "Third_Party_Figure53_QLab.html#qlab-5",
    "href": "Third_Party_Figure53_QLab.html#qlab-5",
    "title": "53  Figure53 QLab",
    "section": "53.1 QLab 5",
    "text": "53.1 QLab 5\nStarting with QLab5, the network type cue (OSC messages) has been substantially revamped and now includes support to directly control SPAT Revolution. Over 100 predefined messages for SPAT Revolution are now possible, including project, source, room, master and snapshot control messages.\n\n\n\nQLab5\n\n\nEarlier provided template (QLab 4) of actual examples of remote control message for SPAT Revolution are no longer needed to assist with programming."
  },
  {
    "objectID": "Third_Party_Figure53_QLab.html#qlab-5-integration-template",
    "href": "Third_Party_Figure53_QLab.html#qlab-5-integration-template",
    "title": "53  Figure53 QLab",
    "section": "53.2 QLab 5 Integration template",
    "text": "53.2 QLab 5 Integration template\nNew QLab 5 template will be provided shortly"
  },
  {
    "objectID": "Third_Party_Figure53_QLab.html#qlab-4-integration-template-v4-validated",
    "href": "Third_Party_Figure53_QLab.html#qlab-4-integration-template-v4-validated",
    "title": "53  Figure53 QLab",
    "section": "53.3 QLab 4 Integration template (V4 validated)",
    "text": "53.3 QLab 4 Integration template (V4 validated)\nThis template shows how you can manage SPAT Revolution and QLab integration on the same machine, using SPAT Revolution Send plug-ins. Both QLab and SPAT Revolution session are included, with 16 Mono and 8 Stereo SPAT Send on cue outputs. This template is SPAT Revolution Essential compliant, for binaural and Channel-based setups.\nQLab templates are available in EURO and US Version, using comma or period for denoting the decimal. (such as the decimal used in interpollation time)\nQLab 4_SPAT Revolution_ integration EURO.qlab4 QLab 4_SPAT Revolution_ integration US.qlab4"
  },
  {
    "objectID": "Third_Party_Figure53_QLab.html#generic-qlab-templates-v4-compliant-with-v5",
    "href": "Third_Party_Figure53_QLab.html#generic-qlab-templates-v4-compliant-with-v5",
    "title": "53  Figure53 QLab",
    "section": "53.4 Generic QLab Templates (V4, compliant with V5)",
    "text": "53.4 Generic QLab Templates (V4, compliant with V5)\nQLab SPAT Revolution snapshot carts.qlab4\nThis template shows how you can manage SPAT Revolution snapshots within QLab and have some carts for quick actions. It demonstrates how interpolation time value can be used in the snapshot recall messages.\nQlab SPAT Revolution snapshot carts EURO.qlab4 Qlab SPAT Revolution snapshot carts US.qlab4\n\n\n\nSPAT Snapshot message with interpolletation time\n\n\nQLab SPAT Revolution OSC Message examples\nThis template is our updated template and includes many cue examples using various messages types in SPAT Revolution.\nBeyond direct cue send actions, it brings 1D and 2D fade (Parameter ramp, 2D trajectories and more). As of QLab4 there is a time interpolated 2D fade system for creating spatial XY gestures or similar multi parameter control ideas. X/Interpolation time value can always be used directly in your messages as well as shown in some template examples. With the latest release of SPAT Revolution, the ability to send messages to the currently selected source (s) with index -1 is shown in this template as well.\nQlab SPAT Revolution examples EURO.qlab4 Qlab SPAT Revolution examples US.qlab4\n\n\n\nSPAT Message with interpolletation time\n\n\n\n\n\n2D Fade - trajectory messages"
  },
  {
    "objectID": "Third_Party_Figure53_QLab.html#configuring-qlab---spat-for-messages-via-network-cues",
    "href": "Third_Party_Figure53_QLab.html#configuring-qlab---spat-for-messages-via-network-cues",
    "title": "53  Figure53 QLab",
    "section": "53.5 Configuring QLab -> SPAT for messages via network cues",
    "text": "53.5 Configuring QLab -&gt; SPAT for messages via network cues\nIn a realtime situation, where performers or sounds are being spatialized live by SPAT Revolution, and cues need to be sent in the right running order with the rest of the show, Network OSC type cues can be sent from QLab to SPAT Revolution to control all aspects of the SPAT rendering software. To do this interaction, it is necessary to setup the OSC communication. It is relatively straightforward. In the SPAT Revolution preferences make sure the OSC Enable is engaged.\n\n\n\nSetting the OSC Connection\n\n\n\n\n\n\n\n\nNote\n\n\n\nEnable commands log to view the commands and confirm you are receiving data (Shift + F7 will open the log window). It is not recommended leaving it active all the time as it takes some system resources.\n\n\nSetting the OSC Connection \nGo to the OSC connection section of SPAT Revolution and:\n\nChange the pull down menu from None to the Input | Custom preset (meaning you are setting an OSC Input of Spat).\nSelect the network interface you want to be receiving the commands from. Doing a local integration of QLab will require you to choose the localhost / loopback address 127.0.0.1.\nUnless you are already using the Port #8000 proposed, you do not need to change it. This is the corresponding QLab Network Patch Output Port used in templates.\n\nQLab Workspace Settings / Network\n\nOn the QLab side, use the Network Patch settings to configure OSC destinations. One of them can be SPAT.\nYou can now send OSC network cues from QLab to SPAT, and control most if not all parameters of this virtual environment using Appendix C - OSC and ADM-OSC Table C. Once you get the hang of it, this is really very straightforward.\n\n…"
  },
  {
    "objectID": "Third_Party_Avid_VENUE_S6L.html#configuring-osc",
    "href": "Third_Party_Avid_VENUE_S6L.html#configuring-osc",
    "title": "54  Avid VENUE S6L",
    "section": "54.1 Configuring OSC",
    "text": "54.1 Configuring OSC\nNow let’s look at configuring the control (OSC) part of this integration. The OSC settings (SPAT send plug-in and SPAT Revolution) are specific to your console IP address and to the SPAT Revolution preferences.\n\nSPAT Send plug-in in the Plug-Ins rack of VENUE\n SPAT Send plug-in setup\nThe PI interface doesn’t have much and is straight forward:\n\nTrack name doesn’t get populated by S6L as you insert it to a channel. That said, If connected to SPAT Revolution, changing the track name to your desired name will rename your source/object name in SPAT Revolution software! Names are part of snapshots as well. The below SPAT / S6L templates have all the start naming set!\nIndex refers to the object/source number in SPAT Revolution application. This gets automatically generated every time there is a new instance of SPAT sent plug-in in the console plug-in rack. It can be changed by snapshots, but it is unique and no instance can take over a currently used index. As Index number is part of snapshots, be careful not to change them after creating snapshots or while using snapshots.\nIn IP: Pull down menu will allow you to choose the ethernet interface you will be listening to OSC commands in the S6L coming from SPAT Revolution. You will need this address for setting up SPAT preference later. This can be the AVB port 169.254.x.x, or your ECx port network interface of the console depending on the integration route. In the above example, ECx interface with IP 192.168.1.203 is chosen.\nIn Port#: This port #9101 is already set for you and matches the corresponding Port# used by the SPAT Revolution OSC preferences / Avid S6L preset. It can be left to default unless conflicting with other OSC traffic.\nOut IP: This IP address is the manual address (above example 192.168.1.201) that your Primary SPAT Revolution computer is configured at.\nOut Port#: This port #9100 is already set for you and matches the corresponding Port# used by the SPAT Revolution OSC preferences / Avid S6L preset. It can be left to default unless conflicting with other OSC traffic.\nOSC second output activates OSC messages to a second SPAT computer (such as your backup/ redundant computer engine). Output IP is the destination IP so the IP of the second SPAT computer. Same port# as primary is already set for you and matches the corresponding Port# used by the SPAT Revolution OSC preferences / Avid S6L preset. Note that the backup computer is not bidirectional to S6L and will only receive messages. So SPAT Primary computer is the one that is bi-directional (so updating plug-ins live with movements so you can take a snapshot of it).\n\n\n\n\n\n\n\nNote\n\n\n\nNote that any changes you do to properties to the SPAT Send interface gets done across the board (across all PI instances, except the index which is unique)."
  },
  {
    "objectID": "Third_Party_Avid_VENUE_S6L.html#setting-the-preferences-of-the-spat-revolution-application",
    "href": "Third_Party_Avid_VENUE_S6L.html#setting-the-preferences-of-the-spat-revolution-application",
    "title": "54  Avid VENUE S6L",
    "section": "54.2 Setting the preferences of the SPAT Revolution Application",
    "text": "54.2 Setting the preferences of the SPAT Revolution Application\nLet’s now setup your preferences in SPAT Revolution preferences page:\n\nHit preference in the top right corner. Look for the OSC Main section. First, you want to make sure the checkbox OSC Enable is engaged.\n\nSPAT OSC Main Preferences\n\n\n\nSPAT OSC Main preferences\n\n\n\nIn the OSC Connections section, you will see 8 OSC connections slots. Set one connection to Input Avid S6L and one to Output Avid S6L. We will use 2 slots for this. Output will be to go to S6L SPAT Send Plug-in, In will be to listen to S6L in SPAT Revolution.\n\nSPAT OSC Connections Matrix\n\n\n\nSPAT OSC Connections Matrix\n\n\n\n\n\nSPAT OSC Connections Matrix\n\n\n\nSPAT OSC Connections preferences\n\nSet the In IP address by pulling then the menu and choosing the network interface of your SPAT engine computer (for example the 192.168.0.201 of whatever network interface/IP you are using for this communication as long as it is in the same network range as the console IP address).\nThe input side (receiving the OSC parameters from the Out IP of the console) doesn’t need anything specific as the OSC input is ready for Avid S6L. You simply need to choose the Input | Avid S6L preset. As mentioned above in the S6L setup, the port # is predefined to port #9100 on both side (PI and SPAT OSC preset for S6L).\nOn the OSC output connection, you will simply need to choose the Output | Avid S6L preset and put the destination IP of the console, see above 192.168.1.203. The port # is already predefined (9101) and matching the Avid SPAT Send PI Input. Port #9101. This IP address is the IP address found in the PI interface (most of the time the ECx port IP setting). With the preset, the default output option checkboxes are all set for S6L.\n\n\n\n\n\n\n\nNote\n\n\n\nIf desired, OSC Log can be seen for testing. In the SPAT OSC Main section, you can use the “Enable commands logs” option in order to confirm OSC communication. Pressing Shift + F7 or going to the help menu of SPAT will give you option for a mini log window to see if the traffic is flowing as you are moving a source either in SPAT software or on the parameters on the PI encoders. It is not recommended to leave commands logs enabled past the confirmation testing step. This will ensure that you don’t take up resources."
  },
  {
    "objectID": "Third_Party_Avid_VENUE_S6L.html#configuring-audio-connections",
    "href": "Third_Party_Avid_VENUE_S6L.html#configuring-audio-connections",
    "title": "54  Avid VENUE S6L",
    "section": "54.3 Configuring Audio Connections",
    "text": "54.3 Configuring Audio Connections\nLet’s now look for the Hardware I/O connection. This is where you will configure the hardware input and output (audio interface) for SPAT Revolution.\nSPAT Hardware IO (Audio) preferences – AVB example \n\n\nIn Devices, please select your Core or ASIO audio device. In this example, we are using the AVB Core Audio E6 Engine, but this could be as well your MADI interface of choice such as an RME MADIface, MADIface XT, Soundgrid MADI device or any preferred interface. Not that the choice of interface will have an impact on your overall possible system latency combined with the computer hardware.\nSample rate should be set at 96000 Hz (unless sample rate converting from the S6L to 48K), and buffer can be set to your desired buffer (mind lower buffer requires a qualified computer and optimized resource).\n\nCongratulation, you are done! You’re ready to go to the setup page in SPAT and configure your Spatial audio system."
  },
  {
    "objectID": "Third_Party_Avid_VENUE_S6L.html#templates",
    "href": "Third_Party_Avid_VENUE_S6L.html#templates",
    "title": "54  Avid VENUE S6L",
    "section": "54.4 Templates",
    "text": "54.4 Templates\nAs of SPAT Revolution version 20.12.0, we are proving our users with 3 different start templates that can help them built their session or simply review an example of SPAT Revolution integration. They have been updated on our latest release, built with S6L v6.3 and qualified/tested for S6L V7.\n\nTo note that show files built with SPAT Send version 48020 or 48049 can’t use SPAT Send 20.12.0. Version 48049 is the version to use for these older showfiles. That said, SPAT Revolution 20.12 release works good with these older sessions (nothing prevents a user to update to the latest SPAT Revolution just keeping the old SPAT Send version for show file (snapshot) compatibility.\n\nSPAT_S6L_V7_64MONO_20_12\nSPAT_S6L_V7_64MONO_20_12 is the exact same template file as we provided before. It is for the model that all channels are being sent to the spatial renderers. Channel 1-64 have a SPAT instance inserted and its direct out post-fader signal are assigned to MADI card 1, 1-64 and in parallel connected to the PTAVB entity channel 65-128 (for alternative routing that some have used). MADI 1-2 is patched to Stereo channel 65 as a means of return of the binaural room (and headphone mix) coming from the SPAT template session (.JSON file). The S6L file contains 3 snapshots: - Reset all, resetting all sources to default position without reverb (acoustic simulation) and 2 other test snapshots called - Circle and Horizontal Line. plug-ins are set with a 2 seconds interpolation time showing how time value is used to smooth out transitions. The accompanying SPAT session file contains the 64 sources/objects connected to a Binaural Room as a start point.\nSPAT_S6L_V7_32MONO_16ST GROUPS_20_12\nSPAT_S6L_V7_32MONO_16ST GROUPS_20_12 contains an S6L file with 32 Mono SPAT send sources/objects ready to be inserted on the channels you are using as direct out to SPAT Revolution. These are name source/object 1-32. The file is all well ready with 16 Stereo groups for your source/object stems (33-48). Two test snapshots are preconfigured to reset all source positions and one as a snapshot test recalling all sources in a horizontal line. Plug-ins are set with a 2 seconds interpolation time showing how time value is used to smooth out transitions. The accompanying SPAT session file contains the 48 sources (32 mono and 16 stereo) connected to a Binaural Room as a start point (It’s a 64 channel of audio setup). The audio routing is not applied yet on this file but post fader pick off point option is set in order to be ready to route direct-out post-fader out of the channels.\nSPAT_S6L_V7_8MONO_8ST GROUPS_20_12\nSPAT_S6L_V7_8MONO_8ST GROUPS_20_12 is a basic entry S6L file with 8 mono SPAT send objects ready to be inserted on the channels you are using as direct out to SPAT. These are source/object 1-8. The file is all well ready with 8 Stereo groups for your source/object stems (9-16). Two test snapshots are preconfigured to reset all source positions and one as a snapshot test recalling all sources in a horizontal line. Plug-ins are set with a 2 seconds interpolation time showing how time value is used to smooth out transitions. The accompanying SPAT session file contains the 16 sources (8 mono and 8 stereo) connected to a Binaural Room as a start point (It’s a 24 channel of audio setup). The audio routing is not applied yet on this file but post fader pick off point option is set in order to be ready to route direct-out post-fader out of the channels."
  },
  {
    "objectID": "Third_Party_DiGiCo.html#configuration-and-templates",
    "href": "Third_Party_DiGiCo.html#configuration-and-templates",
    "title": "55  Setting up DiGiCo console with SPAT Revolution",
    "section": "55.1 Configuration and Templates",
    "text": "55.1 Configuration and Templates\nThe DiGiCo template files were created on a DiGiCo SD series using version 12.2.1280. File versions are provided for all the different console models DiGiCo makes (user can do their own conversion as well). The session files contain all the custom OSC configuration, but you need to set up the external control from the desk to SPAT Revolution as this is specific to the hardware.\nThis is a one-time setup for each specific consoles.\n\nGo to the Setup / External Control section of the desk.\n\n\n\n\nNetwork\n\n\nYou will want to make sure Enable External Control is set to YES and the Suppress OSC retransmit is active. You will be using OSC generic for channel controllers. You are now ready to add device to configure the OSC connection. It is considered other OSC .\n\n\n\nNetwork\n\n\n\nPress add device, give your device a name: for example, SPAT Revolution. Enter the IP address of your SPAT Revolution computer: in this example, 192.168.0.200. For port #, these are already configured in SPAT Revolution in the DiGiCo preset. On your External Device port on the DiGiCo set the Send port to 9200, Rcv Receive port is 9201. Make sure that you enable the OSC device with the green check!\n\n\n\n\n\n\n\nNote\n\n\n\nSettings have to be done individually because they are not part of a session file. These are global settings of the desk - they stay even when you’re loading a new session file.\n\n\nNow you are ready to load the template session provided. Two session models are provided. One for using SPAT control on all of the input channels, one using it on groups. Group template is the one to send audio to SPAT Revolution from group stems.\nAfter your file is loaded, you can see for example how to access these parameters on the desk.\n\n\n\nNetwork\n\n\nSelect an Input channel and open the channel’s output page. Select external control. It will then open the external control tab. Here, you will find the predetermined most common parameters for the SPAT Revolution. A user could decide to change these if needed (for example if rather wanting to use XYZ commands).\n\n\n\nNetwork\n\n\nConfigured in the templates are:\n\nRotaries:\n\n360 Pan (Azimuth)\nDistance (0-10M, default 2M like SPAT)\nElevation (-90 / 90 degree)\nPresence (Direct Source presence)\nSpread (0-100% Spread)\nScale (To scale stereo objects)\nLFE/Aux (Your 0.1 system aux send. The LFE)\nRoom P (The presence of the room reverb/tail)\n\nSwitches:\n\nSelect (to select the source, by default it will select when opening the External Control pane)\nSolo\nMute\nEarly (To enable/disable the localized early reflections - default on)\nCluster (To enable / disable cluster - default on)\nTail (To enable/disable the reverb diffused tail - default on)\nReverb (To completely enable/disable the reverb for this source - default on)\n\n\nDiGiCo OSC Generic External Control - Rotaries\n\n\n\nDiGiCo OSC Generic External Control - Rotaries\n\n\nDiGiCo OSC Generic External Control - Switch\n\n\n\nDiGiCo OSC Generic External Control - Switch"
  },
  {
    "objectID": "Third_Party_DiGiCo.html#audio-routing",
    "href": "Third_Party_DiGiCo.html#audio-routing",
    "title": "55  Setting up DiGiCo console with SPAT Revolution",
    "section": "55.2 Audio routing",
    "text": "55.2 Audio routing\nYour audio routing will happen either from you sending the post-fader channel direct out or the group outputs to MADI for example and receiving it in SPAT Revolution using a USB MADI interface (or any qualified MADI interface). These audio inputs will feed your sources/objects."
  },
  {
    "objectID": "Third_Party_DiGiCo.html#useful-tips-for-integration",
    "href": "Third_Party_DiGiCo.html#useful-tips-for-integration",
    "title": "55  Setting up DiGiCo console with SPAT Revolution",
    "section": "55.3 Useful tips for integration",
    "text": "55.3 Useful tips for integration\nImportant: The source/object index numbers of SPAT Revolution is matching the physical channels or Group (1 to x) of the DiGiCo desk. This means channel or group 1 on the desk will be source/object index 1 in SPAT Revolution. The same applies to a stereo channel or a stereo group. It is a single index for a stereo element. The communication between SPAT Revolution and DiGiCo is bidirectional - so when moving an object in SPAT Revolution, you will see that the parameters are changing at the external control window of the desk and vice versa.\nYou can use console snapshots to create your various scenes/cues. When recalling snapshots, the external parameters will be recalled as well. DiGiCo brings a crossfade time for these snapshots which means interpolation from a scene to the other. This is a powerful function to do crossfades.\n\n\n\n\n\n\nImportant\n\n\n\nKeep in mind that these are just global OSC recall/crossfade times. It’s not possible to set individual crossfade times for each OSC parameter by itself.\n\n\nUsing the Group template session, you have the exact same behaviour on your groups instead of your input channels. You can send either a single channel or multiple ones as a stem to these groups and control them as a single source/object eg. Your drum set.\nThen the fun begins! Feel free to add our Lemur or any other external touch control to the equation. The fact that you can on the desk itself send a select command for a source means that you can rapidly select the source and using the external control set to the -1 source / selected source gives you right away control on your fingertips. (see OSC -1 select message)."
  },
  {
    "objectID": "Third_Party_SSL.html#template",
    "href": "Third_Party_SSL.html#template",
    "title": "56  Solid State Logic SSL Live Consoles",
    "section": "56.1 Template",
    "text": "56.1 Template\nA simple template is available for downloading and provides a start point to configure this integration.\nSolid State Logic SSL Live v4.11 - SPAT Revolution 20.12 template"
  },
  {
    "objectID": "Third_Party_SSL.html#setting-up-ssl-live-console",
    "href": "Third_Party_SSL.html#setting-up-ssl-live-console",
    "title": "56  Solid State Logic SSL Live Consoles",
    "section": "56.2 Setting up SSL Live console",
    "text": "56.2 Setting up SSL Live console\n\nGo to MENU/Setup Option /EXTERNAL CONTROL to configure remote control.\nRename the Generic OSC to SPAT OSC and enter the SPAT Computer IP address.\nSet In port # to 9301 and Host RX Port # to 9300. They will match the SSL Live OSC Input and Output connection presets in SPAT Revolution.\nMake sure to Enable OSC and note the Control IP Address. This address will be needed when configuring SPAT OSC.\n\nSSL OSC Settings\n\n\n\nSSL Live SPAT OSC Swiches"
  },
  {
    "objectID": "Third_Party_SSL.html#external-control-fader-and-switches",
    "href": "Third_Party_SSL.html#external-control-fader-and-switches",
    "title": "56  Solid State Logic SSL Live Consoles",
    "section": "56.3 External control fader and switches",
    "text": "56.3 External control fader and switches\nSSL Generic OSC - External Control\n\n\n\nSSL Live SPAT OSC Swiches\n\n\nWith Solid State Logic live consoles, up to eight Fader (i.e. continuously variable) and eight Switch parameters per third-party device channel may be defined for control by the console. These control parameters (OSC messages) going out to SPAT Revolution source/objects are accessible from each console audio path as well as dedicated OSC paths with no console audio processing associated with them. The provided template has all these configurations done for you but you can decide to customize with different or less parameters.\nSSL OSC Device Configuration and Address for Switch\n\n\n\nSSL Live SPAT OSC Swiches\n\n\nSSL OSC Device Configuration and Address for Fader\n\n\n\nSSL Live SPAT OSC Faders"
  },
  {
    "objectID": "Third_Party_SSL.html#setting-up-spat-revolution",
    "href": "Third_Party_SSL.html#setting-up-spat-revolution",
    "title": "56  Solid State Logic SSL Live Consoles",
    "section": "56.4 Setting up SPAT Revolution",
    "text": "56.4 Setting up SPAT Revolution\n\nStart the SPAT Revolution software and open the preference page.\nEnable OSC.\n\n\n\n\nEnable OSC\n\n\n\nIn the OSC Connections section, use the pre-configured SSL Live OSC presets. In the pull down menu, choose input |SSL Live and select the local IP address you are using to communicate with the desk. Then set a second OSC Connection for the output from SPAT Revolution to the desk. In the pull down menu, choose output | SSL Live. You will enter the desk IP address as found in the OSC settings. Ports # 9300 (Input) and 9301 (Output) are pre-configured.\n\n\n\n\nEnable OSC"
  },
  {
    "objectID": "ThirdParty_SPATRevolution_Remote.html#installation",
    "href": "ThirdParty_SPATRevolution_Remote.html#installation",
    "title": "57  SPAT Revolution Remote",
    "section": "57.1 Installation",
    "text": "57.1 Installation\nThe first installation step is to download the resources. A config and a patch files are available for download via in the FLUX:: Center\n\n\n\nFLUX:: Center SPAT Revolution Remote\n\n\nThis install the resources in: - macOS: Library/Application Support/Flux/SPAT Remote Server - Windows: Program Files/Flux/SPAT Remote Server\nTo operate this server, you will need to download and install Open Stage Control, The application (server) that runs in the background and allows a web remote client access.\n\nMacOS\nWindows (64-bit)"
  },
  {
    "objectID": "ThirdParty_SPATRevolution_Remote.html#configuration",
    "href": "ThirdParty_SPATRevolution_Remote.html#configuration",
    "title": "57  SPAT Revolution Remote",
    "section": "57.2 Configuration",
    "text": "57.2 Configuration\nOnce installed, you can simply run the Open Stage Control application and configure it. According to your system, a Windows or macOS config file were downloaded. This config file can be simply loaded to Open Stage Control pressing the three dots on the right side of the interface.\n\n\n\nLoad Config\n\n\nSimply locate the config file in your folder:\n\nmacOS: Library/Application Support/Flux/SPAT Remote Server\nWindows: Program Files/Flux/SPAT Remote Server\n\nThis config file will provide a default configuration with predefined OSC (9400 and 9401) and Web server (9410) port numbers.\n\n\n\nSPAT Revolution Remote Config\n\n\nThe last step is to simply run the server. Simply press the Play button and the server will be up and running. The console will show all the client session info for all the available network interfaces with the computer.  \nBy default, the actual user interface of the Remote control will appear on your computer. You can actually use it but can simply close it if you strictly intend to use it remotely.\nIf you rather not see this interface every-time the server starts, you can add true to the no-gui field. But you are serving any browser in all cases.\n\n\n\nNo GUI\n\n\n\n\n\n\n\n\nWarning\n\n\n\nImportant:  Please make sure to open the server before opening SPAT Revolution."
  },
  {
    "objectID": "ThirdParty_SPATRevolution_Remote.html#autostart",
    "href": "ThirdParty_SPATRevolution_Remote.html#autostart",
    "title": "57  SPAT Revolution Remote",
    "section": "57.3 Autostart",
    "text": "57.3 Autostart\nYou can optionally engage the autostart so every-time Open Stage Control is started, the server will run. You can as well make Open Stage Control part of the launch of your computer so it will always be there running for you.\n\n\n\nAutostart"
  },
  {
    "objectID": "ThirdParty_SPATRevolution_Remote.html#spat-revolution-configuration",
    "href": "ThirdParty_SPATRevolution_Remote.html#spat-revolution-configuration",
    "title": "57  SPAT Revolution Remote",
    "section": "57.4 SPAT Revolution configuration",
    "text": "57.4 SPAT Revolution configuration\nConfiguring SPAT Revolution requires to set the OSC Connection Input and Output ports for the SPAT Remote Server. Predefined presets simply need to be chosen for the input and the output. These presets include the ADM-OSC transformation presets which offer the ability to scale the normalized positioning data to the desired range (the object positioning zone). By default, it is scaling to a scene of 10 m3 and a max distance of 10m.\n\nAccess the SPAT Revolution preference page and reach the OSC Connection section.\nAdd the input | SPAT Remote server preset\n\n\n\n\nSPAT Revolution OSC Connection Input\n\n\n\nAdd the output| SPAT Remote server preset\n\n\n\n\nSPAT Revolution OSC Connection Output\n\n\n\n\n\n\n\n\nNote\n\n\n\nThese above presets use the default ports and address of the Open Stage Control Config files supplied. By default, the local 127.0.0.1 address is set as it is assumed that the Remote server (Open Stage Control) is used locally on the same computer as SPAT Revolution. This is the most common scenario. If your server is running on another computer, you can simply change the IP address on the server prior to launching it, giving the IP of the SPAT Revolution computer Ethernet interface NIC.\n\n\n\n\n\nChanging the IP address in the server"
  },
  {
    "objectID": "ThirdParty_SPATRevolution_Remote.html#reaching-the-remote-interface-from-browser",
    "href": "ThirdParty_SPATRevolution_Remote.html#reaching-the-remote-interface-from-browser",
    "title": "57  SPAT Revolution Remote",
    "section": "57.5 Reaching the Remote interface from browser",
    "text": "57.5 Reaching the Remote interface from browser\nIn the above example, we saw that after launching the server, we saw the addresses that the app was available at:\n\n\n\nServer Info\n\n\nThis is basically giving you all the addresses of the network interfaces of your computer that can reach the server as a client (in a browser), and reach the SPAT Revolution Remote. For example, the last one, the 172.20.10.2 represents the hardwire connection of an Ipad - yes, they form a network when you connect them in USB. This makes a more than ever robust remote instead of relying on Wi-Fi (which still works good).\nWith this, we can then turn to the Ipad and start Safari. It is the preferred browser, simply dial the address shows where the server lies.\n\nhttp://172.20.10.2:9410\n\n\n\n\nReaching the server from Ipad\n\n\n\nAdding the SPAT Revolution Remote as a shortcut(Ipad)\nIf you would like to have a shortcut on your iPad to reach the SPAT Revolution remote, you can do this with these simple steps. Important to note that if you change the IP address of the server, you will need to redo this step again.\n\n\n\nAdding Page to iPad Home Screen 1 25%\n\n\n\n\n\nAdding Page to iPad Home Screen 2\n\n\n\n\n\nAdding Page to iPad Home Screen 3"
  },
  {
    "objectID": "ThirdParty_SPATRevolution_Remote.html#spat-revolution-remote-page",
    "href": "ThirdParty_SPATRevolution_Remote.html#spat-revolution-remote-page",
    "title": "57  SPAT Revolution Remote",
    "section": "57.6 SPAT Revolution Remote page",
    "text": "57.6 SPAT Revolution Remote page\nAlthough most pages are pretty much self-explanatory, here is a review of the Main and Snapshot pages\n\n\n\nSPAT Revolution Main Page\n\n\n\n\n\nSPAT Revolution Main Page"
  },
  {
    "objectID": "ThirdParty_SPATRevolution_Remote.html#release-notes",
    "href": "ThirdParty_SPATRevolution_Remote.html#release-notes",
    "title": "57  SPAT Revolution Remote",
    "section": "57.7 Release Notes",
    "text": "57.7 Release Notes\n\n22.10.0.50212\nRelease of the SPAT Revolution Remote package"
  },
  {
    "objectID": "ThirdParty_BlackTrax.html",
    "href": "ThirdParty_BlackTrax.html",
    "title": "58  BlackTrax integration",
    "section": "",
    "text": "Starting in SPAT version 1.1, a new UI implementation is available in order to integrate BlackTrax RTTrPM tracking protocol in SPAT. This provides a way to map BlackTrax tracking beacons with SPAT source objects and SPAT room listeners. In order to do this, you will need to configure the output configuration of a BlackTrax system and have your SPAT (or multiple SPAT) computers networked on the same third party network interface (NIC) of the BlackTrax server hardware. In the BlackTrax software, press on the output configuration button or access output configuration via the menu bar in the Settings section (shortcut Ctrl + T).\n\n\nIn the Output Configuration window, you will need to create with the + sign 1 (or multiple if running a main and a back up SPAT computer engine) output that will be sending tracking RTTrPM data to SPAT. Clicking the + sign will give you an edit window.\n\nIn the edit window, you will first label you Output to the desired name (Ex: SPAT Main). Type of output will be RTTrPM, the third party motion protocol of BlackTrax. NIC is the actual network interface that you are doing the integration to SPAT. The default NIC of BlackTrax server for RTTrPM is 10.133.3.9 255.255.255.0. They do have multiple NIC for various use such as lighting and the actual BlackTrax network itself. You will want to make sure your SPAT is either in the same range as this address (10.133.3.x, 255.255.255.0), or use your addresses of choice in the same range. Please consult with a certified BlackTrax support representative before to attempt to change IP.\nIn the below example, addresses of the Blacktrax NIC was changed to 192.168.1.200 Communication should be set to Unicast. Please refrain from using Broadcast unless specific circumstances. Currently, Multicast is not implemented with SPAT software. Port number should be left to the default port # 24002 as it is the default port for the BlackTrax system and the default port preconfigured into SPAT software. Press Apply and you are set with this step.\n\nPressing the Advanced button will give you some advanced option. Your default Coordinate System should be Stage. You can apply these settings. You are now set. Before BlackTrax will actually output anything to the SPAT system, you will need to enable the Beacons present in the system that you actually want to be sending tracking data. In the Active Output window, select you SPAT Main output. On the bottom right, select the Beacon you would like to have data sending and press Enable Selected. You can multi-select when pressing the CTRL key or select all with CTRL + A.\n\nWhen done with all operations with BlackTrax, you want to Apply the changes to the system. You can at this point close the Output Configuration window and go back to the main BlackTrax page. You will want to apply the changes to the system.\n\nYou can confirm that you are actually sending data by going back to the Output Configuration page. The status will give you this information.\n\nNow let’s go and configure the SPAT software. In the preference page accessible by clicking on the top right button, you can scroll down to the BlackTrax preference section.\n\nYou can from there, Enable BlackTrax RTTrPM tracking, select the amount of Max Beacon you system may need (1, 2, 4, 8, 16, 24, 32 or more). Select the network interface you are using on your computer for the BlackTrax integration (Or leave to Automatic) and then the port # which is already set at the default port # used by BlackTrax RTTrPM output. You are set. These new preferences will be store with all your preferences and remain after closing and restarting SPAT Revolution software.\nFirst option is to assign a Beacon ID to an actual audio source object. Selecting a source will give you the source menu options. In the option are now Tracking options and a pull down menu to choose the Tracking Index (the beacon ID number you want for this audio source). The list will be based on your Max Beacon preference. It is possible to have the same Index for multiple sources providing the ability to have multiple sources track a single beacon.\n\nYour second option is to assign a Beacon ID to an actual room in order to have the listener position tracked. Selecting a room will give you the room menu options. In the option are now Tracking options with a pull down menu to choose the Tracking Index (the beacon ID number you want for this room listener). The list will be based on your Max Beacon preference. A Tracking Scale setting is as well provide which would allow to scale the incoming data to adjust to your speaker output setup size if needed.\n\nIn the actual room output parameters in the room view, you will also see a tracking option become available."
  },
  {
    "objectID": "Appendix_A.html#availability",
    "href": "Appendix_A.html#availability",
    "title": "Appendix A — SPAT Revolution specifications",
    "section": "A.1 Availability",
    "text": "A.1 Availability\nSPAT Revolution is a stand-alone application for macOS and Windows. SPAT Send/Return/Room plugins are available in AU/VST/AAX Native. SPAT Send plugin is available in AAX VENUE.\nSee plugins specifications for more details."
  },
  {
    "objectID": "Appendix_A.html#processing",
    "href": "Appendix_A.html#processing",
    "title": "Appendix A — SPAT Revolution specifications",
    "section": "A.2 Processing",
    "text": "A.2 Processing\nSPAT Revolution stand-alone software: - unlimited number of channels for Inputs and Outputs (Ultimate license only, hardware and audio interface dependent). - 32/64-bits internal floating-point processing. - Sampling rates up to 384kHz, block size starting at 16 samples."
  },
  {
    "objectID": "Appendix_A.html#os-compatibility",
    "href": "Appendix_A.html#os-compatibility",
    "title": "Appendix A — SPAT Revolution specifications",
    "section": "A.3 OS Compatibility",
    "text": "A.3 OS Compatibility\n\nWindows 10 - 64 bits.\nmacOS - All versions from 10.15 including macOS Big Sur and Monterey compliant. *\n\n\n\n\n\n\n\nNote\n\n\n\n*See hardware details for more information on compatibility."
  },
  {
    "objectID": "Appendix_A.html#hardware-recommendations-and-requirements",
    "href": "Appendix_A.html#hardware-recommendations-and-requirements",
    "title": "Appendix A — SPAT Revolution specifications",
    "section": "A.4 Hardware Recommendations and requirements",
    "text": "A.4 Hardware Recommendations and requirements\n\nSingle Computer (Creative Station with DAW and SPAT Revolution)\nSingle computer systems can provide an excellent option for portability but come with the importance of having a performing computer. As SPAT Revolution comes with a 3D graphic engine where audio objects are manipulated, GPU resources are required.\nApple based recommended hardware:\n\nApple Silicon / ARM M1 *\n\nMac Studio M1 Max / M1 Ultra off the shelf models\nMac Mini M1 Chip\nMacBook Pro (13/14/16 inches) M1 Chip\n\nApple Intel\n\nMacPro, 3.5GHz 8‑core Intel Xeon W processor, Radeon Pro W5500X, 32GB RAM\niMac Pro, 3.2GHz 8‑core Intel Xeon W Turbo Boost, Radeon Pro Vega 56 8 GB, 32GB RAM\nMacBook Pro with dedicated GPU video graphic card\n\n\n\n\n\n\n\n\nNote\n\n\n\n*SPAT Revolution is fully supported to Silicon / ARM Apple computers via the Rosetta binary translator.\n\n\nGeneric hardware specification:\n\nProcessing: Intel Core i9-9900K, i7-9700K or equivalent. Intel 8th generation or greater processor. (Minimum 6 cores - 8 preferred), 8 MB Cache.\nSystem Memory: 16 minimum GB DDR4 (32 preferred when integrating with DAW and SPAT Revolution on the same machine with local audio path - LAP)\nChipset: High-quality / Professional main-board\nGraphic: GeForce GTX 1060 - 4GB GDDR5 Graphic Memory or greater. Graphic card fully supporting OpenGL 2.0 is required. USB displays are not supported.\nAudio Interfaces:\n\nmacOS: Core Audio compatible interface or virtual sound card\nWindows: ASIO compatible interface or virtual sound card.\n\n\n\n\nHardware for Live Productions (Dedicated SPAT Revolution Computer)\nRecommended audio interfaces:\n\nRME Digiface AVB or Dante, USB 3 Audio interface\nRME Madi HDSPe (PCIe), MADI FX or MADIface XT.\n\nApple based recommended hardware:\n\nApple Silicon / ARM M1\n\nMac Studio M1 Max (10-Core CPU, 24-Core GPU, 32 GB RAM)\nMac Studio M1 Ultra (20-Core CPU, 48-Core GPU, 64 GB RAM)\n\nApple Intel\n\nMacPro, 3.5GHz 8‑core Intel Xeon W processor, Radeon Pro W5500X, 32GB RAM\n\n\n\n\n\n\n\n\nNote\n\n\n\nRackmounted Apple Mac Studio is possible using Sonnet’s xMac Studio or RackMac Studio 3U rackmount systems. xMac Studio can hold one Mac Studio and provide PCIe card expansion module while the RackMac Studio can hold 2 units such as in redundant configuration. MacPro can be installed in a Sonnet’s RackMac™\n\n\nGeneric recommended hardware specification:\n\nIntel® Xeon® W family W-2200 or W-3200 Series CPU (preferred), E-22xx, or equivalent. Higher core speed. Minimum 8 Cores, 12 MB Cache\nChipset: Professional workstation chipset C422, C621, or equivalent.\nSystem Memory: 32 – 64 GB. A system with ECC support is preferred.\nGraphic: Professional NVIDIA Quadro P4000 or equivalent - 8GB GDDR5 Graphic Memory (Graphic card with full support for OpenGL 2.0), with the latest graphic drivers.\nNetwork: Dual network interface (NIC) - Intel I210-T1 or equivalent\nOS drive (Operating System): NVMe Internal SSD\nAudio Projects Hard Drive: no specifics. For redundant systems, only certified RAID systems should be used.\nReal-Time optimized OS with minimum services.\n\n\n\nSoftware License Requirements\nTo use the software, an iLok.com user account is required (the iLok USB Smart Key is not required, authorization can be made to hardware machines)."
  },
  {
    "objectID": "Appendix_A.html#certified-configurations-spat-revolution-v.22.02.50151",
    "href": "Appendix_A.html#certified-configurations-spat-revolution-v.22.02.50151",
    "title": "Appendix A — SPAT Revolution specifications",
    "section": "A.5 Certified configurations (SPAT Revolution v.22.02.50151)",
    "text": "A.5 Certified configurations (SPAT Revolution v.22.02.50151)\nThese configurations are tested and validated on a computer dedicated to SPAT Revolution. All other applications have been closed, and computer has been optimized as indicated below.\nComputer optimization: - Disable Wi-Fi and Bluetooth if not absolutely required. - Disable Airdrop - Disable Spotlight - Disable display sleep, disk spin-down, and system sleep - Disable screen saver - Disable Time Machine - Disable software update - Disable dashboard (Catalina and prior) - Disable photos processing and Cloud services - Log out of iCloud\nThe below configurations have been tested at the worst scenario, with the reverberation at the highest density for all rooms, all sources active with reverberation and all sources in full movement using OSC input. WFS and Binaural PanType are used as reference as they are the most processing heavy techniques.\n\n\n\n\n\n\nWarning\n\n\n\nProcessing can be different according to the used HRTF. Kemar HRTF were used for these tests.\nIn the case of the Dante Virtual Soundcard, the network latency, reported into SPAT, have been set to 10ms.\n\n\n\n48000 kHz\n\nmac Mini M1 | Basic configuration\n\n\n\n\n\n\n\n\n\n\nNumber of sources\nNumber of speakers\nRoom and PanType\nBuffer with RME Digiface Dante / AVB\nBuffer with Dante Virtual Soudcard\n\n\n\n\n64\n32\n1 WFS room\n256 (11.5ms)\n128 (25.33ms)\n\n\n64\n64\n1 WFS room\n512 (22.16ms)\n256 (30.66ms)\n\n\n64\n16 + Binaural\n2 rooms: 1 WFS + 1 Binaural\n1024 (43.5ms)\n512 (52ms)\n\n\n\n\n\nmac Studio M1 Max | Basic configuration\n\n\n\n\n\n\n\n\n\n\nNumber of sources\nNumber of speakers\nRoom and PanType\nSound card\nBuffer size / reported Latency\n\n\n\n\n64\n32\n1 WFS room\nRME Digiface Dante / AVB\n64 (3.5ms)\n\n\n64\n64\n1 WFS room\nRME Digiface Dante / AVB\n128 (6.16ms)\n\n\n64\n16 + Binaural\n2 rooms: 1 WFS + 1 Binaural\nRME Digiface Dante / AVB\n128 (6.16ms)\n\n\n\n\n\n\n96000 kHz\n\nmac Mini M1 | Basic configuration\n\n\n\n\n\n\n\n\n\n\nNumber of sources\nNumber of speakers\nRoom and PanType\nSound card\nBuffer size / reported Latency\n\n\n\n\n32\n16\n1 WFS room\nRME Digiface Dante / AVB\n256 (6.05ms)\n\n\n32\n48\n1 WFS room\nRME Digiface Dante / AVB\n512 (11.44ms)\n\n\n32\n32 + Binaural\n2 rooms: 1 WFS + 1 Binaural\nRME Digiface Dante / AVB\n1024 (22.1ms)\n\n\n64\n16\n1 WFS room\nRME Digiface Dante / AVB\n512 (11.44ms)\n\n\n64\n24\n1 WFS room\nRME Digiface Dante / AVB\n1024 (22.1ms)\n\n\n\n\n\nmac Studio M1 Max | Basic configuration\n\n\n\n\n\n\n\n\n\n\nNumber of sources\nNumber of speakers\nRoom and PanType\nSound card\nBuffer size / reported Latency\n\n\n\n\n32\n16\n1 WFS room\nRME Digiface Dante / AVB\n64 (2.1ms)\n\n\n32\n48\n1 WFS room\nRME Digiface Dante / AVB\n128 (3.42ms)\n\n\n32\n32 + Binaural\n2 rooms: 1 WFS + 1 Binaural\nRME Digiface Dante / AVB\n256 (6.05ms)\n\n\n64\n16\n1 WFS room\nRME Digiface Dante / AVB\n128 (3.42ms)\n\n\n64\n24\n1 WFS room\nRME Digiface Dante / AVB\n256 (6.05ms)"
  },
  {
    "objectID": "Appendix_B.html#sync-issues-with-lap",
    "href": "Appendix_B.html#sync-issues-with-lap",
    "title": "Appendix B — Troubleshooting",
    "section": "B.1 Sync issues with LAP",
    "text": "B.1 Sync issues with LAP\nWhen using Local Audio Path (LAP), synchronisation issues can be identified when the synchronisation indicator in SPAT Revolution (bottom left corner) turns to red. This can in some cases result in clicks, noises, and or loss of sound.\n\n\n\nSync Error\n\n\nAll ‘green’ indicators mean the sync is correct.\n\n\n\nSync\n\n\nThanks to the DAW templates provided, this should not happen unless the required routing is not in place (session modified, routing unpatched). To work properly, the SPAT Send plug-ins instances must be processed by the DAW before the SPAT return plug-in instances.\nTo force the DAW to process this way, each track with SEND plug-in inserted must be routed (directly or indirectly) to the ‘return’ tracks, using DAW internal routing (ex: dummy busses in ProTools, direct routing in Reaper).\n\n\n\n\n\n\nNote\n\n\n\nCPU performance overloading could generate some sync errors.\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can reset the sync error by double-clicking on the sync error counter.\n\n\nIf you see red indicators in the bottom left corner section of SPAT, this could be related to having a mismatch in frame size (buffer) or sample rate between the DAW and the SPAT Revolution.\nFrame size (sometimes called buffer size or block size) should be matched in the host DAW and SPAT Revolution. A red message would identify a different frame rate the host DAW. Simply double-clicking on smp/f message in error will automatically change you SPAT block size setup to match the incoming audio.\nIf the audio processing is too demanding for your computer at the current block size and sample rate, you may also experience dropouts and sync problems due to CPU overload.\nIf you are experiencing lost sync when using Local Audio:\n\nIncrease the block size in the SPAT preferences.\nSave your project and quit SPAT Revolution.\nChange the block size in your host DAW to match the new setting.\nReopen SPAT Revolution.\n\nAlso, please be sure to carefully read the detailed advice of the various DAW in the ?sec-third-party section of this guide and refer to the various provided templates."
  },
  {
    "objectID": "Appendix_B.html#spat-send-and-return-daw",
    "href": "Appendix_B.html#spat-send-and-return-daw",
    "title": "Appendix B — Troubleshooting",
    "section": "B.2 SPAT Send and Return DAW",
    "text": "B.2 SPAT Send and Return DAW\nWhen dealing with SPAT Send and Return, you do not need to have a hardware device configured in the preference. In this case, SPAT Revolution will automatically adapt its sampling rate and synchronize to the incoming software audio I/O.\nSync issues encountered in SPAT Revolution when using the Local Audio Path workflow can often be fixed when following some guidelines for routing order inside the DAW. Thanks to the various DAW templates, this is done for the users.\nTo work properly, the SEND plug-ins instances must be processed by the DAW before the RETURN plug-in instances. To force the DAW to process this way, each track with SEND plug-in inserted must be routed (directly or indirectly) to the tracks hosting a RETURN plug-in, using DAW internal routing.\nFollowing are four examples of recommended practice with DAW routing, which should cover the main use cases. If your problems persist even after implementing these suggestions, don’t hesitate to drop us a line at FLUX:: support.\n\n\n\n\n\n\nNote\n\n\n\nPLEASE NOTE: The mixing of HARDWARE inputs and LOCAL AUDIO PATH may report a sync loss, as SPAT Revolution cannot guarantee correct sync in this scenario. Proceed with caution if this is unavoidable. This is not officially supported._\n\n\nSPAT RETURN plug-in on master track\nIn simple projects, when having a single return plug-in on a master track, you should not encounter any sync issue as long as each SEND track is routed to the master.\n\nSingle RETURN on an AUX track\nIssues may happen when return is inserted on an AUX track. Make sure that each SEND track is routed to the AUX track (RETURN track). Here is an example using AUX send (see examples below).\n\n\n\n\n\n\n\nNote\n\n\n\nYou might achieve the same by routing the track outputs to the bus.\n\n\nSeveral RETURN on AUX tracks\nWhen several RETURN tracks are needed (for example several rooms to render from SPAT Revolution, and/or several output stream formats), you will have to route each SEND track to each RETURN track, using the same technique.\nAs it can quickly become complicated as the project grows, in the following example, the use of a ‘dummy’ track, avoids using several AUX sends on the ‘SEND ’tracks. It makes routing clearer and easier to implement on larger projects. The ’dummy’ AUX track is routed to all the RETURN tracks (using AUX sends or patching the output to a multichannel/multi-format ‘dummy’ bus).\nThen, simply route all your SEND tracks to this ‘dummy’ track by simply patching its output to the multichannel/multi-format ‘dummy’ bus or via the use of aux send.\n\nUsing specific tracks as your SPAT source/object\nOne of the good practices to deal with the source/object you are sending for external rendering is to use tracks as dedicated objects. (Similar to many object-based mixing workflows proposed by DAW.) This way you can leave the session audio tracks and their channel insertion as they are and simply send your audio track to the SPAT SEND object track. This allows you to send a single audio track or multiple ones (stem) to the SPAT SEND object track.\nDoing this can segment your external rendering routing and is highly recommended to prevent audio track delay compensation systems in DAW to come and jeopardize the audio synchronization between the DAW and SPAT. This as well ensures that your audio track automation on levels for example is respected as some DAWs don’t have post-fader insertion (a pre-fader insert with SPAT SEND PI will send audio to SPAT Revolution prior to your fader automation).\n\nThe above best practice ensures as well that you keep both the dry signal and the SPAT RETURN signals independent (when the mix requires to switch easily from one to the other), add one object AUX track per audio track to be sent to SPAT, and insert the SEND plug-in on these object AUX tracks.\nThis way, you keep the dry signal on the audio track’s output."
  },
  {
    "objectID": "Appendix_B.html#clearing-shared-memory",
    "href": "Appendix_B.html#clearing-shared-memory",
    "title": "Appendix B — Troubleshooting",
    "section": "B.3 Clearing Shared Memory",
    "text": "B.3 Clearing Shared Memory\nSome users have experienced an issue where SPAT SEND and RETURN plug-ins are not cleared from the shared memory when used with certain third-party DAW hosts (or seen after DAW crashes). Although this should not happen and have been intensively improved in the latest releases of SPAT Revolution, a Clean Shared Memory option can fix some connection issues (ghost modules, duplicated modules, modules not connecting when opening session). This can sometimes be seen where SPAT Send and Return modules appear in the SPAT setup page when there is no DAW host software running in the background. It can cause problems, when a host with plug-ins is launched and more SEND and RETURN plug-ins appear to be doubled.\nAlthough rebooting the computer would fix this issue, the workaround if this is happening with your particular third-party software, is to invoke a special debug action called Clean Shared Memory. It is available by the Help menu Help/Clean Shared Memory\nIf this command is executed, SPAT and the plug-in host will then need to be restarted."
  },
  {
    "objectID": "Appendix_B.html#performance-issues",
    "href": "Appendix_B.html#performance-issues",
    "title": "Appendix B — Troubleshooting",
    "section": "B.4 Performance issues",
    "text": "B.4 Performance issues\nThere are also some performance preferences that may help in the case that your host machine CPU is overloading and causing audio glitches.\n\nLower UI frame rates.\nTurn the ‘Nebula Alpha’ to zero in your rooms.\nLowering Reverb Density to 8x8 for all Rooms.\nLower the automation rate via the engine preference\nAdjust the Multi-Core Parallel Computation Algorithm via the engine preference.\n\nTo lower UI graphic frame rates, go to the SPAT preferences. Changing the Edit Frame Rate will reduce pressure on the graphics updates and important when a host machine does not have dedicated GPU and CPU resources.\nThe latest release of SPAT Revolution includes a new Multi-Core Parallel Computation Algorithm. In the preference of SPAT Revolution, in the Engine section at the bottom, you can choose various computer hardware presets that match your setup. This is a simple step to tuning the computation algorithm.\nIf you are still experiencing performance and sync issues, you may want to ensure that your hardware configuration meets the SPAT Revolution requirements and recommendations A\nConsider as well to kill as many processes not required as possible (Wi-Fi/internet, background services and activity)."
  },
  {
    "objectID": "Appendix_B.html#display-performance-cpu-measurements",
    "href": "Appendix_B.html#display-performance-cpu-measurements",
    "title": "Appendix B — Troubleshooting",
    "section": "B.5 Display Performance (CPU) measurements",
    "text": "B.5 Display Performance (CPU) measurements\nIncluded in release version 20.12 is the ability to display performance (CPU) measurements. This can be done in the Help menu Display Performance option. This can be accesses as well with shortcuts Shift + Option + Command + P.\n\n\n\nDisplay Performance"
  },
  {
    "objectID": "Appendix_B.html#engine-parallel-processing-profile",
    "href": "Appendix_B.html#engine-parallel-processing-profile",
    "title": "Appendix B — Troubleshooting",
    "section": "B.6 Engine Parallel Processing profile",
    "text": "B.6 Engine Parallel Processing profile\nSPAT Revolution v20.12 introduced a new Multi-Core Parallel Computation Algorithm that is key to optimizing your hardware. This is for both the automation and the audio processing. The Display Performance option stated above will be our best ally to monitor the results. This can be accessed with shortcuts Shift + Option + Command + P.\nThe Engine Preference section includes three Profiles for parallel processing\n\n\n\nNew updated Engine Preference Section\n\n\nAutomation Rate provides the ability to set the refresh rate (frequency) of the automation. By default, we use 10.0 ms (100.00 fps). This can be decreased to lower the frequency if you see that automation is becoming a burden for your system with such a fast refresh.\n\n\n\nAutomation Rate Optimization\n\n\nMax Number of Core is your ability to make more or fewer cores available to the SPAT Revolution algorithm. By default, it will be at your number of native core. Not hyper-threading. This can be increased or reduced. Watch not to take all cores for a multitasking computer.\n\n\n\nMax Number Of Cores - Engine Preference\n\n\nLastly are the 3 presets for you to choose from, to adapt the parallel profile to your use:\n\nMax distribution is a preset which helps to spread the load as much as possible to all cores. It is mainly recommended for Desktop systems and dedicated real-time SPAT computers.\nFavor first core is a typical preset for laptop computers where we find that loading cores as much as possible, allowing us to get out of the way of some laptop optimization (power and cooling) that are playing with available processing speed.\nBalanced distribution is a preset somehow in the middle. It intends to be a balance between both above options.\n\n\n\n\nParallel Processing Algo Profile"
  },
  {
    "objectID": "Appendix_C_OSC_Table.html#osc-grammar",
    "href": "Appendix_C_OSC_Table.html#osc-grammar",
    "title": "Appendix C — Appendix C - OSC Table",
    "section": "C.1 OSC Grammar",
    "text": "C.1 OSC Grammar\nFLUX:: SPAT Revolution supports by default 3 input grammars: FLUX:: OSC grammar, ADM-OSC grammar and IRCAM ADMix positional grammar."
  },
  {
    "objectID": "Appendix_C_OSC_Table.html#osc-output-options",
    "href": "Appendix_C_OSC_Table.html#osc-output-options",
    "title": "Appendix C — Appendix C - OSC Table",
    "section": "C.2 OSC Output Options",
    "text": "C.2 OSC Output Options\nFor position / radiation messages such as XYZ and AED, it supports individual messages, abbreviated individual messages, packed messages (XYZ or AED) or partially packed messages (XY or AE or AD). On OSC Output, various OSC connections options are available to configure a custom OSC output. 1) AED or/and XYZ packing can be forced on output 2) Auto-Bundle features of OSC can be enabled or disabled. 3) Messages can be sent with Index as Argument rather than in the message (aka /source/aed [1, 45, 45, 2] instead of /source/1/aed [45, 45, 2] ) 4) The ping-pong feature will force send messages coming from an OSC source back to it (by default, we send all message incoming to all output destination except destinations that are the source of the message. The destination which is defined as the source is the output with same IP address and a port number in the range of [input OSC port / input OSC port +10]. Example : for input 127.0.0.1 Port 8000, Output 127.0.0.1 port 8009 is considered as the same device, port 8011 as another device). 5) Touch/Release messages are used to nicely integrate with DAW Automation features, this can be disabled on output if required or if messages are not supported by destination 6) Alternatively, ADM-OSC grammar can be used on output rather the standard FLUX:: OSC grammar"
  },
  {
    "objectID": "Appendix_D_release_notes.html",
    "href": "Appendix_D_release_notes.html",
    "title": "Appendix D — SPAT Revolution - Release notes",
    "section": "",
    "text": "Here are the release notes of the last SPAT Revolution versions.\n\nVersion 22.10.50222\nVersion 22.10.50219\nVersion 22.10.50213\nVersion 22.09.50206\nVersion 22.09.50200\nVersion 22.02.50151\nVersion 22.02.50148\nVersion 21.04.50030\nVersion 21.04.50020\nVersion 20.12.49943\nVersion 20.12.49930\nVersion 20.12.49890\nVersion 20.12.49880"
  }
]